* Table of Contents :TOC:QUOTE:
#+BEGIN_QUOTE
- [[#links][Links]]
- [[#getting-started][Getting Started]]
  - [[#why-async][Why async]]
  - [[#the-state-of-asynchronous-rust][The State of Asynchronous Rust]]
  - [[#asyncawait-primer][~async/.await~ Primer]]
- [[#asyncawait][async/.await]]
  - [[#async-lifetimes][~async~ Lifetimes]]
  - [[#async-move][~async move~]]
  - [[#awaiting-on-a-multithreaded-executor][~.await~ing on a Multithreaded Executor]]
- [[#the-stream-trait][The ~Stream~ Trait]]
  - [[#iteration-and-concurrency][Iteration and Concurrency]]
- [[#executing-multiple-futures-at-a-time][Executing Multiple Futures at a Time]]
#+END_QUOTE

* Links

- https://rust-lang.github.io/async-book/

* Getting Started
** Why async
*** Async in Rust vs other languages

Although asynchronous programming is supported in many languages, some details
vary across implementations. Rust's implementation of async differs from most
languages in a few ways:

- *Futures are inert* in Rust and make progress only when polled. Dropping a
  future stops it from making further progress.
- *Async is zero-cost* in Rust, which means that you only pay for what you use.
  Specifically, you can use async without heap allocations and dynamic dispatch,
  which is great for performance! This also lets you use async in constrained
  environments, such as embedded systems.
- *No built-in runtime* is provided by Rust. Instead, runtimes are provided by
  community maintained crates.
- *Both single- and multithreaded* runtimes are available in Rust, which have
  different strengths and weaknesses.

*** Async vs threads in Rust

OS threads are suitable for a small number of tasks, since threads come with CPU
and memory overhead. Spawning and switching between threads is quite expensive
as even idle threads consume system resources. A thread pool library can help
mitigate some of these costs, but not all. However, threads let you reuse
existing synchronous code without significant code changes—no particular
programming model is required. In some operating systems, you can also change
the priority of a thread, which is useful for drivers and other latency
sensitive applications.

Async provides significantly reduced CPU and memory overhead, especially for
workloads with a large amount of IO-bound tasks, such as servers and databases.
All else equal, you can have orders of magnitude more tasks than OS threads,
because an async runtime uses a small amount of (expensive) threads to handle a
large amount of (cheap) tasks. However, async Rust results in larger binary
blobs due to the state machines generated from async functions and since each
executable bundles an async runtime.

On a last note, asynchronous programming is not /better/ than threads, but
different. If you don't need async for performance reasons, threads can often be
the simpler alternative.

*** Example: Concurrent downloading

In this example our goal is to download two web pages concurrently. In a typical
threaded application we need to spawn threads to achieve concurrency:

#+BEGIN_SRC rust :noeval
fn get_two_sites() {
    // Spawn two threads to do work.
    let thread_one = thread::spawn(|| download("https://www.foo.com"));
    let thread_two = thread::spawn(|| download("https://www.bar.com"));

    // Wait for both threads to complete.
    thread_one.join().expect("thread one panicked");
    thread_two.join().expect("thread two panicked");
}
#+END_SRC

However, downloading a web page is a small task; creating a thread for such a
small amount of work is quite wasteful. For a larger application, it can easily
become a bottleneck. In async Rust, we can run these tasks concurrently without
extra threads:

#+BEGIN_SRC rust :noeval
async fn get_two_sites_async() {
    // Create two different "futures" which, when run to completion,
    // will asynchronously download the webpages.
    let future_one = download_async("https://www.foo.com");
    let future_two = download_async("https://www.bar.com");

    // Run both futures to completion at the same time.
    join!(future_one, future_two);
}
#+END_SRC

Here, no extra threads are created. Additionally, all function calls are
statically dispatched, and there are no heap allocations! However, we need to
write the code to be asynchronous in the first place.

Rust doesn't force you to choose between threads and async. You can use both
models within the same application, which can be useful when you have mixed
threaded and async dependencies. In fact, you can even use a different
concurrency model altogether, such as event-driven programming, as long as you
find a library that implements it.

** The State of Asynchronous Rust

In short, async Rust is more difficult to use and can result in a higher
maintenance burden than synchronous Rust, but gives you best-in-class
performance in return. All areas of async Rust are constantly improving, so the
impact of these issues will wear off over time.

*** Language and library support

While asynchronous programming is supported by Rust itself, most async
applications depend on functionality provided by community crates. As such, you
need to rely on a mixture of language features and library support:

- The most fundamental traits, types and functions, such as the [[https://doc.rust-lang.org/std/future/trait.Future.html][Future]] trait are
  provided by the standard library.
- The ~async/await~ syntax is supported directly by the Rust compiler.
- Many utility types, macros and functions are provided by the [[https://docs.rs/futures/][futures]] crate.
  They can be used in any async Rust application.
- Execution of async code, IO and task spawning are provided by "async
  runtimes", such as Tokio and async-std. Most async applications, and some
  async crates, depend on a specific runtime.

*** Compatibility considerations

Asynchronous and synchronous code cannot always be combined freely. For
instance, you can't directly call an async function from a sync function. Sync
and async code also tend to promote different design patterns, which can make it
difficult to compose code intended for the different environments.

Even async code cannot always be combined freely. Some crates depend on a
specific async runtime to function. If so, it is usually specified in the
crate's dependency list.

These compatibility issues can limit your options, so make sure to research
which async runtime and what crates you may need early. Once you have settled in
with a runtime, you won't have to worry much about compatibility.

** ~async/.await~ Primer

~async~ / ~.await~ is Rust's built-in tool for writing asynchronous functions
that look like synchronous code. ~async~ transforms a block of code into a state
machine that implements a trait called ~Future~. Whereas calling a blocking
function in a synchronous method would block the whole thread, blocked ~Future~s
will yield control of the thread, allowing other ~Future~s to run.

Let's add some dependencies to the ~Cargo.toml~ file:

#+BEGIN_SRC toml
[dependencies]
futures = "0.3"
#+END_SRC

To create an asynchronous function, you can use the async fn syntax:

#+BEGIN_SRC rust :noeval
async fn do_something() { /* ... */ }
#+END_SRC

The value returned by ~async fn~ is a ~Future~. For anything to happen, the
~Future~ needs to be run on an executor.

#+BEGIN_SRC rust :results output
// `block_on` blocks the current thread until the provided future has run to
// completion. Other executors provide more complex behavior, like scheduling
// multiple futures onto the same thread.
use futures::executor::block_on;

async fn hello_world() {
    println!("hello, world!");
}

fn main() {
    let future = hello_world(); // Nothing is printed
    block_on(future); // `future` is run and "hello, world!" is printed
}
#+END_SRC

Inside an ~async fn~, you can use ~.await~ to wait for the completion of another
type that implements the ~Future~ trait, such as the output of another
~async fn~. Unlike ~block_on~, ~.await~ doesn't block the current thread, but
instead asynchronously waits for the future to complete, allowing other tasks to
run if the future is currently unable to make progress.

For example, imagine that we have three ~async fn~: ~learn_song~, ~sing_song~,
and ~dance~:

#+BEGIN_SRC rust :noeval
async fn learn_song() -> Song { /* ... */ }
async fn sing_song(song: Song) { /* ... */ }
async fn dance() { /* ... */ }
#+END_SRC

One way to do learn, sing, and dance would be to block on each of these
individually:

#+BEGIN_SRC rust :noeval
fn main() {
    let song = block_on(learn_song());
    block_on(sing_song(song));
    block_on(dance());
}
#+END_SRC

However, we're not giving the best performance possible this way—we're only ever
doing one thing at once! Clearly we have to learn the song before we can sing
it, but it's possible to dance at the same time as learning and singing the
song. To do this, we can create two separate async fn which can be run
concurrently:

#+BEGIN_SRC rust :noeval
async fn learn_and_sing() {
    // Wait until the song has been learned before singing it.
    // We use `.await` here rather than `block_on` to prevent blocking the
    // thread, which makes it possible to `dance` at the same time.
    let song = learn_song().await;
    sing_song(song).await;
}

async fn async_main() {
    let f1 = learn_and_sing();
    let f2 = dance();

    // `join!` is like `.await` but can wait for multiple futures concurrently.
    // If we're temporarily blocked in the `learn_and_sing` future, the `dance`
    // future will take over the current thread. If `dance` becomes blocked,
    // `learn_and_sing` can take back over. If both futures are blocked, then
    // `async_main` is blocked and will yield to the executor.
    futures::join!(f1, f2);
}

fn main() {
    block_on(async_main());
}
#+END_SRC

In this example, learning the song must happen before singing the song, but both
learning and singing can happen at the same time as dancing. If we used
~block_on(learn_song())~ rather than ~learn_song().await~ in ~learn_and_sing~,
the thread wouldn't be able to do anything else while ~learn_song~ was running.
This would make it impossible to ~dance~ at the same time. By ~.await~-ing the
~learn_song~ future, we allow other tasks to take over the current thread if
~learn_song~ is blocked. This makes it possible to run multiple futures to
completion concurrently on the same thread.

* async/.await

~async~ / ~.await~ are special pieces of Rust syntax that make it possible to
yield control of the current thread rather than blocking, allowing other code to
make progress while waiting on an operation to complete.

There are two main ways to use ~async~: ~async fn~ and ~async~ blocks. Each
returns a value that implements the ~Future~ trait:

#+BEGIN_SRC rust :noeval
// `foo()` returns a type that implements `Future<Output = u8>`.
// `foo().await` will result in a value of type `u8`.
async fn foo() -> u8 { 5 }

fn bar() -> impl Future<Output = u8> {
    // This `async` block results in a type that implements
    // `Future<Output = u8>`.
    async {
        let x: u8 = foo().await;
        x + 5
    }
}
#+END_SRC

As we saw in the first chapter, ~async~ bodies and other futures are lazy: they
do nothing until they are run. The most common way to run a ~Future~ is to
~.await~ it. When ~.await~ is called on a ~Future~, it will attempt to run it to
completion. If the ~Future~ is blocked, it will yield control of the current
thread. When more progress can be made, the ~Future~ will be picked up by the
executor and will resume running, allowing the ~.await~ to resolve.

** ~async~ Lifetimes

Unlike traditional functions, ~async fn~s which take references or other
non-~'static~ arguments return a ~Future~ which is bounded by the lifetime of
the arguments:

#+BEGIN_SRC rust :noeval
// This function:
async fn foo(x: &u8) -> u8 { *x }

// Is equivalent to this function:
fn foo_expanded<'a>(x: &'a u8) -> impl Future<Output = u8> + 'a {
    async move { *x }
}
#+END_SRC

This means that the future returned from an ~async fn~ must be ~.awaited~ while
its non-~'static~ arguments are still valid. In the common case of ~.await~ing
the future immediately after calling the function (as in ~foo(&x).await~) this
is not an issue. However, if storing the future or sending it over to another
task or thread, this may be an issue.

One common workaround for turning an ~async fn~ with references-as-arguments
into a ~'static~ future is to bundle the arguments with the call to the
~async fn~ inside an ~async~ block:

#+BEGIN_SRC rust :noeval
fn bad() -> impl Future<Output = u8> {
    let x = 5;
    borrow_x(&x) // ERROR: `x` does not live long enough
}

fn good() -> impl Future<Output = u8> {
    async {
        let x = 5;
        borrow_x(&x).await
    }
}
#+END_SRC

By moving the argument into the ~async~ block, we extend its lifetime to match
that of the ~Future~ returned from the call to ~good~.

** ~async move~

~async~ blocks and closures allow the ~move~ keyword, much like normal closures.
An ~async move~ block will take ownership of the variables it references,
allowing it to outlive the current scope, but giving up the ability to share
those variables with other code:

#+BEGIN_SRC rust :noeval
/// `async` block:
///
/// Multiple different `async` blocks can access the same local variable
/// so long as they're executed within the variable's scope
async fn blocks() {
    let my_string = "foo".to_string();

    let future_one = async {
        // ...
        println!("{my_string}");
    };

    let future_two = async {
        // ...
        println!("{my_string}");
    };

    // Run both futures to completion, printing "foo" twice:
    let ((), ()) = futures::join!(future_one, future_two);
}

/// `async move` block:
///
/// Only one `async move` block can access the same captured variable, since
/// captures are moved into the `Future` generated by the `async move` block.
/// However, this allows the `Future` to outlive the original scope of the
/// variable:
fn move_block() -> impl Future<Output = ()> {
    let my_string = "foo".to_string();
    async move {
        // ...
        println!("{my_string}");
    }
}
#+END_SRC

** ~.await~ing on a Multithreaded Executor

Note that, when using a multithreaded ~Future~ executor, a ~Future~ may move
between threads, so any variables used in ~async~ bodies must be able to travel
between threads, as any ~.await~ can potentially result in a switch to a new
thread.

This means that it is not safe to use ~Rc~, ~&RefCell~ or any other types that
don't implement the ~Send~ trait, including references to types that don't
implement the ~Sync~ trait.

(Caveat: it is possible to use these types as long as they aren't in scope
during a call to ~.await~.)

Similarly, it isn't a good idea to hold a traditional non-futures-aware lock
across an ~.await~, as it can cause the threadpool to lock up: one task could
take out a lock, ~.await~ and yield to the executor, allowing another task to
attempt to take the lock and cause a deadlock. To avoid this, use the ~Mutex~
in ~futures::lock~ rather than the one from ~std::sync~.

* The ~Stream~ Trait

The ~Stream~ trait is similar to ~Future~ but can yield multiple values before
completing, similar to the ~Iterator~ trait from the standard library:

#+BEGIN_SRC rust :noeval
trait Stream {
    /// The type of the value yielded by the stream.
    type Item;

    /// Attempt to resolve the next item in the stream.
    /// Returns `Poll::Pending` if not ready, `Poll::Ready(Some(x))` if a value
    /// is ready, and `Poll::Ready(None)` if the stream has completed.
    fn poll_next(self: Pin<&mut Self>, cx: &mut Context<'_>)
        -> Poll<Option<Self::Item>>;
}
#+END_SRC

One common example of a ~Stream~ is the ~Receiver~ for the channel type from the
~futures~ crate. It will yield ~Some(val)~ every time a value is sent from the
~Sender~ end, and will yield ~None~ once the ~Sender~ has been dropped and all
pending messages have been received:

#+BEGIN_SRC rust :noeval
async fn send_recv() {
    const BUFFER_SIZE: usize = 10;
    let (mut tx, mut rx) = mpsc::channel::<i32>(BUFFER_SIZE);

    tx.send(1).await.unwrap();
    tx.send(2).await.unwrap();
    drop(tx);

    // `StreamExt::next` is similar to `Iterator::next`, but returns a
    // type that implements `Future<Output = Option<T>>`.
    assert_eq!(Some(1), rx.next().await);
    assert_eq!(Some(2), rx.next().await);
    assert_eq!(None, rx.next().await);
}
#+END_SRC

** Iteration and Concurrency

Similar to synchronous ~Iterator~s, there are many different ways to iterate
over and process the values in a ~Stream~. There are combinator-style methods
such as ~map~, ~filter~, and ~fold~, and their early-exit-on-error cousins
~try_map~, ~try_filter~, and ~try_fold~.

Unfortunately, ~for~ loops are not usable with ~Stream~s, but for
imperative-style code, ~while let~ and the ~next~ / ~try_next~ functions can be
used:

#+BEGIN_SRC rust :noeval
async fn sum_with_next(mut stream: Pin<&mut dyn Stream<Item = i32>>) -> i32 {
    use futures::stream::StreamExt; // for `next`
    let mut sum = 0;
    while let Some(item) = stream.next().await {
        sum += item;
    }
    sum
}

async fn sum_with_try_next(
    mut stream: Pin<&mut dyn Stream<Item = Result<i32, io::Error>>>,
) -> Result<i32, io::Error> {
    use futures::stream::TryStreamExt; // for `try_next`
    let mut sum = 0;
    while let Some(item) = stream.try_next().await? {
        sum += item;
    }
    Ok(sum)
}
#+END_SRC

However, if we're just processing one element at a time, we're potentially
leaving behind opportunity for concurrency, which is, after all, why we're
writing async code in the first place. To process multiple items from a stream
concurrently, use the ~for_each_concurrent~ and ~try_for_each_concurrent~
methods:

#+BEGIN_SRC rust
async fn jump_around(
    mut stream: Pin<&mut dyn Stream<Item = Result<u8, io::Error>>>,
) -> Result<(), io::Error> {
    use futures::stream::TryStreamExt; // for `try_for_each_concurrent`
    const MAX_CONCURRENT_JUMPERS: usize = 100;

    stream.try_for_each_concurrent(MAX_CONCURRENT_JUMPERS, |num| async move {
        jump_n_times(num).await?;
        report_n_jumps(num).await?;
        Ok(())
    }).await?;

    Ok(())
}
#+END_SRC

* Executing Multiple Futures at a Time

Up until now, we've mostly executed futures by using ~.await~, which blocks the
current task until a particular ~Future~ completes. However, real asynchronous
applications often need to execute several different operations concurrently.


- ~join!~: waits for futures to all complete
- ~select!~: waits for one of several futures to complete
- Spawning: creates a top-level task which ambiently runs a future to completion
- ~FuturesUnordered~: a group of futures which yields the result of each
  subfuture (not described yet)
