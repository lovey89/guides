* Table of Contents :TOC:QUOTE:
#+BEGIN_QUOTE
- [[#links][Links]]
- [[#install][Install]]
- [[#getting-started][Getting started]]
  - [[#build-infrastructure][Build infrastructure]]
  - [[#change-infrastructure][Change infrastructure]]
  - [[#destroy-infrastructure][Destroy infrastructure]]
  - [[#define-input-variables][Define input variables]]
  - [[#query-data-with-outputs][Query data with outputs]]
- [[#the-command-line-interface][The Command Line Interface]]
  - [[#initialize-terraform-configuration][Initialize Terraform configuration]]
  - [[#create-a-terraform-plan][Create a Terraform plan]]
  - [[#apply-terraform-configuration][Apply Terraform configuration]]
  - [[#customize-terraform-configuration-with-variables][Customize Terraform configuration with variables]]
  - [[#output-data-from-terraform][Output data from Terraform]]
  - [[#manage-terraform-versions][Manage Terraform versions]]
  - [[#lock-and-upgrade-provider-versions][Lock and upgrade provider versions]]
  - [[#target-resources][Target resources]]
  - [[#manage-resource-state][Manage resource state]]
  - [[#import][Import]]
  - [[#use-refresh-only-mode-to-sync-terraform-state][Use refresh-only mode to sync Terraform state]]
- [[#write-terraform-configuration][Write Terraform Configuration]]
  - [[#define-infrastructure-with-terraform-resources][Define infrastructure with Terraform resources]]
  - [[#protect-sensitive-input-variables][Protect sensitive input variables]]
  - [[#simplify-terraform-configuration-with-locals][Simplify Terraform configuration with locals]]
  - [[#query-data-sources][Query data sources]]
  - [[#create-resource-dependencies][Create resource dependencies]]
  - [[#manage-similar-resources-with-count][Manage similar resources with ~count~]]
  - [[#manage-similar-resources-with-for_each][Manage similar resources with ~for_each~]]
  - [[#perform-dynamic-operations-with-functions][Perform dynamic operations with functions]]
  - [[#create-dynamic-expressions][Create dynamic expressions]]
  - [[#use-checks-to-validate-infrastructure][Use checks to validate infrastructure]]
- [[#reuse-configuration-with-modules][Reuse Configuration with Modules]]
  - [[#modules-overview][Modules overview]]
  - [[#use-registry-modules-in-configuration][Use registry modules in configuration]]
  - [[#build-and-use-a-local-module][Build and use a local module]]
  - [[#customize-modules-with-object-attributes][Customize modules with object attributes]]
  - [[#handle-multiple-environments][Handle multiple environments]]
  - [[#use-configuration-to-move-resources][Use configuration to move resources]]
  - [[#validate-modules-with-custom-conditions][Validate modules with custom conditions]]
#+END_QUOTE

* Links

- https://developer.hashicorp.com/terraform/tutorials

* Install

#+BEGIN_SRC bash :noeval
sudo dnf install -y dnf-plugins-core
sudo dnf config-manager --add-repo https://rpm.releases.hashicorp.com/fedora/hashicorp.repo
sudo dnf -y install terraform

# Verify
terraform -help # Current version is v1.9.4

# Enable auto complete
terraform -install-autocomplete
#+END_SRC

* Getting started
** Build infrastructure

With Terraform, you can provision an NGINX server in less than a minute using
Docker.

We have already created the project in [[file:001_learn-terraform-docker-container][001_learn-terraform-docker-container]].
This working directory houses the configuration files that you write to describe
the infrastructure you want Terraform to create and manage. When you initialize
and apply the configuration here, Terraform uses this directory to store
required plugins, modules (pre-written configurations), and information about
the real infrastructure it created.

Navigate to [[file:001_learn-terraform-docker-container][001_learn-terraform-docker-container]] and initialize the project
which downloads a plugin called provider that lets Terraform interact with
Docker.

#+BEGIN_SRC bash :noeval
terraform init
#+END_SRC

Provision the NGINX server with ~apply~:

#+BEGIN_SRC bash :noeval
terraform apply
#+END_SRC

Verify that the container is created with the ~docker ps~ command and open a web
browser and navigate to http://localhost:8000.

Stop the container with ~terraform destroy~.

*** Review the configuration

The set of files used to describe infrastructure in Terraform is known as a
/Terraform configuration/. Each configuration must be in its own working
directory. This is a complete configuration that you can deploy with Terraform.

**** ~terraform~ Block

The ~terraform {}~ block contains Terraform settings, including the required
providers Terraform will use to provision your infrastructure. For each
provider, the ~source~ attribute defines an optional hostname, a namespace, and
the provider type. Terraform installs providers from the [[https://registry.terraform.io/][Terraform Registry]] by
default. In this example configuration, the ~docker~ provider's source is
defined as ~kreuzwerker/docker~, which is shorthand for
~registry.terraform.io/kreuzwerker/docker~.

You can also set a version constraint for each provider defined in the
~required_providers~ block. The ~version~ attribute is optional, but
recommended. If no version is specified the most recent version will be
downloaded.

Docs: https://developer.hashicorp.com/terraform/language/providers/requirements

**** ~provider~ Block

The ~provider~ block configures the specified provider, in this case ~docker~. A
provider is a plugin that Terraform uses to create and manage your resources.

You can use multiple provider blocks in your Terraform configuration to manage
resources from different providers. You can even use different providers
together. For example, you could pass the Docker image ID to a Kubernetes
service.

**** ~resource~ Blocks

Use ~resource~ blocks to define components of your infrastructure. A resource
might be a physical or virtual component such as a Docker container, or it can
be a logical resource such as a Heroku application.

Resource blocks have two strings before the block: the resource type and the
resource name. In this example, the first resource type is ~docker_image~ and
the name is ~nginx~. The prefix of the type maps to the name of the provider. In
the example configuration, Terraform manages the ~docker_image~ resource with
the ~docker~ provider. Together, the resource type and resource name form a
unique ID for the resource. For example, the ID for your Docker image is
~docker_image.nginx~.

Resource blocks contain arguments which you use to configure the resource.
Arguments can include things like machine sizes, disk image names, or VPC IDs.
The [[https://developer.hashicorp.com/terraform/language/providers][providers reference]] documents the required and optional arguments for each
resource. For your container, the example configuration sets the Docker image as
the image source for your ~docker_container~ resource.

*** Initialize the directory

When you create a new configuration — or check out an existing configuration
from version control — you need to initialize the directory with ~terraform init~.

Initializing a configuration directory downloads and installs the providers
defined in the configuration, which in this case is the ~docker~ provider.

Terraform downloads the ~docker~ provider and installs it in a hidden
subdirectory of your current working directory, named ~.terraform~. The
~terraform init~ command prints out which version of the provider was installed.
Terraform also creates a lock file named ~.terraform.lock.hcl~ which specifies
the exact provider versions used, so that you can control when you want to
update the providers used for your project.

*** Format and validate the configuration

The ~terraform fmt~ command automatically updates configurations in the current
directory for readability and consistency.

When you run ~terraform fmt~, Terraform will print out the names of the files it
modified, if any.

You can also make sure your configuration is syntactically valid and internally
consistent by using the ~terraform validate~ command.

No extra arguments needs to be added to either ~terraform fmt~ or
~terraform validate~.

*** Create infrastructure

Apply the configuration now with the ~terraform apply~ command. Before it
applies any changes, Terraform prints out the execution plan which describes the
actions Terraform will take in order to change your infrastructure to match the
configuration.

Terraform will now pause and wait for your approval before proceeding. If
anything in the plan seems incorrect or dangerous, it is safe to abort here with
no changes made to your infrastructure. In this case the plan is acceptable, so
type ~yes~ at the confirmation prompt to proceed.

*** Inspect state

When you applied your configuration, Terraform wrote data into a file called
~terraform.tfstate~. Terraform stores the IDs and properties of the resources it
manages in this file, so that it can update or destroy those resources going
forward.

The Terraform state file is the only way Terraform can track which resources it
manages, and often contains sensitive information, so you must store your state
file securely and restrict access to only trusted team members who need to
manage your infrastructure. Terraform supports several [[https://developer.hashicorp.com/terraform/language/settings/backends/configuration][remote backends]] you can
use to store and manage your state.

Inspect the current state using ~terraform show~.

*** Manually Managing State

Terraform has a built-in command called ~terraform state~ for advanced state
management. Use the ~list~ subcommand to list of the resources in your project's
state.

#+BEGIN_SRC bash :noeval
terraform state list
#+END_SRC

** Change infrastructure

Infrastructure is continuously evolving, and Terraform helps you manage that
change. As you change Terraform configurations, Terraform builds an execution
plan that only modifies what is necessary to reach your desired state.

*** Update configuration

Now update the external port number of your container. Change the
~docker_container.nginx~ resource under the provider block in
[[file:001_learn-terraform-docker-container/main.tf][001_learn-terraform-docker-container/main.tf]] by replacing the ~ports.external~
value of ~8000~ with ~8080~.

*** Apply changes

This update changes the port number your container uses to serve your nginx
server. The Docker provider knows that it cannot change the port of a container
after it has been created, so Terraform will destroy the old container and
create a new one.

Run ~terraform apply~ again to see how Terraform will apply this change to the
existing resources.

The prefix ~-/+~ means that Terraform will destroy and recreate the resource,
rather than updating it in-place. Terraform can update some attributes in-place
(indicated with the ~~~ prefix), but changing the port for a Docker container
requires recreating it. Terraform handles these details for you, and the
execution plan displays what Terraform will do.

The output will also reveal what forces Terraform to replace the container by
displaying ~# forces replacement~ next to the field(s) that caused it.

** Destroy infrastructure

The ~terraform destroy~ command terminates resources managed by your Terraform
project. This command is the inverse of ~terraform apply~ in that it terminates
all the resources specified in your Terraform state. It does not destroy
resources running elsewhere that are not managed by the current Terraform
project.

The ~-~ prefix indicates that the container will be destroyed. As with apply,
Terraform shows its execution plan and waits for approval before making any
changes. In more complicated cases with multiple resources, Terraform will
destroy them in a suitable order to respect dependencies.

** Define input variables

Terraform configurations can include variables to make your configuration more
dynamic and flexible.

A project has already been setup at [[file:002_docker-container-with-variable][002_docker-container-with-variable]] which is
very similar to [[file:001_learn-terraform-docker-container][001_learn-terraform-docker-container]]. The differences are
explained below.

*** Set the container name with a variable

The current configuration includes a number of hard-coded values. Terraform
variables allow you to write configuration that is flexible and easier to
re-use.

Create a new file called ~variables.tf~ with a block defining a new
~container_name~ variable.

#+BEGIN_SRC hcl
variable "container_name" {
  description = "Value of the name for the Docker container"
  type        = string
  default     = "ExampleNginxContainer"
}
#+END_SRC

The name of the files are not important. Terraform loads all files in the
current directory ending in ~.tf~, so you can name your configuration files
however you choose.

In ~main.tf~, we have updated the ~docker_container~ resource block to use the
new variable by specifying ~name = var.container_name~. The ~container_name~
variable block will default to its default value unless you declare a different
value.

*** Apply your configuration

You can now apply your change with the default value with ~terraform apply~ or
override the value with the ~-var~ option.

Try both and see how terraform updates the state:

#+BEGIN_SRC bash :noeval
terraform apply
terraform apply -var "container_name=YetAnotherName"
#+END_SRC

For more about variables see:
https://developer.hashicorp.com/terraform/tutorials/configuration-language/variables

** Query data with outputs

We can use output values to organize data to be easily queried and displayed to
the Terraform user.

We continue with the [[file:002_docker-container-with-variable][002_docker-container-with-variable]] example:

*** Output Docker container configuration

We have also added a file [[file:002_docker-container-with-variable/outputs.tf][002_docker-container-with-variable/outputs.tf]].

*** Inspect output values

You must apply this configuration before you can use these output values. Apply
your configuration now. Terraform prints output values to the screen when you
apply your configuration. You can also query the outputs with the
~terraform output~ command.

You can use Terraform outputs to connect your Terraform projects with other
parts of your infrastructure, or with other Terraform projects. To learn more,
see: https://developer.hashicorp.com/terraform/tutorials/configuration-language/outputs

* The Command Line Interface
** Initialize Terraform configuration

The core Terraform workflow consists of three main steps after you have written
your Terraform configuration:

- *Initialize* prepares your workspace so Terraform can apply your
  configuration.
- *Plan* allows you to preview the changes Terraform will make before you apply
  them.
- *Apply* makes the changes defined by your plan to create, update, or destroy
  resources.

When you initialize a Terraform workspace, Terraform configures the backend,
installs all providers and modules referred to in your configuration, and
creates a version lock file if one doesn't already exist. In addition, you can
use the terraform init command to change your workspace's backend and upgrade
your workspace's providers and modules.

*** Initialize your workspace

#+BEGIN_SRC bash :noeval
terraform init
#+END_SRC

When you initialize a workspace, Terraform will attempt to download the provider
versions specified by the workspace's lock file. If the lock file does not
exist, Terraform will use the ~required_providers~ block to determine the
provider version and create a new lock file. If neither exists, Terraform will
search for a matching provider and download the latest version.

The lock file ~.terraform.lock.hcl~ should be commited to your repository to
ensure that the same provider versions are used across the team.

*** When to initialize Terraform

You initialize your Terraform workspace with terraform init when:

- You create new Terraform configuration and are ready to use it to create a
  workspace and provision infrastructure.
- You clone a version control repository containing Terraform configuration, and
  are ready to use it to create a workspace and provision infrastructure.
- You add, remove, or change the version of a module or provider in an existing
  workspace.
- You add, remove, or change the backend or cloud blocks within the terraform
  block of an existing workspace.

** Create a Terraform plan

When you provision infrastructure, Terraform creates an execution plan before it
applies any changes. Terraform creates the plan by comparing your Terraform
configuration to the state of your infrastructure. The execution plan consists
of a set of changes that create, update, or destroy resources. You can use the
~terraform plan~ command to compare your configuration to your resource's state,
review changes before you apply them, or to refresh your workspace's state.
Terraform plan supports automation workflows in CI/CD pipelines by guaranteeing
that the infrastructure changes Terraform applies match the ones you or your
team approve, even if the deploy process completes across different machines or
at different times.

*** Create a plan

There are three commands that tell Terraform to generate an execution plan:

- The ~terraform plan~ command creates a plan consisting of a set of changes
  that will make your resources match your configuration. This lets you preview
  the actions Terraform would take to modify your infrastructure before applying
  them. Terraform plan does not make any changes to your resources, you must
  apply a plan for Terraform to make changes.

  You can also save a plan with the ~-out~ flag. Later, you can apply the saved
  plan, and Terraform will only perform the changes listed in the plan. In an
  automated Terraform pipeline, applying a saved plan file ensures that
  Terraform only makes the changes you expect, even if your pipeline runs across
  multiple machines at different times.

- The ~terraform apply~ command applies a Terraform plan. If you do not pass a
  saved plan, then Terraform will a create a plan and prompt you for approval
  before applying the plan.

- The ~terraform destroy~ command creates an execution plan to delete all of the
  resources managed by your workspace.

Generate a plan:

#+BEGIN_SRC bash :noeval
terraform plan -out "tfplan"
#+END_SRC

The file ~tfplan~ is not in human readable format but you can inspect it with:

#+BEGIN_SRC bash :noeval
terraform show "tfplan"
#+END_SRC

You can also convert the code to json to easily inspect it with code:

#+BEGIN_SRC bash :noeval
terraform show -json "tfplan" | jq > tfplan.json
#+END_SRC

*Note:* Terraform plan files can contain sensitive data. Never commit a plan
file to version control.

*** Apply a saved plan

#+BEGIN_SRC bash :noeval
terraform apply "tfplan"
#+END_SRC

** Apply Terraform configuration

When you apply changes to your infrastructure, Terraform uses the providers and
modules installed during initialization to execute the steps stored in an
execution plan. These steps create, update, and delete infrastructure to match
your resource configuration.

*** Apply configuration

Apply the configuration with:

#+BEGIN_SRC bash :noeval
terraform apply
#+END_SRC

When you approve the plan and apply this configuration, Terraform will:

1. Lock your workspace's state, so that no other instances of Terraform will
   attempt to modify your state or apply changes to your resources. If Terraform
   detects an existing lock file (~.terraform.tfstate.lock.info~), it will
   report an error and exit.
2. Create a plan, and wait for you to approve it. Alternatively, you can provide
   a saved plan created with the ~terraform plan~ command, in which case
   Terraform will not prompt for approval.
3. Execute the steps defined in the plan using the providers you installed when
   you initialized your configuration. Terraform executes steps in parallel when
   possible, and sequentially when one resource depends on another.
4. Update your workspace's state with a snapshot of the new state of your
   resources.
5. Unlock your workspace's state.
6. Report the changes it made, as well as any output values defined in your
   configuration.

*** Errors during apply

When Terraform encounters an error during an apply step, it will:

1. Log the error and report it to the console.
2. Update the state file with any changes to your resources.
3. Unlock the state file.
4. Exit.

Your infrastructure may be in an invalid state after a Terraform apply step
errors out. Terraform does not support automatically rolling back a
partially-completed apply. After you resolve the error, you must apply your
configuration again to update your infrastructure to the desired state.

If the state has changed between the time you have created a plan and the time
you apply it since Terraform assumes as certain state.

Common reasons for apply errors include:

1. A change to a resource outside of Terraform's control.
2. Networking or other transient errors.
3. An expected error from the upstream API, such as a duplicate resource name or
   reaching a resource limit.
4. An unexpected error from the upstream API, such as an internal server error.
5. A bug in the Terraform provider code, or Terraform itself.

Depending on the cause of the error, you may need to resolve the underlying
issue by either modifying your configuration or diagnosing and resolving the
error from the cloud provider API. You can use the ~terraform show~ command to
print out your state. This command does not refresh your state, so the
information in your state can be out of date.

The next time you plan a change to this project, Terraform will update the
current state of your resources from the underlying APIs using the providers you
have installed. At this point Terraform may know how to fix the problem itself.

*** Replace Resources

When using Terraform, you will usually apply an entire configuration change at
once. Terraform and its providers will determine the changes to make and the
order to make them in. However, there are some cases where you may need to
replace or modify individual resources. Terraform provides two arguments to the
~plan~ and ~apply~ commands that allow you to interact with specific resources:
~-replace~ and ~-target~.

Use the ~-replace~ argument when a resource has become unhealthy or stops
working in ways that are outside of Terraform's control.

The ~-replace~ argument requires a resource address. List the resources in your
configuration with ~terraform state list~.

Use the ~-target~ command line argument when you apply to target individual
resources rather than apply the entire configuration.

** Customize Terraform configuration with variables

Terraform's input variables don't change values during a Terraform run such as
plan, apply, or destroy. Instead, they allow users to more safely customize
their infrastructure by assigning different values to the variables before
execution begins, rather than editing configuration files manually.

*** Parameterize your configuration

Variable declarations can appear anywhere in your configuration files. However,
it's recommended to put them into a separate file called ~variables.tf~ to make
it easier for users to understand how they can customize the configuration.

To parameterize an argument with an input variable, you must first define the
variable, then replace the hardcoded value with a reference to that variable in
your configuration. E.g.

#+BEGIN_SRC hcl
variable "aws_region" {
  description = "AWS region"
  type        = string
  default     = "us-west-2"
}
#+END_SRC

The fields are:

- ~Description~: A short description to document the purpose of the variable.
- ~Type~: The type of data contained in the variable.
- ~Default~: The default value.

If you do not set a default value for a variable, you must assign a value before
Terraform can apply the configuration. Terraform does not support unassigned
variables.

Variable values must be literal values, and cannot use computed values like
resource attributes, expressions, or other variables. You can refer to variables
in your configuration with ~var.<variable_name>~.

*** Types of variables
**** Simple types

Apart from the ~string~ type there is also a ~number~ and ~bool~ type. These are
called /simple/ types.

When Terraform interprets values, either hard-coded or from variables, it will
convert them into the correct type if possible. So you can supply ~"2"~ instead
of ~2~ and it will work as well.

~bool~ can have the values ~true~ / ~false~.

**** Complex type

Terraform also supports several collection variable types.

- *List*: A sequence of values of the same type.
- *Map*: A lookup table, matching keys to values, all of the same type.
- *Set*: An unordered collection of unique values, all of the same type.

***** ~list~

The type of a ~list~ is given with it's type. E.g. ~list(string)~. But they can
also consit of complex types. E.g. ~list(list)~. Here's an example of a list:

#+BEGIN_SRC hcl
variable "private_subnet_cidr_blocks" {
  description = "Available cidr blocks for private subnets."
  type        = list(string)
  default     = [
    "10.0.101.0/24",
    "10.0.102.0/24",
    "10.0.103.0/24",
    "10.0.104.0/24",
  ]
}
#+END_SRC

You can retrieve elements in a list by index. Retrieve the second element from a
list by index with square brackets: ~var.private_subnet_cidr_blocks[1]~.

To get a slice you use the ~slice()~ function. E.g.:
~slice(var.private_subnet_cidr_blocks, 0, 3)~ will get element 0, 1 and 2 from
the list.

***** ~map~

An example of a map looks like this:

#+BEGIN_SRC hcl
variable "resource_tags" {
  description = "Tags to set for all resources"
  type        = map(string)
  default     = {
    project     = "project-alpha",
    environment = "dev"
  }
}
#+END_SRC

Setting the type to ~map(string)~ tells Terraform to expect strings for the
values in the map. Map keys are always strings.

To retrieve the value of the ~environment~ key from the ~resource_tags~ map:
~var.resource_tags["environment"]~.

You can also replace a full block with a map. E.g.

#+BEGIN_SRC hcl
tags = {
  project     = "project-alpha",
  environment = "dev"
}
#+END_SRC

can be replaced with:

#+BEGIN_SRC hcl
tags = var.resource_tags
#+END_SRC

*** Assign values to variables

Terraform requires a value for every variable. There are several ways to assign
variable values.

**** Use command line flag

You can use ~-var~ to set a variable. E.g.

#+BEGIN_SRC bash :noeval
terraform apply -var ec2_instance_type=t2.micro
# or
terraform plan -var ec2_instance_type=t2.micro
#+END_SRC

**** Assign values with a file

Terraform automatically loads all files in the current directory with the exact
name ~terraform.tfvars~ or matching ~*.auto.tfvars~. You can also use the
~-var-file~ flag to specify other files by name.

These files use syntax similar to Terraform configuration files (HCL), but they
cannot contain configuration such as resource definitions. Like Terraform
configuration files, these files can also contain JSON.

In addition to command line flags and variable files, you can use environment
variables to set input variables.

*** Interpolate variables in strings

Terraform configuration supports string interpolation - inserting the output of
an expression into a string. This allows you to use variables, local values, and
the output of functions to create strings in your configuration. You use the
~${variable}~ syntax.

E.g.

#+BEGIN_SRC hcl
resource "docker_container" "nginx" {
  image = docker_image.nginx.image_id
  name  = "Container_${var.container_name}"

  ports {
    internal = 80
    external = 8080
  }
}
#+END_SRC

*** Validate variables

You can also validate that the provided variables follow a certain format.

#+BEGIN_SRC hcl
variable "resource_tags" {
  description = "Tags to set for all resources"
  type        = map(string)
  default     = {
    project     = "my-project",
    environment = "dev"
  }

  validation {
    condition     = length(var.resource_tags["project"]) <= 16 && length(regexall("[^a-zA-Z0-9-]", var.resource_tags["project"])) == 0
    error_message = "The project tag must be no more than 16 characters, and only contain letters, numbers, and hyphens."
  }

  validation {
    condition     = length(var.resource_tags["environment"]) <= 8 && length(regexall("[^a-zA-Z0-9-]", var.resource_tags["environment"])) == 0
    error_message = "The environment tag must be no more than 8 characters, and only contain letters, numbers, and hyphens."
  }
}
#+END_SRC

Using variable validation can be a good way to catch configuration errors early.

** Output data from Terraform

Terraform output values let you export structured data about your resources. You
can use this data to configure other parts of your infrastructure with
automation tools, or as a data source for another Terraform workspace. Outputs
are also how you expose data from a child module to a root module.

*** Output information

You can add output declarations anywhere in your Terraform configuration files.
However, it's recommended to put them in a separate file called ~outputs.tf~ to
make it easier for users to understand your configuration and review its
expected outputs. E.g.:

#+BEGIN_SRC hcl
output "container_id" {
  description = "ID of the Docker container"
  value       = docker_container.nginx.id
}

output "image_id" {
  description = "ID of the Docker image"
  value       = docker_image.nginx.id
}
#+END_SRC

While the ~description~ argument is optional, you should include it in all
output declarations to document the intent and content of the output.

You can use the result of any Terraform expression as the value of an output.
Add the following definitions to ~outputs.tf~. E.g.

#+BEGIN_SRC hcl
output "lb_url" {
  description = "URL of load balancer"
  value       = "http://${module.elb_http.elb_dns_name}/"
}

output "web_server_count" {
  description = "Number of web servers provisioned"
  value       = length(module.ec2_instances.instance_ids)
}
#+END_SRC

 In order to see these outputs, you need to update the state by applying this
 new configuration, even though the infrastructure will not change.

*** Query outputs

After creating the outputs, use the ~terraform output~ command to query all of
them. You can also query output by name with ~terraform output <name>~.

By default Terraform wraps string outputs in quotes. You can disable that with
the ~-raw~ flag. E.g. ~terraform output -raw container_id~

*** Redact sensitive outputs

You can designate Terraform outputs as sensitive. Terraform will redact the
values of sensitive outputs to avoid accidentally printing them out to the
console. Use sensitive outputs to share sensitive data from your configuration
with other Terraform modules, automation tools, or HCP Terraform workspaces.

Terraform will redact sensitive outputs when planning, applying, or destroying
your configuration, or when you query all of your outputs. Terraform will not
redact sensitive outputs in other cases, such as when you query a specific
output by name, query all of your outputs in JSON format, or when you use
outputs from a child module in your root module.

E.g.

#+BEGIN_SRC hcl
output "db_password" {
  description = "Database administrator password"
  value       = aws_db_instance.database.password
  sensitive   = true
}
#+END_SRC

*** Generate machine-readable output

To get machine-readable format for automation, use the ~-json~ flag:

#+BEGIN_SRC bash :noeval
terraform output -json
#+END_SRC

*** Maps and lists

When you include the ~-json~ flag in your Terraform output commands, Terraform
converts maps and lists to the equivalent JSON data structures. E.g.

#+BEGIN_SRC tf
output "bucket_details" {
  description = "S3 bucket details."
  value = {
    arn    = aws_s3_bucket.data.arn,
    region = aws_s3_bucket.data.region,
    id     = aws_s3_bucket.data.id
  }
}
#+END_SRC

** Manage Terraform versions
*** Terraform version constraints

The following table summarizes some of the ways you can pin the Terraform
version in the ~required_version~ setting in the ~terraform {}~ block:

| Required Version    | Meaning                                           | Considerations                                          |
|---------------------+---------------------------------------------------+---------------------------------------------------------|
| ~1.7.5~             | Only Terraform v1.7.5 exactly                     |                                                         |
| ~>= 1.7.5~          | Any Terraform v1.7.5 or greater                   | Includes Terraform v2.0.0 and above                     |
| ~~> 1.7.5~          | Any Terraform v1.7.x, but not v1.8 or later       | Minor version updates are intended to be non-disruptive |
| ~>= 1.7.5, < 1.9.5~ | Terraform v1.7.5 or greater, but less than v1.9.5 |                                                         |

As a best practice, consider using ~~>~ style version constraints to pin your
major and minor Terraform version. Doing so will allow you and your team to use
patch version updates without updating your Terraform configuration. You can
then plan when you want to upgrade your configuration to use a new version of
Terraform, and carefully review the changes to ensure that your project still
works as intended.

** Lock and upgrade provider versions

Terraform providers manage resources by communicating between Terraform and
target APIs. Whenever the target APIs change or add functionality, provider
maintainers may update and version the provider.

If you do not scope provider version appropriately, Terraform will download the
latest provider version that fulfills the version constraint. This may lead to
unexpected infrastructure changes. By specifying carefully scoped provider
versions and using the dependency lock file, you can ensure Terraform is using
the correct provider version so your configuration is applied consistently.

The provider versions downloaded when running ~terraform init~ will be written
to ~.terraform.lock.hcl~ if it doesn't exists. Otherwise the exact version
written in the lock file will be downloaded. If the lock file is not found it
will download the latest version of the providers that you have defined in the
~required_providers {}~ block.

*** Upgrade the provider version

The ~-upgrade~ flag will upgrade all providers to the latest version consistent
within the version constraints specified in your configuration.

#+BEGIN_SRC bash :noeval
terraform init -upgrade
#+END_SRC

It can also be used for downgrading if the version constrants are modified to
a lower provider version.

Always run a Terraform plan after changing your provider versions. Occasionally
a provider upgrade will require that you to modify your configuration to work
with the new provider version. If the plan or apply steps fail, do not commit
the lock file to version control until you've resolved the error.

** Target resources

When you apply changes to your Terraform projects, Terraform generates a plan
that includes all of the differences between your configuration and the
resources currently managed by your project, if any. When you apply the plan,
Terraform will add, remove, and modify resources as proposed by the plan.

In a typical Terraform workflow, you apply the entire plan at once. Occasionally
you may want to apply only part of a plan, such as when Terraform's state has
become out of sync with your resources due to a network failure, a problem with
the upstream cloud platform, or a bug in Terraform or its providers. To support
this, Terraform lets you target specific resources when you plan, apply, or
destroy your infrastructure. Targeting individual resources can be useful for
troubleshooting errors, but should not be part of your normal workflow.

You can use Terraform's ~-target~ option to target specific resources, modules,
or collections of resources.

*** Try it out

Use project [[file:003_learn-terraform-plan][003_learn-terraform-plan]]:

#+BEGIN_SRC bash :noeval
terraform init
terraform apply
#+END_SRC

Update the ~random_pet~ config:

#+BEGIN_SRC diff
 resource "random_pet" "instance" {
-  length    = 2
+  length    = 5
 }
#+END_SRC

Plan the change:

#+BEGIN_SRC bash :noeval
terraform plan
#+END_SRC

Terraform plans to change the ~random_pet~ resource along with any resources
dependent on it.

Now target only ~random_pet.instance~:

#+BEGIN_SRC bash :noeval
terraform plan -target=random_pet.instance
#+END_SRC

Now only ~random_pet.instance~ will be updated. Try targeting
~docker_container.nginx~ instead:

#+BEGIN_SRC bash :noeval
terraform plan -target=docker_container.nginx
#+END_SRC

Terraform determines that ~docker_container.nginx~ depends on
~random_pet.instance~, and that the instance name configuration has changed.
Because of this dependency, Terraform will update both. Resource targeting
updates resources that the target depends on, but not resources that depend on
it.

You can also provide ~-target~ multiple times.

** Manage resource state

Terraform stores information about your infrastructure in a state file. This
state file keeps track of resources created by your configuration and maps them
to real-world resources.

Terraform compares your configuration with the state file and your existing
infrastructure to create plans and make changes to your infrastructure. When you
run ~terraform apply~ or ~terraform destroy~ against your initialized
configuration, Terraform writes metadata about your configuration to the state
file and updates your infrastructure resources accordingly. Occasionally, you
may need to manipulate your projects state outside of the standard workflow. For
example, you may want to remove a resource from your project without destroying
the real-world resource associated with it.

*** Move a resource to a different state file

You can move a state to a different state file with ~terraform state mv~

*** Remove a resource from state

Use a ~removed~ block to remove specific resources from your state. This does
not destroy the infrastructure itself, instead it indicates that your Terraform
configuration will no longer manage the resource.

Comment out the block of the resource that you don't want Terraform to manage
anylonger and add a ~removed~ block:

#+BEGIN_SRC tf
removed {
  from = aws_instance.example_new

  lifecycle {
    destroy = false
  }
}

# resource "aws_instance" "example_new" {
#   ami                    = data.aws_ami.ubuntu.id
#   instance_type          = "t2.micro"
#   vpc_security_group_ids = [aws_security_group.sg_8080.id]
#   user_data              = <<-EOF
#               #!/bin/bash
#               apt-get update
#               apt-get install -y apache2
#               sed -i -e 's/80/8080/' /etc/apache2/ports.conf
#               echo "Hello World" > /var/www/html/index.html
#               systemctl restart apache2
#               EOF
#   tags = {
#     Name = "terraform-learn-state-ec2"
#   }
# }
#+END_SRC

Then plan and apply the configuration.

** Import

Terraform supports bringing your existing infrastructure under its management.
By importing resources into Terraform, you can consistently manage your
infrastructure using a common workflow.

When you create new infrastructure with Terraform, you usually use the following
workflow:

1. Write Terraform configuration that defines the infrastructure you want to
   create.
2. Review the Terraform plan to ensure the configuration will result in the
   expected infrastructure.
3. Apply the configuration to have Terraform create your infrastructure.

You can use configuration to import existing resources into your state file with
the plan-and-apply workflow. You can use the ~terraform import~ command, but
configuration-driven import is safer, works with CICD pipelines, and allows you
to preview the import operation before modifying state. You can also optionally
use Terraform to generate an initial configuration for the resources you will
import.

Using configuration to import resources involves the following steps:

1. Identify the existing infrastructure you will import.
2. Define an import block for the resources.
3. Run terraform plan to review the import plan and optionally generate
   configuration for the resources.
4. Prune generated configuration to only the required arguments.
5. Apply the configuration to bring the resource into your Terraform state file.

*** Define import block to import docker container

Configuration-driven import relies on the ~import~ block, which has two required
arguments:

- ~id~ is the provider-specific identifier for the infrastructure you want to
  import
- ~to~ is the identifier Terraform will give the resource in state, consisting
  of the resource type and name

The ~id~ for a docker container is the SHA256 container ID you get by running

#+BEGIN_SRC bash :noeval
docker inspect --format="{{.ID}}" <container_name>
#+END_SRC

Add an ~import~ block to your configuration:

#+BEGIN_SRC tf
import {
  id = <container_id_hash>
  to = docker_container.web
}
#+END_SRC

*** Generate configuration

When importing a resource, you must both bring the resource into your state
file, and define a corresponding ~resource~ block for it in your configuration.
Although you can manually define the resource yourself, configuration-driven
import can generate configuration for you to use as a starting point.

The generated configuration contains all possible arguments for the imported
resources, including those set to default values and those without values. it's
recommended that you prune the generated configuration to only required
arguments and arguments whose values differ from defaults, to reduce the size of
your configuration.

Use ~terraform plan~ with the ~-generate-config-out~ flag to generate
configuration for the container you will import. Terraform builds a plan and
outputs the generated configuration for the container to the specified file.

E.g.

#+BEGIN_SRC bash :noeval
terraform plan -generate-config-out=generated.tf
#+END_SRC

Here you may see that Terraform plans to replace the imported resource due to
conflicts in the generated configuration and the imported instance. This is why
we usually need to prune the generated config and get rid of default
configuration. In the end our docker container resource should look something
like this:

#+BEGIN_SRC tf
resource "docker_container" "web" {
  env = []
  image = "..."
  name  = "hashicorp-learn"
  ports {
    external = 8080
    internal = 80
    ip       = "0.0.0.0"
    protocol = "tcp"
  }
}
#+END_SRC

Run ~terraform plan~ to verify that it will not replace the container.

Docker don't store all attributes that Terraform uses to create a container.
Since Docker does not track these attributes, Terraform did not include them in
the generated configuration. When you apply your configuration, the Docker
provider will assign the default values for these attributes and save them in
state, but they will not affect the running container.

It's recommended when you import a resource to make the first operation on the
resource a no-op. Basically, an operation that will not update the imported
resource.

*** Create image resource

You can bring some resources under Terraform's management without using the
~import~ block. This is often the case for resources defined by a single unique
ID or tag, such as Docker images.

In your ~generated.tf~ file, the ~docker_container.web~ resource specifies the
SHA256 hash ID of the image used to create the container. This is how Docker
stores the image ID internally, so the import operation loaded the image ID
directly into your state. However, identifying the image by its tag or name
would make your configuration easier to understand.

Retrieve the image's tag name by running the following command:

#+BEGIN_SRC bash :noeval
docker image inspect -f {{.RepoTags}} `docker inspect --format="{{.Image}}" <container_name>`
#+END_SRC

Then add the following configuration to your terraform configuration file to
represent this image as a resource.

#+BEGIN_SRC tf
resource "docker_image" "nginx" {
  name         = "nginx:latest"
}
#+END_SRC

Run ~terraform apply~. This will load the ~docker_image.nginx~ resource into
state. The image resource must exist in state before you can reference it. If
you would reference it in this step, the container would be recreated since
Terraform wouldn't know the ID during the plan step.

Now that Terraform created a resource for the image, you can reference it in
your container's configuration. Change the ~image~ value for
~docker_container.web~ to reference the new image resource.

Since ~docker_image.nginx.latest~ matches the hardcoded image ID you replaced,
~terraform apply~ returns a no-op.

*** Limitations and other considerations

- Importing manipulates the Terraform state file during the apply. You may want
  to create a backup before importing new infrastructure.
- Terraform import does not detect or generate relationships between
  infrastructure. You can manually add relationships to the configuration before
  you apply changes.
- Terraform import does not detect which default attributes you can skip
  setting.
- Not all providers and resources support Terraform import.
- Importing a resource into Terraform does not mean that Terraform can destroy
  and recreate it. For example, the imported infrastructure could rely on other
  unmanaged infrastructure or configuration.

** Use refresh-only mode to sync Terraform state

Terraform relies on the contents of your workspace's state file to generate an
execution plan to make changes to your resources. To ensure the accuracy of the
proposed changes, your state file must be up to date.

In Terraform, refreshing your state file updates Terraform's knowledge of your
infrastructure, as represented in your state file, with the actual state of your
infrastructure. Terraform ~plan~ and ~apply~ operations run an implicit
in-memory refresh as part of their functionality, reconciling any drift from
your state file before suggesting infrastructure changes. You can also update
your state file without making modifications to your infrastructure using the
~-refresh-only~ flag for ~plan~ and ~apply~ operations.

*** Run a refresh-only plan

A common error scenario that can prompt Terraform to refresh the contents of
your state file is mistakenly modifying your credentials or provider
configuration. E.g. providing the wrong cloud region.

You can compare your infrastructure with your statefile with
~terraform plan -refresh-only~. This will not update your state file. If the
changes in the plan are acceptable, you could run a
~terraform apply -refresh-only~ and approve the operation to overwrite your
state file without modifying your infrastructure.

A refresh-only ~apply~ operation also updates outputs, if necessary.

* Write Terraform Configuration
** Define infrastructure with Terraform resources

Terraform uses ~resource~ blocks to manage infrastructure, such as virtual
networks, compute instances, or higher-level components such as DNS records.
Resource blocks represent one or more infrastructure objects in your Terraform
configuration.

Most Terraform providers have a number of different resources that map to the
appropriate APIs to manage that particular infrastructure type.

In this section we make use of the git repository:
https://github.com/hashicorp/learn-terraform-resources

*** Review the ~random_pet~ resource

The first resource block defines a ~random_pet~ resource named name, which
generates a random pet name. You can use the name generated by this resource to
ensure that your other resources have unique names.

#+BEGIN_SRC tf
resource "random_pet" "name" {}
#+END_SRC

Resource blocks declare a resource type and name. Together, the type and name
form a resource identifier (ID) in the format ~resource_type.resource_name~, in
this case ~random_pet.name~. The resource's ID must be unique within a
workspace. When Terraform displays information about this resource in its output
it will use the resource ID.

Resource types always start with the provider name followed by an underscore.
The ~random_pet~ resource type belongs to the ~random~ provider.

Resources have arguments, attributes, and meta-arguments.

- *Arguments* configure a particular resource; because of this, many arguments
  are resource-specific. Arguments can be ~required~ or ~optional~, as specified
  by the provider. If you do not supply a required argument, Terraform will give
  an error and not apply the configuration.
- *Attributes* are values exposed by an existing resource. References to
  resource attributes take the format
  ~resource_type.resource_name.attribute_name~. Unlike arguments which specify
  an infrastructure object's configuration, a resource's attributes are often
  assigned to it by the underlying cloud provider or API.
- *Meta-arguments* change a resource's behavior, such as using a count
  meta-argument to create multiple resources. Meta-arguments are a function of
  Terraform itself and are not resource or provider-specific.

Because ~random_pet~ has no required arguments, you can define the
~random_pet.name~ resource without arguments.

*** Review the EC2 instance resource

#+BEGIN_SRC tf
resource "aws_instance" "web" {
  ami                    = "ami-a0cfeed8"
  instance_type          = "t2.micro"
  user_data              = file("init-script.sh")

  tags = {
    Name = random_pet.name.id
  }
}
#+END_SRC

The ~aws_instance.web~ resource block defines an ~aws_instance~ resource named
~web~ to create an AWS EC2 instance.

The arguments inside the ~aws_instance.web~ resource block specify what type of
resource to create.

- The ~user_data~ argument uses the ~file()~ function to return the contents of
  ~init-script.sh~.
- The ~tags~ argument specifies this EC2 instance's name. Notice that the
  argument references the ~random_pet.name~'s ID attribute
  (~random_pet.name.id~) to give the EC2 instance a unique name. This defines an
  implicit dependency between the EC2 instance and the ~random_pet~ resource;
  Terraform cannot create the instance until it has a name for it.

*** Create infrastructure

It will output something similar to:

#+BEGIN_SRC
...
Apply complete! Resources: 2 added, 0 changed, 0 destroyed.

Outputs:

application-url = "ec2-18-236-123-132.us-west-2.compute.amazonaws.com/index.php"
domain-name = "ec2-18-236-123-132.us-west-2.compute.amazonaws.com"
#+END_SRC

because of the ~output.tf~ file:

#+BEGIN_SRC tf
output "domain-name" {
  value = aws_instance.web.public_dns
}

output "application-url" {
  value = "${aws_instance.web.public_dns}/index.php"
}
#+END_SRC

But you can't visit the url, because you have not yet configured access to port
~80~ of the instance.

*** Associate security group with instance

To enable access to the EC2 instance's web server, you must define a security
group that allows ingress traffic on port ~80~ and all egress traffic, and
associate the security group with your instance.

In the [[https://registry.terraform.io/providers/hashicorp/aws/latest/docs][AWS Provider documentation page]] you can search for ~security_group~ and
selecte the ~aws_security_group~ resource. Define a new ~aws_security_group~
resource in ~main.tf~ that allows ingress traffic on port ~80~ and all egress
traffic for all CIDR blocks.

#+BEGIN_SRC tf
resource "aws_security_group" "web-sg" {
  name = "${random_pet.name.id}-sg"
  ingress {
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
}
#+END_SRC

Then, update your ~aws_instance.web~ resource to use this security group.

Add the ~vpc_security_group_ids~ argument to the ~aws_instance.web~ resource as
a *list* by placing the ~aws_security_group.web-sg.id~ attribute inside square
brackets.

#+BEGIN_SRC diff
resource "aws_instance" "web" {
  ami                    = "ami-a0cfeed8"
  instance_type          = "t2.micro"
  user_data              = file("init-script.sh")
+ vpc_security_group_ids = [aws_security_group.web-sg.id]

  tags = {
    Name = random_pet.name.id
  }
}
#+END_SRC

Apply the change.

** Protect sensitive input variables

Often you need to configure your infrastructure using sensitive or secret
information such as usernames, passwords, API tokens, or Personally Identifiable
Information (PII). When you do so, you need to ensure that you do not
accidentally expose this data in CLI output, log output, or source control.
Terraform provides several features to help avoid accidentally exposing
sensitive data.

*** Sensitive credentials

Declare the variables as you normally would in the ~variables.tf~ file.

#+BEGIN_SRC tf
variable "db_username" {
  description = "Database administrator username"
  type        = string
  sensitive   = true
}

variable "db_password" {
  description = "Database administrator password"
  type        = string
  sensitive   = true
}
#+END_SRC

Note that we also added a ~sensitive~ field. They will now be redacted in the
output of ~plan~, ~apply~ and ~destroy~

*** Set values with a ~.tfvars~ file

Terraform supports setting variable values with variable definition (~.tfvars~)
files. You can use multiple variable definition files, and many practitioners
use a separate file to set sensitive or secret values.

Create a new file called ~secret.tfvars~ to assign values to the new variables.

#+BEGIN_SRC tf
db_username = "admin"
db_password = "insecurepassword"
#+END_SRC

Apply these changes using the ~-var-file~ parameter.

#+BEGIN_SRC bash :noeval
terraform apply -var-file="secret.tfvars"
#+END_SRC

*** Set values with variables

You can also set variables using environment variables.

When Terraform runs, it looks in your environment for variables that match the
pattern ~TF_VAR_<VARIABLE_NAME>~, and assigns those values to the corresponding
Terraform variables in your configuration. E.g.

#+BEGIN_SRC bash :noeval
export TF_VAR_db_username=admin TF_VAR_db_password=adifferentpassword
#+END_SRC

*** Reference sensitive variables

When you use sensitive variables in your Terraform configuration, you can use
them as you would any other variable. Terraform will redact these values in
command output and log files, and raise an error when it detects that they will
be exposed in other ways.

If this would be in you ~outputs.tf~ file:

#+BEGIN_SRC tf
output "db_connect_string" {
  description = "MySQL database connection string"
  value       = "Server=${aws_db_instance.database.address}; Database=ExampleDB; Uid=${var.db_username}; Pwd=${var.db_password}"
}
#+END_SRC

You would get an error when applys the configuration as the output is
referencing sensitive variables. To correct this you can flag this output as
sensitive to hide it in the output:

#+BEGIN_SRC diff
output "db_connect_string" {
  description = "MySQL database connection string"
  value       = "Server=${aws_db_instance.database.address}; Database=ExampleDB; Uid=${var.db_username}; Pwd=${var.db_password}"
+ sensitive   = true
}
#+END_SRC

*** Sensitive values in state

When you run Terraform commands with a local state file, Terraform stores the
state as plain text, including variable values, even if you have flagged them as
~sensitive~. Terraform needs to store these values in your state so that it can
tell if you have changed them since the last time you applied your
configuration.

** Simplify Terraform configuration with locals

Terraform local values (or "locals") assign a name to an expression or value.
Using locals simplifies your Terraform configuration - since you can reference
the local multiple times, you reduce duplication in your code. Locals can also
help you write more readable configuration by using meaningful names rather than
hard-coding values.

Unlike variables found in programming languages, Terraform's locals do not
change values during or between Terraform runs such as plan, apply, or destroy.
You can use locals to give a name to the result of any Terraform expression, and
re-use that name throughout your configuration. Unlike input variables, locals
are not set directly by users of your configuration.

*** Use locals to name resources

If multiple resources share the same suffix you can make use of locals. In your
~main.tf~ file define e.g.:

#+BEGIN_SRC tf
locals {
  name_suffix = "${var.resource_tags["project"]}-${var.resource_tags["environment"]}"
}
#+END_SRC

As in any Terraform configuration, the order of your resource definitions and
values does not affect how Terraform interprets them. To make your configuration
more readable, consider putting local definitions near the top of your files.

Now you can use this ~name_suffix~ local for all your resources by referring to
it with ~local.name_suffix~:

#+BEGIN_SRC tf
 module "vpc" {
   source  = "terraform-aws-modules/vpc/aws"
   version = "2.66.0"

   name = "vpc-${local.name_suffix}"
   ## ...
 }

 module "app_security_group" {
   source  = "terraform-aws-modules/security-group/aws//modules/web"
   version = "3.17.0"

   name        = "web-sg-${local.name_suffix}"
   ## ...
 }

 module "lb_security_group" {
   source  = "terraform-aws-modules/security-group/aws//modules/web"
   version = "3.17.0"

   name        = "lb-sg-${local.name_suffix}"
   ## ...
 }

 module "elb_http" {
   source  = "terraform-aws-modules/elb/aws"
   version = "2.4.0"

   # Ensure load balancer name is unique
   name = "lb-${random_string.lb_id.result}-${local.name_suffix}"
   ## ...
 }
#+END_SRC

*** Combine variables with local values

In the previous example we used the map variable ~resource_tags~ to define our
local variable. We can split that variable into two and then redefine
~resource_tags~ as a local variable. In ~variables.tf~:

#+BEGIN_SRC tf
variable "project_name" {
  description = "Name of the project."
  type        = string
  default     = "my-project"
}

variable "environment" {
  description = "Name of the environment."
  type        = string
  default     = "dev"
}

// Still give the user the possibility to add more tags
variable "resource_tags" {
  description = "Tags to set for all resources"
  type        = map(string)
  default     = { }
}
#+END_SRC

In ~main.tf~:

#+BEGIN_SRC tf
locals {
  name_suffix = "${var.project_name}-${var.environment}"

  required_tags = {
    project     = var.project_name,
    environment = var.environment
  }

  // Merge two maps
  tags = merge(var.resource_tags, local.required_tags)
}
#+END_SRC

All of your configuration's local values can be defined in a single ~locals~
block, or you can use multiple blocks.

Finally, add an output named ~tags~ to your ~outputs.tf~ file. This output will
display the tags you used in this configuration. Based on your local value, the
tags are a combination of ~var.resource_tags~ and ~local.required_tags~.

#+BEGIN_SRC tf
output "tags" {
  value = local.tags
}
#+END_SRC

** Query data sources

Terraform ~data~ sources let you dynamically fetch data from APIs or other
Terraform state backends. Examples of data sources include machine image IDs
from a cloud provider or Terraform outputs from other configurations. Data
sources make your configuration more flexible and dynamic and let you reference
values from other configurations, helping you scope your configuration while
still referencing any dependent resource attributes.

Data sources provide information about entities that are not managed by the
current Terraform configuration.

** Create resource dependencies

Most of the time, Terraform infers dependencies between resources based on the
configuration given, so that resources are created and destroyed in the correct
order. Occasionally, however, Terraform cannot infer dependencies between
different parts of your infrastructure, and you will need to create an explicit
dependency with the ~depends_on~ argument.

Terraform automatically infers when one resource depends on another by studying
the resource attributes used in interpolation expressions. Terraform uses this
dependency information to determine the correct order in which to create the
different resources. To do so, it creates a dependency graph of all of the
resources defined by the configuration.

*** Manage explicit dependencies

Implicit dependencies are the primary way that Terraform understands the
relationships between your resources. Sometimes there are dependencies between
resources that are not visible to Terraform, however. The ~depends_on~ argument
is accepted by any resource or module block and accepts a list of resources to
create explicit dependencies for.

To illustrate this, assume you have an application running on your EC2 instance
that expects to use a specific Amazon S3 bucket. This dependency is configured
inside the application, and thus not visible to Terraform. You can use
~depends_on~ to explicitly declare the dependency. You can also specify multiple
resources in the ~depends_on~ argument, and Terraform will wait until all of
them have been created before creating the target resource.

Since Terraform will wait to create the dependent resource until after the
specified resource is created, adding explicit dependencies can increase the
length of time it takes for Terraform to create your infrastructure.

E.g.

#+BEGIN_SRC tf
resource "aws_s3_bucket" "example" { }

resource "aws_instance" "example_c" {
  ami           = data.aws_ami.amazon_linux.id
  instance_type = "t2.micro"

  depends_on = [aws_s3_bucket.example]
}

module "example_sqs_queue" {
  source  = "terraform-aws-modules/sqs/aws"
  version = "3.3.0"

  depends_on = [aws_s3_bucket.example, aws_instance.example_c]
}
#+END_SRC

Both implicit and explicit dependencies affect the order in which resources are
destroyed as well as created. A resource is destroyed before the resources they
depend on.

** Manage similar resources with ~count~

The ~count~ argument replicates the given resource or module a specific number
of times with an incrementing counter. It works best when resources will be
identical, or nearly so.

*** Declare a variable for instance number

Add the ~instances_per_subnet~ variable to ~variables.tf~ to define how many
instances each private subnet will have.

#+BEGIN_SRC tf
variable "instances_per_subnet" {
  description = "Number of EC2 instances in each private subnet"
  type        = number
  default     = 2
}
#+END_SRC

*** Scale EC2 configuration with ~count~

Edit ~main.tf~ to use ~count~ to provision multiple EC2 instances with the ~app~
resource block, based on the value of the new ~instances_per_subnet~ variable
and the number of private subnets.

#+BEGIN_SRC tf
resource "aws_instance" "app" {
  depends_on = [module.vpc]

  // Count used here
  count = var.instances_per_subnet * length(module.vpc.private_subnets)

  ami           = data.aws_ami.amazon_linux.id
  instance_type = var.instance_type

  // Count used here
  subnet_id              = module.vpc.private_subnets[count.index % length(module.vpc.private_subnets)]
  vpc_security_group_ids = [module.app_security_group.this_security_group_id]

  ## ...
}
#+END_SRC

Each instance provisioned by the resource block with ~count~ will have a
different incrementing value for ~count.index~ - starting with zero. This
configuration uses ~count.index~ and modulo division to assign each instance to
a private subnet.

Because the default value of ~instances_per_subnet~ is ~2~, Terraform will
provision two EC2 instances per private subnet.

*** Update the load balancer

Update the load balancer configuration in the ~elb_http~ block to attach the
instances to the load balancer.

#+BEGIN_SRC tf
module "elb_http" {
  source  = "terraform-aws-modules/elb/aws"
  version = "3.0.1"

##...

  security_groups = [module.lb_security_group.this_security_group_id]
  subnets         = module.vpc.public_subnets

  // Reference to instances here
  number_of_instances = length(aws_instance.app)
  instances           = aws_instance.app.*.id

  listener = [{
    instance_port     = "80"
    instance_protocol = "HTTP"
    lb_port           = "80"
    lb_protocol       = "HTTP"
  }]

##...
#+END_SRC

he name of resources or modules provisioned with ~count~ refers to the entire
collection. In this example, ~aws_instance.app~ now refers to all of the EC2
instances. You can reference individual items in collections with the same
notation as list indexing. For example, ~aws_instance.app[0]~ refers to the
first instance Terraform provisions.

You can create a list of all of the values of a given attribute for the items in
the collection with a star. For instance, ~aws_instance.app.*.id~ will be a list
of all of the IDs of the instances.

You can also output all IDs of the instances by adding the following to
~outputs.tf~:

#+BEGIN_SRC tf
output "instance_ids" {
  description = "IDs of EC2 instances"
  value       = aws_instance.app.*.id
}
#+END_SRC

** Manage similar resources with ~for_each~

Terraform's ~for_each~ meta-argument allows you to configure a set of similar
resources by iterating over a data structure to configure a resource or module
for each item in the data structure. You can use ~for_each~ to customize a set
of similar resources that share the same lifecycle.

*** Define a map to configure each project

Define a map for project configuration in ~variables.tf~ that ~for_each~ will
iterate over to configure each resource.

#+BEGIN_SRC tf
variable "project" {
  description = "Map of project names to configuration."
  type        = map(any)

  default = {
    client-webapp = {
      public_subnets_per_vpc  = 2,
      private_subnets_per_vpc = 2,
      instances_per_subnet    = 2,
      instance_type           = "t2.micro",
      environment             = "dev"
    },
    internal-webapp = {
      public_subnets_per_vpc  = 1,
      private_subnets_per_vpc = 1,
      instances_per_subnet    = 2,
      instance_type           = "t2.nano",
      environment             = "test"
    }
  }
}
#+END_SRC

*** Add ~for_each~ to the VPC

Now use ~for_each~ to iterate over the ~project~ map in the VPC module block of
~main.tf~, which will create one VPC for each key/value pair in the map.

#+BEGIN_SRC tf
module "vpc" {
  source  = "terraform-aws-modules/vpc/aws"
  version = "3.14.2"

  for_each = var.project

  cidr = var.vpc_cidr_block

  azs             = data.aws_availability_zones.available.names
  private_subnets = slice(var.private_subnet_cidr_blocks, 0, each.value.private_subnets_per_vpc)
  public_subnets  = slice(var.public_subnet_cidr_blocks, 0, each.value.public_subnets_per_vpc)
##...
#+END_SRC

This Terraform configuration defines multiple VPCs, assigning each key/value
pair in the ~var.project~ map to ~each.key~ and ~each.value~ respectively. When
you use ~for_each~ with a list or set, ~each.key~ is the index of the item in
the collection, and ~each.value~ is the value of the item.

In this example, the project map includes values for the number of private and
public subnets in each VPC.

Update the ~app_security_group~ module to iterate over the project variable to
get the security group name, VPC ID, and CIDR blocks for each project.

#+BEGIN_SRC tf
module "app_security_group" {
  source  = "terraform-aws-modules/security-group/aws//modules/web"
  version = "4.9.0"

  for_each = var.project

  name        = "web-server-sg-${each.key}-${each.value.environment}"
  description = "Security group for web-servers with HTTP ports open within VPC"
  vpc_id      = module.vpc[each.key].vpc_id

  ingress_cidr_blocks = module.vpc[each.key].public_subnets_cidr_blocks
}
#+END_SRC

You can differentiate between instances of resources and modules configured with
~for_each~ by using the keys of the map you use. In this example, using
~module.vpc[each.key].vpc_id~ to define the VPC means that the security group
for a given project will be assigned to the corresponding VPC.

*** Outputs

Finally, replace the entire contents of ~outputs.tf~ in your root module with
the following:

#+BEGIN_SRC tf
output "public_dns_names" {
  description = "Public DNS names of the load balancers for each project."
  value       = { for p in sort(keys(var.project)) : p => module.elb_http[p].elb_dns_name }
}

output "vpc_arns" {
  description = "ARNs of the vpcs for each project."
  value       = { for p in sort(keys(var.project)) : p => module.vpc[p].vpc_arn }
}

output "instance_ids" {
  description = "IDs of EC2 instances."
  value       = { for p in sort(keys(var.project)) : p => module.ec2_instances[p].instance_ids }
}
#+END_SRC

The ~for~ expressions used here will map the project names to the corresponding
values in the Terraform output.

~for~ and ~for_each~ are different features. ~for_each~ provisions similar
resources in module and resource blocks. ~for~ creates a list or map by
iterating over a collection, such as another list or map.

** Perform dynamic operations with functions

The Terraform configuration language allows you to write declarative expressions
to create infrastructure. While the configuration language is not a programming
language, you can use several built-in functions to perform operations
dynamically.

In this tutorial, you will:

- use the ~templatefile~ function to dynamically create an EC2 instance user
  data script.
- use the ~lookup~ function to reference values from a map.
- use the ~file~ function to read the contents of a file.

*** Use ~templatefile~ to dynamically generate a script

AWS lets you configure EC2 instances to run a user-provided script -- called a
user-data script -- at boot time. You can use Terraform's ~templatefile~
function to interpolate values into the script at resource creation time. This
makes the script more adaptable and re-usable.

You can add a ~user_data.tftpl~ file, which will be the user data script for
your EC2 instance. This template file is a shell script to configure and deploy
an application. Notice the ~${department}~ and ~${name}~ references -- Terraform
will interpolate these values using the ~templatefile~ function.

#+BEGIN_SRC bash :noeval
#!/bin/bash

# Install necessary dependencies
sudo DEBIAN_FRONTEND=noninteractive apt-get -y -o Dpkg::Options::="--force-confdef" -o Dpkg::Options::="--force-confold" dist-upgrade
sudo apt-get update
sudo apt-get -y -qq install curl wget git vim apt-transport-https ca-certificates
sudo apt -y -qq install golang-go

# Setup sudo to allow no-password sudo for your group and adding your user
sudo groupadd -r ${department}
sudo useradd -m -s /bin/bash ${name}
sudo usermod -a -G ${department} ${name}
sudo cp /etc/sudoers /etc/sudoers.orig
echo "${name} ALL=(ALL) NOPASSWD:ALL" | sudo tee /etc/sudoers.d/${name}

# Create GOPATH for your user & download the webapp from github
sudo -H -i -u ${name} -- env bash << EOF
cd /home/${name}
export GOROOT=/usr/lib/go
export GOPATH=/home/${name}/go
export PATH=$PATH:$GOROOT/bin:$GOPATH/bin
git clone https://github.com/hashicorp/learn-go-webapp-demo.git
cd learn-go-webapp-demo
go run webapp.go
EOF
#+END_SRC

Next, create a ~variables.tf~ file. This file includes definitions for the
~user_name~ and ~user_department~ input variables, which the configuration uses
to set the values for the corresponding template file keys.

#+BEGIN_SRC tf
variable "user_name" {
  description = "The user creating this infrastructure"
  default     = "terraform"
}

variable "user_department" {
  description = "The organization the user belongs to: dev, prod, qa"
  default     = "learn"
}
#+END_SRC

Now create ~main.tf~. Add the ~user_data~ attribute to the ~aws_instance~
resource block. The ~templatefile~ function takes two arguments: the template
file name and a map of template value assignments.

#+BEGIN_SRC tf
resource "aws_instance" "web" {
  ami                         = data.aws_ami.ubuntu.id
  instance_type               = "t2.micro"
  subnet_id                   = aws_subnet.subnet_public.id
  vpc_security_group_ids      = [aws_security_group.sg_8080.id]
  associate_public_ip_address = true
  user_data                   = templatefile("user_data.tftpl", { department = var.user_department, name = var.user_name })
}
#+END_SRC

*** Use ~lookup~ function to select AMI

The ~lookup~ function retrieves the value of a single element from a map, given
its key.

Add the following configuration to your ~variables.tf~ file to declare a new
input variable.

#+BEGIN_SRC tf
variable "aws_amis" {
  type = map
  default = {
    "us-east-1" = "ami-04b70fa74e45c3917"
    "us-west-2" = "ami-08012c0a9ee8e21c4"
    "us-east-2" = "ami-09040d770ffe2224f"
  }
}
#+END_SRC

In your ~aws_instance~ resource, update the ami attribute to use the lookup
function.

#+BEGIN_SRC diff
resource "aws_instance" "web" {
- ami                         = data.aws_ami.ubuntu.id
+ ami                         = lookup(var.aws_amis, var.aws_region)
  instance_type               = "t2.micro"
  subnet_id                   = aws_subnet.subnet_public.id
  vpc_security_group_ids      = [aws_security_group.sg_8080.id]
  associate_public_ip_address = true
  user_data                   = templatefile("user_data.tftpl", { department = var.user_department, name = var.user_name })
}
#+END_SRC

The ~ami~ is a required attribute for the ~aws_instance~ resource, so the
~lookup~ function must return a valid value for Terraform to apply your
configuration. The ~lookup~ function arguments are a map, the key to access in
the map, and an optional default value in case the key does not exist.

Next, add the following configuration for an ~ami_value~ output to your
~outputs.tf~ file. This output lets you verify the AMI returned by the ~lookup~
function.

#+BEGIN_SRC tf
output "ami_value" {
  value = lookup(var.aws_amis, var.aws_region)
}
#+END_SRC

*** Use the ~file~ function

Add the following configuration to ~main.tf~ to create a new security group and
AWS key pair.



#+BEGIN_SRC tf
resource "aws_security_group" "sg_22" {
  name = "sg_22"
  vpc_id = aws_vpc.vpc.id

  ingress {
    from_port = 22
    to_port  = 22
    protocol  = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }
}

resource "aws_key_pair" "ssh_key" {
  key_name = "ssh_key"
  public_key = file("ssh_key.pub")
}
#+END_SRC

This configuration uses the ~file~ function to read the contents of a file to
configure an SSH key pair. The ~file~ function does not interpolate values into
file contents; you should only use it with files that do not need modification.

** Create dynamic expressions

The Terraform configuration language supports complex expressions to allow you
to compute or generate values for your infrastructure configuration. Expressions
can be simple string or integer values, or more complex values to make your
configuration more dynamic.

*** Use a conditional expression

Conditional expressions select a value based on whether the expression evaluates
to ~true~ or ~false~.

In this configuration, you will use the ~locals~ block to create a resource name
based on a conditional value and capture that name in a map of resource tags.

#+BEGIN_SRC tf
resource "random_id" "id" {
  byte_length = 8
}

locals {
  name  = (var.name != "" ? var.name : random_id.id.hex)
  owner = var.team
  common_tags = {
    Owner = local.owner
    Name  = local.name
  }
}
#+END_SRC

*** Use a ~splat~ expression

The ~splat~ expression captures all objects in a list that share an attribute.
The special ~*~ symbol iterates over all of the elements of a given list and
returns information based on the shared attribute you define.

Without the splat expression, Terraform would not be able to output the entire
array of your instances and would only return the first item in the array.

**** Create a splat expression

This output will return the private DNS of all instances created by the
~aws_instance.ubuntu~ resource.

#+BEGIN_SRC tf
output "private_addresses" {
  description = "Private DNS for AWS instances"
  value       = aws_instance.ubuntu[*].private_dns
}
#+END_SRC

This expression mirrors capturing a specific element in an array. If you only
wanted to return the third instance IP in the array of instances, you could do
that by replacing the ~*~ with ~2~.

** Use checks to validate infrastructure

Terraform checks let you define assertions to validate as part of your
infrastructure management workflow. Unlike variable validation or custom
conditions, check blocks are decoupled from the lifecycle of a specific resource
or data source. Checks let you take advantage of Terraform's abstraction of the
differences between different provider APIs. Because Terraform standardizes how
you interact with all provider APIs, you can use the familiar Terraform language
features and syntax to define conditions to validate in your Terraform runs.
Checks also let you verify your assumptions about your infrastructure on an
ongoing basis instead of just at the time of provisioning.

*** Define a check

Checks can validate any condition that you can define with Terraform
configuration. A check can validate an attribute of your infrastructure, or the
functionality of the resource itself. Rather than writing custom scripts to test
assertions about your infrastructure, you can use Terraform language features to
validate your infrastructure health.

E.g.

#+BEGIN_SRC tf
check "certificate" {
  assert {
    condition     = aws_acm_certificate.cert.status == "ISSUED"
    error_message = "Certificate status is ${aws_acm_certificate.cert.status}"
  }
}
#+END_SRC

Defines a check we call ~certificate~. A ~check~ block consists of one or more
~assert~ statements. The assertions contain the condition to verify and the
error message to display if the assertion fails. This check verifies the TLS
certificate's status.

*** Create infrastructure and validate checks

Terraform will evaluate any checks included in your configuration as the last
step of the ~apply~ operation. If the check fails Terraform will not prevent you
from applying new changes.

Terraform evaluates checks after generating the plan. Unlike custom conditions
or variable validation errors, failed checks do not block applies. Terraform
will notify if there are any failures or issues to address, letting you decide
whether to proceed with the operation.

Unlike other configuration validation mechanisms, checks are decoupled from
other components and resources in your configuration. These differ from variable
validation, which lets you ensure the inputs to your configuration satisfy your
requirements, and custom conditions, which let you define conditions as part of
your resource definitions. These conditions are tied to the specific resource
lifecycle, rather than your configuration as a whole.

*** Use a data source within a check

You can reference data sources in check block assertions. Terraform queries the
data source when it evaluates your configuration's checks, at the end of each
Terraform operation. This lets you access the most up-to-date data about your
environment when a workspace manages many resources and takes longer to complete
Terraform operations.

#+BEGIN_SRC tf
check "response" {
  data "http" "terramino" {
    url      = "https://${aws_lb.terramino.dns_name}"
    insecure = true
  }

  assert {
    condition     = data.http.terramino.status_code == 200
    error_message = "Terramino response is ${data.http.terramino.status_code}"
  }
}
#+END_SRC

This check defines a data source that captures the response of a GET request to
your Terramino service and asserts that the status code is ~200~.

You can reference any data sources or resource attributes in your configuration
to define check conditions, but you cannot access data sources defined within
check blocks in the rest of your configuration. The data source namespace is
scoped within the check block, and evaluates at the time of the check. If
needed, you can specify the ~depends_on~ meta-argument for a data source within
the check to enforce an evaluation order.

Apply your change. Open your ~terraform.tfstate~ file and find the
~check_results~ field. Terraform records your check's statuses.

#+BEGIN_SRC tf
"check_results": [
  {
    "object_kind": "check",
    "config_addr": "check.certificate",
    "status": "pass",
    "objects": [
      {
        "object_addr": "check.certificate",
        "status": "pass"
      }
    ]
  },
  {
    "object_kind": "check",
    "config_addr": "check.response",
    "status": "pass",
    "objects": [
      {
        "object_addr": "check.response",
        "status": "pass"
      }
    ]
  }
]
#+END_SRC

* Reuse Configuration with Modules
** Modules overview

As you manage your infrastructure with Terraform, you will create increasingly
complex configurations. There is no intrinsic limit to the complexity of a
single Terraform configuration file or directory, so it is possible to continue
writing and updating your configuration files in a single directory. However, if
you do, you may encounter one or more problems:

- Understanding and navigating the configuration files will become increasingly
  difficult.
- Updating the configuration will become more risky, as an update to one section
  may cause unintended consequences to other parts of your configuration.
- There will be an increasing amount of duplication of similar blocks of
  configuration, for instance when configuring separate dev/staging/production
  environments, which will cause an increasing burden when updating those parts
  of your configuration.
- You may wish to share parts of your configuration between projects and teams,
  and will quickly find that cutting and pasting blocks of configuration between
  projects is error prone and hard to maintain.
- Engineers will need more Terraform expertise to understand and modify your
  configuration. This makes self-service workflows for other teams more
  difficult, slowing down their development.

*** What are modules for?

Here are some of the ways that modules help solve the problems listed above:

- Organize configuration - Modules make it easier to navigate, understand, and
  update your configuration by keeping related parts of your configuration
  together. Even moderately complex infrastructure can require hundreds or
  thousands of lines of configuration to implement. By using modules, you can
  organize your configuration into logical components.

- Encapsulate configuration - Another benefit of using modules is to encapsulate
  configuration into distinct logical components. Encapsulation can help prevent
  unintended consequences, such as a change to one part of your configuration
  accidentally causing changes to other infrastructure, and reduce the chances
  of simple errors like using the same name for two different resources.

- Re-use configuration - Writing all of your configuration from scratch can be
  time consuming and error prone. Using modules can save time and reduce costly
  errors by re-using configuration written either by yourself, other members of
  your team, or other Terraform practitioners who have published modules for you
  to use. You can also share modules that you have written with your team or the
  general public, giving them the benefit of your hard work.

- Provide consistency and ensure best practices - Modules also help to provide
  consistency in your configurations. Not only does consistency make complex
  configurations easier to understand, it also helps to ensure that best
  practices are applied across all of your configuration. For instance, cloud
  providers give many options for configuring object storage services, such as
  Amazon S3 or Google Cloud Storage buckets. There have been many high-profile
  security incidents involving incorrectly secured object storage, and given the
  number of complex configuration options involved, it's easy to accidentally
  misconfigure these services.

- Self service - Modules make your configuration easier for other teams to use.
  The HCP Terraform registry lets other teams find and re-use your published and
  approved Terraform modules. You can also build and publish no-code ready
  modules, which let teams without Terraform expertise provision their own
  infrastructure that complies with your organization's standards and policies.

Using modules can help reduce these errors. For example, you might create a
module to describe how all of your organization's public website buckets will be
configured, and another module for private buckets used for logging
applications. Also, if a configuration for a type of resource needs to be
updated, using modules allows you to make that update in a single place and have
it be applied to all cases where you use that module.

*** What is a Terraform module?

A Terraform module is a set of Terraform configuration files in a single
directory. Even a simple configuration consisting of a single directory with one
or more ~.tf~ files is a module. When you run Terraform commands directly from
such a directory, it is considered the *root module*. So in this sense, every
Terraform configuration is part of a module. You may have a simple set of
Terraform configuration files such as:

#+BEGIN_SRC
.
├── LICENSE
├── README.md
├── main.tf
├── variables.tf
├── outputs.tf
#+END_SRC

**** Calling modules

Terraform commands will only directly use the configuration files in one
directory, which is usually the current working directory. However, your
configuration can use module blocks to call modules in other directories. When
Terraform encounters a module block, it loads and processes that module's
configuration files.

A module that is called by another configuration is sometimes referred to as a
"child module" of that configuration.

**** Local and remote modules

Modules can either be loaded from the local filesystem, or a remote source.
Terraform supports a variety of remote sources, including the Terraform
Registry, most version control systems, HTTP URLs, and HCP Terraform or
Terraform Enterprise private module registries.

*** Module best practices

In many ways, Terraform modules are similar to the concepts of libraries,
packages, or modules found in most programming languages, and provide many of
the same benefits. Just like almost any non-trivial computer program, real-world
Terraform configurations should almost always use modules to provide the
benefits mentioned above.

We recommend that every Terraform practitioner use modules by following these
best practices:

1. Name your provider ~terraform-<PROVIDER>-<NAME>~. You must follow this
   convention in order to publish to the HCP Terraform or Terraform Enterprise
   module registries.

2. Start writing your configuration with modules in mind. Even for modestly
   complex Terraform configurations managed by a single person, you'll find the
   benefits of using modules outweigh the time it takes to use them properly.

3. Use local modules to organize and encapsulate your code. Even if you aren't
   using or publishing remote modules, organizing your configuration in terms of
   modules from the beginning will significantly reduce the burden of
   maintaining and updating your configuration as your infrastructure grows in
   complexity.

4. Use the public Terraform Registry to find useful modules. This way you can
   more quickly and confidently implement your configuration by relying on the
   work of others to implement common infrastructure scenarios.

5. Publish and share modules with your team. Most infrastructure is managed by a
   team of people, and modules are important way that teams can work together to
   create and maintain infrastructure. As mentioned earlier, you can publish
   modules either publicly or privately. Module users can reference published
   child modules in a root module, or deploy no-code ready modules through the
   HCP Terraform UI.

** Use registry modules in configuration

#+BEGIN_SRC tf
module "vpc" {
  source  = "terraform-aws-modules/vpc/aws"
  version = "3.18.1"

  name = var.vpc_name
  cidr = var.vpc_cidr

  azs             = var.vpc_azs
  private_subnets = var.vpc_private_subnets
  public_subnets  = var.vpc_public_subnets

  enable_nat_gateway = var.vpc_enable_nat_gateway

  tags = var.vpc_tags
}

module "ec2_instances" {
  source  = "terraform-aws-modules/ec2-instance/aws"
  version = "4.3.0"

  count = 2
  name  = "my-ec2-cluster-${count.index}"

  ami                    = "ami-0c5204531f799e0c6"
  instance_type          = "t2.micro"
  vpc_security_group_ids = [module.vpc.default_security_group_id]
  subnet_id              = module.vpc.public_subnets[0]

  tags = {
    Terraform   = "true"
    Environment = "dev"
  }
}
#+END_SRC

This configuration includes two blocks:

1. The ~module "vpc"~ block configures a Virtual Private Cloud (VPC) module,
   which provisions networking resources such as a VPC, subnets, and internet
   and NAT gateways based on the arguments provided.
2. The ~module "ec2_instances"~ block defines two EC2 instances provisioned
   within the VPC created by the module.

*** Set values for module input variables

Modules can contain both required and optional arguments. You must specify all
required arguments to use the module. Most module arguments correspond to the
module's input variables. Optional inputs will use the module's default values
if not explicitly defined.

*** Review root input variables

Using input variables with modules is similar to using variables in any
Terraform configuration. A common pattern is to identify which module arguments
you may want to change in the future, and create matching variables in your
configuration's ~variables.tf~ file with sensible default values. You can pass
the variables to the module block as arguments.

*** Review root output values

Modules also have output values. You can reference them with the
~module.MODULE_NAME.OUTPUT_NAME~ naming convention.

You can reference module outputs in other parts of your configuration. Terraform
will not display module outputs by default. You must create a corresponding
output in your root module and set it to the module's output. E.g.

#+BEGIN_SRC tf
output "vpc_public_subnets" {
  description = "IDs of the VPC's public subnets"
  value       = module.vpc.public_subnets
}

output "ec2_instance_public_ips" {
  description = "Public IP addresses of EC2 instances"
  value       = module.ec2_instances[*].public_ip
}
#+END_SRC

*** Understand how modules work

When using a new module for the first time, you must run either ~terraform init~
or ~terraform get~ to install the module. When you run these commands, Terraform
will install any new modules in the ~.terraform/modules~ directory within your
configuration's working directory. For local modules, Terraform will create a
symlink to the module's directory. Because of this, any changes to local modules
will be effective immediately, without having to reinitialize or re-run
~terraform get~.

** Build and use a local module

While using existing Terraform modules correctly is an important skill, every
Terraform practitioner will also benefit from learning how to create modules. In
fact, it's recommended that every Terraform configuration be created with the
assumption that it may be used as a module, because doing so will help you
design your configurations to be flexible, reusable, and composable.

As you may already know, Terraform treats every configuration as a module. When
you run ~terraform~ commands the target directory containing Terraform
configuration is treated as the root module.

*** Module structure

Terraform treats any local directory referenced in the ~source~ argument of a
~module~ block as a module. A typical file structure for a new module is:

#+BEGIN_SRC
.
├── LICENSE
├── README.md
├── main.tf
├── variables.tf
├── outputs.tf
#+END_SRC

None of these files are required, or have any special meaning to Terraform when
it uses your module. You can create a module with a single ~.tf~ file, or use
any other file structure you like.

*** Create a module

You will create a local submodule within your existing configuration that uses
the s3 bucket resource from the AWS provider.

In your existing terraform project,  create a directory called ~modules~, with a
directory called ~aws-s3-static-website-bucket~ inside of it.

#+BEGIN_SRC bash :noeval
mkdir -p modules/aws-s3-static-website-bucket
#+END_SRC

Hosting a static website with S3 is a fairly common use case. While it isn't too
difficult to figure out the correct configuration to provision a bucket this
way, encapsulating this configuration within a module will provide your users
with a quick and easy way create buckets they can use to host static websites
that adhere to best practices. Another benefit of using a module is that the
module name can describe exactly what buckets created with it are for. In this
example, the aws-s3-static-website-bucket module creates s3 buckets that host
static websites.

*** Add module configuration

You will work with three Terraform configuration files inside the
~aws-s3-static-website-bucket~ directory: ~main.tf~, ~variables.tf~, and
~outputs.tf~.

Add an S3 bucket resource to ~main.tf~ inside the
~modules/aws-s3-static-website-bucket~ directory:

#+BEGIN_SRC tf
resource "aws_s3_bucket" "s3_bucket" {
  bucket = var.bucket_name

  tags = var.tags
}

resource "aws_s3_bucket_website_configuration" "s3_bucket" {
  bucket = aws_s3_bucket.s3_bucket.id

  index_document {
    suffix = "index.html"
  }

  error_document {
    key = "error.html"
  }
}

resource "aws_s3_bucket_acl" "s3_bucket" {
  bucket = aws_s3_bucket.s3_bucket.id

  acl = "public-read"
}

resource "aws_s3_bucket_policy" "s3_bucket" {
  bucket = aws_s3_bucket.s3_bucket.id

  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Sid       = "PublicReadGetObject"
        Effect    = "Allow"
        Principal = "*"
        Action    = "s3:GetObject"
        Resource = [
          aws_s3_bucket.s3_bucket.arn,
          "${aws_s3_bucket.s3_bucket.arn}/*",
        ]
      },
    ]
  })
}
#+END_SRC

This configuration creates a public S3 bucket hosting a website with an index
page and an error page.

Notice that there is no ~provider~ block in this configuration. When Terraform
processes a module block, it will inherit the provider from the enclosing
configuration. Because of this, we recommend that you do not include ~provider~
blocks in modules.

Just like the root module of your configuration, modules will define and use
variables.

Define the following variables in ~variables.tf~ inside the
~modules/aws-s3-static-website-bucket~ directory:

#+BEGIN_SRC tf
# Input variable definitions

variable "bucket_name" {
  description = "Name of the s3 bucket. Must be unique."
  type        = string
}

variable "tags" {
  description = "Tags to set on the bucket."
  type        = map(string)
  default     = {}
}
#+END_SRC

Variables within modules work almost exactly the same way that they do for the
root module. When you run a Terraform command on your root configuration, there
are various ways to set variable values, such as passing them on the
commandline, or with a ~.tfvars~ file. When using a module, variables are set by
passing arguments to the module in your configuration. You will set some of
these variables when calling this module from your root module's ~main.tf~.

Variables declared in modules that aren't given a default value are required,
and so must be set whenever you use the module.

You should also consider which values to add as outputs, since outputs are the
only supported way for users to get information about resources configured by
the module.

Add outputs to your module in the ~outputs.tf~ file inside the
~modules/aws-s3-static-website-bucket~ directory:

#+BEGIN_SRC tf
# Output variable definitions

output "arn" {
  description = "ARN of the bucket"
  value       = aws_s3_bucket.s3_bucket.arn
}

output "name" {
  description = "Name (id) of the bucket"
  value       = aws_s3_bucket.s3_bucket.id
}

output "domain" {
  description = "Domain name of the bucket"
  value       = aws_s3_bucket_website_configuration.s3_bucket.website_domain
}
#+END_SRC

Like variables, outputs in modules perform the same function as they do in the
root module but are accessed in a different way. You can access a module's
output from the configuration that calls the module through the following
syntax: ~module.<MODULE NAME>.<OUTPUT NAME>~. Module outputs are read-only
attributes.

Now that you have created your module, return to the ~main.tf~ in your root
module and add a reference to the new module:

#+BEGIN_SRC tf
module "website_s3_bucket" {
  source = "./modules/aws-s3-static-website-bucket"

  bucket_name = "<UNIQUE BUCKET NAME>"

  tags = {
    Terraform   = "true"
    Environment = "dev"
  }
}
#+END_SRC

*** Define outputs

Earlier, you added several outputs to the ~aws-s3-static-website-bucket~ module,
making those values available to your root module configuration.

Add the following to the ~outputs.tf~ file in your root module directory (not
the one in ~modules/aws-s3-static-website-bucket~) to create additional outputs
for your S3 bucket.

#+BEGIN_SRC tf
# Output variable definitions

output "vpc_public_subnets" {
  description = "IDs of the VPC's public subnets"
  value       = module.vpc.public_subnets
}

output "ec2_instance_public_ips" {
  description = "Public IP addresses of EC2 instances"
  value       = module.ec2_instances[*].public_ip
}

output "website_bucket_arn" {
  description = "ARN of the bucket"
  value       = module.website_s3_bucket.arn
}

output "website_bucket_name" {
  description = "Name (id) of the bucket"
  value       = module.website_s3_bucket.name
}

output "website_bucket_domain" {
  description = "Domain name of the bucket"
  value       = module.website_s3_bucket.domain
}
#+END_SRC

*** Install the local module

Whenever you add a new module to a configuration, Terraform must install the
module before it can be used. Both the ~terraform get~ and ~terraform init~
commands will install and update modules. The ~terraform init~ command will also
initialize backends and install plugins.

*** Upload files to the bucket

You have now configured and used your own module to create a static website. You
may want to visit this static website. Right now there is nothing inside your
bucket, so there would be nothing to see if you visit the bucket's website. In
order to see any content, you will need to upload objects to your bucket.

E.g:

#+BEGIN_SRC bash :noeval
aws s3 cp modules/aws-s3-static-website-bucket/www/ s3://$(terraform output -raw website_bucket_name)/ --recursive
#+END_SRC

** Customize modules with object attributes

Terraform modules let you organize and re-use Terraform configuration. They make
your infrastructure deployments consistent and help your team adhere to your
organization's best practices. Input variables let module users customize
attributes of the module. You can define module attributes using strings,
numbers, booleans, lists, maps, and objects.

Object type attributes contain a fixed set of named values of different types.
Using objects in your modules lets you group related attributes together, making
it easier for users to understand how to use your module. You can make
attributes within objects optional, which make it easier for you to ship new
module versions without changing the variables that module users need to
define.

*** Work with object attributes

Instead of variable that are defined something like this in your ~variables.tf~
file:

#+BEGIN_SRC tf
variable "index_document_suffix" {
  description = "Suffix for index documents."
  type        = string
  default     = "index.html"
}
##...
variable "terraform_managed_files" {
  description = "Flag to indicate whether Terraform should upload files to the bucket."
  type        = bool
  default     = true
}

variable "www_path" {
  description = "Local absolute or relative path containing files to upload to website bucket."
  type        = string
  default     = null
}

variable "terraform_managed_files" {
  description = "Flag to indicate whether Terraform should upload files to the bucket."
  type        = bool
  default     = true
}
#+END_SRC

You can create an object instead to link related variables together:

#+BEGIN_SRC tf
variable "files" {
  description = "Configuration for website files."
  type = object({
    terraform_managed     = bool
    error_document_key    = optional(string, "error.html")
    index_document_suffix = optional(string, "index.html")
    www_path              = optional(string)
  })
}
#+END_SRC

The ~files~ variable defines an object with fields corresponding to the
variables you removed. Since it does not set a ~default~ value, it is required
whenever practitioners use your module. Objects map a specific set of named keys
to values. Keeping related attributes in a single object helps your users
understand how to use your module.

The ~terraform_managed~ field is required, while the other three are optional.

Both ~error_document_key~ and ~index_document_suffix~ fields configure default
values for the attributes after specifying that they are optional. Since no
default value is set for www_path, Terraform will set it to null, unless the
module user specifies a value for it.

You can now refer to these variables with ~var.files.<name>~, e.g.
~var.files.index_document_suffix~. The ~files~ variable can now be configured
when calling your module with e.g.:

#+BEGIN_SRC tf
files = {
  terraform_managed = false
}
# Or
files = {
  terraform_managed = true
  www_path          = "${path.root}/www"
}
# Or
files = {
  terraform_managed     = true
  www_path              = "${path.root}/www"
  index_document_suffix = "main.html"
  error_document_key    = "error.html"
}
#+END_SRC

*** Use a list of objects to configure CORS

Cross-Origin Resource Sharing (CORS) allows web developers to control where and
how users access resources in their website. CORS configuration limits access to
websites based on request headers, method, or originating domain. Add a new
variable to ~modules/aws-s3-static-website/variables.tf~ to control your S3
bucket's CORS configuration.

#+BEGIN_SRC tf
variable "cors_rules" {
  description = "List of CORS rules."
  type = list(object({
    allowed_headers = optional(set(string)),
    allowed_methods = set(string),
    allowed_origins = set(string),
    expose_headers  = optional(set(string)),
    max_age_seconds = optional(number)
  }))
  default = []
}
#+END_SRC

The ~cors_rules~ variable contains a list of objects. Since the default value is
an empty list (~[]~), users do not need to set this input variable to deploy the
module. When they do use it, they must set ~allowed_methods~ and
~allowed_origins~ for each object in the list; the other attributes are
optional. This matches the behavior of the ~aws_s3_bucket_cors_configuration~
resource you will use to configure CORS.

Use the ~cors_rules~ variable by adding a new resource:

#+BEGIN_SRC tf
resource "aws_s3_bucket_cors_configuration" "web" {
  count = length(var.cors_rules) > 0 ? 1 : 0

  bucket = aws_s3_bucket.web.id

  dynamic "cors_rule" {
    for_each = var.cors_rules

    content {
      allowed_headers = cors_rule.value["allowed_headers"]
      allowed_methods = cors_rule.value["allowed_methods"]
      allowed_origins = cors_rule.value["allowed_origins"]
      expose_headers  = cors_rule.value["expose_headers"]
      max_age_seconds = cors_rule.value["max_age_seconds"]
    }
  }
}
#+END_SRC

This resource uses the ~dynamic~ block to create a ~cors_rule~ block for each
item in the ~var.cors_rules~ list. When the list is empty, the ~count~
meta-argument will evaluate to ~0~, and Terraform will not provision this
resource. Otherwise, the ~dynamic~ block will create a CORS rule for each object
in the list. Since optional object attributes default to ~null~, Terraform will
not set values for them unless the module user specifies them.

** Handle multiple environments

Some Terraform projects start as a /monolith/, a Terraform project managed by a
single main configuration file in a single directory, with a single state file.
Small projects may be convenient to maintain this way. However, as your
infrastructure grows, restructuring your monolith into logical units will make
your Terraform configurations less confusing and safer to manage.

*** Separate states

State separation signals more mature usage of Terraform; with additional
maturity comes additional complexity. There are two primary methods to separate
state between environments: directories and workspaces.

To separate environments with potential configuration differences, use a
directory structure. Use workspaces for environments that do not greatly deviate
from one another, to avoid duplicating your configurations.

**** Separate states with different directories

By creating separate directories for each environment, you can shrink the blast
radius of your Terraform operations and ensure you will only modify intended
infrastructure. Terraform stores your state files on disk in their corresponding
configuration directories. Terraform operates only on the state and
configuration in the working directory by default.

Directory-separated environments rely on duplicate Terraform code. This may be
useful if you want to test changes in a development environment before promoting
them to production. However, the directory structure runs the risk of creating
drift between the environments over time. If you want to reconfigure a project
with a single state file into directory-separated states, you must perform
advanced state operations to move the resources.

After reorganizing your environments into directories, your file structure
should look like the one below, where ~assets~ is a directory containing
resources for both environments.

#+BEGIN_SRC
.
├── assets
│   ├── index.html
├── prod
│   ├── main.tf
│   ├── variables.tf
│   ├── terraform.tfstate
│   └── terraform.tfvars
└── dev
    ├── main.tf
    ├── variables.tf
    ├── terraform.tfstate
    └── terraform.tfvars

#+END_SRC

You can refer to the ~assets~ directory with
~file("${path.module}/../assets/index.html")~

You now do your terraform operations in the ~dev~ and ~prod~ directories
separately, including ~terraform init~.

**** Separate staes with workspaces

Workspace-separated environments use the same Terraform code but have different
state files, which is useful if you want your environments to stay as similar to
each other as possible, for example if you are providing development
infrastructure to a team that wants to simulate running in production.

However, you must manage your workspaces in the CLI and be aware of the
workspace you are working in to avoid accidentally performing operations on the
wrong environment.

All Terraform configurations start out in the ~default~ workspace. Type
~terraform workspace list~ to have Terraform print out the list of your
workspaces with the currently selected one denoted by a ~*~.

Using workspaces organizes the resources in your state file by environments.
Also outputs are handled per workspace. Create variables files for each
environment: ~dev.tfvars~ and ~prod.tfvars~.

***** Create environments

Create a new workspace in the Terraform CLI with the ~workspace~ command.

#+BEGIN_SRC tf
terraform workspace new dev
#+END_SRC

Any previous state files from your ~default~ workspace are hidden from your
~dev~ workspace, but your directory and file structure do not change.

Inititialize the directory:

#+BEGIN_SRC bash :noeval
terraform init
#+END_SRC

Apply the configuration:

#+BEGIN_SRC bash :noeval
terraform apply -var-file=dev.tfvars
#+END_SRC

Then create a ~prod~ environment:

#+BEGIN_SRC bash :noeval
terraform workspace new prod
#+END_SRC

Apply the configuration:

#+BEGIN_SRC
terraform apply -var-file=prod.tfvars
#+END_SRC

***** State storage in workspaces

When you use the default workspace with the local backend, your
~terraform.tfstate~ file is stored in the root directory of your Terraform
project. When you add additional workspaces your state location changes;
Terraform internals manage and store state files in the directory
~terraform.tfstate.d~.

Your directory will look similar to the one below.

#+BEGIN_SRC
.
├── README.md
├── assets
│   └── index.html
├── dev.tfvars
├── main.tf
├── outputs.tf
├── prod.tfvars
├── terraform.tfstate.d
│   ├── dev
│   │   └── terraform.tfstate
│   ├── prod
│   │   └── terraform.tfstate
├── terraform.tfvars
└── variables.tf
#+END_SRC

***** Destroy the environment

To destroy your infrastructure in a multiple workspace deployment, you must
select the intended workspace and run ~terraform destroy -var-file=~ with the
~.tfvars~ file that corresponds to your workspace.

#+BEGIN_SRC bash :noeval
terraform workspace select dev
terraform destroy -var-file=dev.tfvars
#+END_SRC

** Use configuration to move resources

As your Terraform configuration grows in complexity, updating resources becomes
more risky: an update to one resource may cause unintended changes to other
parts of your infrastructure. One way to address this is to refactor your
existing Terraform code into separate modules. In addition to limiting the scope
of potential changes, modules help abstract your resources, making your
configuration easier to understand.

When you move existing resources from a parent to a child module, your Terraform
resource IDs will change. Because of this, you must let Terraform know that you
intend to move resources rather than replace them, or Terraform will destroy and
recreate your resources with the new ID.

The ~moved~ configuration block lets you track your resource moves in the
configuration itself. With the ~moved~ configuration block, you can plan,
preview, and validate resource moves, enabling you to safely refactor your
configuration.

** Validate modules with custom conditions

Terraform lets you define custom conditions in your module configuration to
validate resources, data sources, and outputs. When planning and applying
changes to your infrastructure, Terraform evaluates these condition blocks and
reports an error if a condition fails. Terraform supports preconditions, which
it evaluates before it provisions the enclosing block, and postconditions, which
it evaluates afterward.

*** Add preconditions

Terraform allows you to add preconditions and postconditions to the lifecycle of
resource, data source, or output blocks. Terraform evaluates preconditions
before the enclosing block, validating that your configuration is compliant
before it applies it. Terraform evaluates post conditions after the enclosing
block, letting you confirm that the results of applied changes are compliant
before it applies the rest of your configuration.

E.g.

#+BEGIN_SRC tf
data "aws_ec2_instance_type" "app" {
  instance_type = var.aws_instance_type
}

resource "aws_instance" "app" {
  count = var.aws_instance_count

  instance_type = var.aws_instance_type
  ami           = var.aws_ami_id

  subnet_id              = var.aws_private_subnet_ids[count.index % length(var.aws_private_subnet_ids)]
  vpc_security_group_ids = [module.app_security_group.security_group_id]

  lifecycle {
    precondition {
      condition     = var.aws_instance_count % length(var.aws_private_subnet_ids) == 0
      error_message = "The number of instances (${var.aws_instance_count}) must be evenly divisible by the number of private subnets (${length(var.aws_private_subnet_ids)})."
    }

    precondition {
      condition     = data.aws_ec2_instance_type.app.ebs_optimized_support != "unsupported"
      error_message = "The EC2 instance type (${var.aws_instance_type}) must support EBS optimization."
    }
  }
}
#+END_SRC

The first precondition verifies that each private subnet contains the same
number of instances. It does so by dividing the number of instances by the
number of subnets, and checking that the remainder is ~0~. This condition
ensures that application traffic is spread evenly across the subnets used by
your application.

The second precondition verifies that the chosen EC2 instance type supports EBS
optimization. In order to do so, it accesses the instance type's
~ebs_optimized_support~ attribute from the data source.

Terraform reports errors whenever a condition fails, and will not continue to
plan or apply your configuration. You must resolve the errors before you can
successfully deploy this configuration.

*** Add a postcondition

#+BEGIN_SRC tf
data "aws_vpc" "app" {
  id = var.aws_vpc_id

  lifecycle {
    postcondition {
      condition     = self.enable_dns_support == true
      error_message = "The selected VPC must have DNS support enabled."
    }
  }
}
#+END_SRC

The postcondition refers to the data source using the ~self~ value. Terraform
will not create the VPC until you apply the example configuration, so it cannot
validate this condition until after it has begun provisioning your
infrastructure. When you run ~terraform apply~, Terraform will start applying
the configuration, and will create the VPC before it reads its attributes from
the data source. After it does so, it will evaluate the postcondition and report
an error if it fails.
