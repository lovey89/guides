* Table of Contents :TOC_3:QUOTE:
#+BEGIN_QUOTE
- [[#links][Links]]
- [[#getting-started][Getting started]]
  - [[#install][Install]]
    - [[#install-on-the-managed-node][Install on the managed node]]
  - [[#configure-ansible][Configure ansible]]
    - [[#a-note-about-comments-in-ansiblecfg][A note about comments in ~ansible.cfg~]]
  - [[#create-docker-target-environment][Create docker target environment]]
    - [[#ubuntu-environment][Ubuntu environment]]
    - [[#fedora-environment][Fedora environment]]
    - [[#create-multiple-containers-with-the-docker-compose-command][Create multiple containers with the ~docker compose~ command]]
- [[#building-an-inventory][Building an inventory]]
  - [[#intro][Intro]]
    - [[#variables][Variables]]
    - [[#metagroups][Metagroups]]
    - [[#example][Example]]
  - [[#how-to-build-your-inventory][How to build your inventory]]
    - [[#adding-ranges-of-hosts][Adding ranges of hosts]]
    - [[#passing-multiple-inventory-sources][Passing multiple inventory sources]]
    - [[#organizing-inventory-in-a-directory][Organizing inventory in a directory]]
    - [[#adding-variables-to-inventory][Adding variables to inventory]]
  - [[#patterns-targeting-hosts-and-groups][Patterns: targeting hosts and groups]]
    - [[#using-patterns][Using patterns]]
    - [[#common-patterns][Common patterns]]
    - [[#pattern-processing-order][Pattern processing order]]
    - [[#limit-a-run-to-a-subset-of-hosts][Limit a run to a subset of hosts]]
- [[#using-ansible-command-line-tools][Using Ansible command line tools]]
  - [[#introduction-to-ad-hoc-commands][Introduction to ad hoc commands]]
    - [[#use-cases-for-ad-hoc-tasks][Use cases for ad hoc tasks]]
- [[#playbooks][Playbooks]]
  - [[#ansible-playbooks][Ansible playbooks]]
    - [[#playbook-syntax][Playbook syntax]]
    - [[#playbook-execution][Playbook execution]]
    - [[#task-execution][Task execution]]
    - [[#desired-state-and-idempotency][Desired state and 'idempotency']]
    - [[#running-playbooks][Running playbooks]]
    - [[#verifying-playbooks][Verifying playbooks]]
  - [[#working-with-playbooks][Working with playbooks]]
    - [[#templating-with-jinja2][Templating with Jinja2]]
    - [[#example-1][Example]]
- [[#old][Old]]
  - [[#ad-hoc-commands][Ad-hoc commands]]
  - [[#module-documentation][Module documentation]]
  - [[#playbooks-1][Playbooks]]
    - [[#example-1-1][Example 1]]
    - [[#example-2][Example 2]]
    - [[#example-3][Example 3]]
    - [[#example-4][Example 4]]
    - [[#other-keywords-to-investigate][Other keywords to investigate]]
  - [[#ansible-vault][Ansible vault]]
  - [[#playbook-organization][Playbook organization]]
  - [[#roles][Roles]]
  - [[#config][Config]]
    - [[#ansiblecfg][~ansible.cfg~]]
    - [[#inventory-format][Inventory format]]
#+END_QUOTE

* Links

- https://www.jeffgeerling.com/blog/2020/ansible-101-jeff-geerling-youtube-streaming-series (ansible 2.9)?
- https://docs.ansible.com/ansible/latest/getting_started/basic_concepts.html (glossary)
- https://docs.ansible.com/ansible/latest/reference_appendices/playbooks_keywords.html#playbook-keywords
- https://docs.ansible.com/ansible/latest/reference_appendices/general_precedence.html#general-precedence-rules

* Getting started
** Install

#+BEGIN_SRC bash :noeval
# For fedora
sudo dnf install ansible

# For osx
brew install ansible

# Verify install
ansible --version
#+END_SRC

*** Install on the managed node

Ansible does not have to be installed but you need python and a user account
that can connect through SSH.

** Configure ansible

You don't have to follow these steps as there is already a [[file:ansible.cfg][ansible.cfg]] created.

You can generate an Ansible configuration file, ~ansible.cfg~, that lists all
default settings as follows:

#+BEGIN_SRC bash :noeval
ansible-config init --disabled > ansible.cfg
#+END_SRC

Include available plugins to create a more complete Ansible configuration as
follows:

#+BEGIN_SRC bash :noeval
ansible-config init --disabled -t all > ansible.cfg
#+END_SRC

The configuration files are searched for in the following order:

- ~ANSIBLE_CONFIG~ (environment variable if set)
- ~ansible.cfg~ (in the current directory)
- ~~/.ansible.cfg~ (in the home directory)
- ~/etc/ansible/ansible.cfg~

Not all configuration options are present in the command line, just the ones
deemed most useful or common. Settings in the command line will override those
passed through the configuration file and the environment.

For more information see the [[https://docs.ansible.com/ansible/latest/reference_appendices/config.html#ansible-configuration-settings][Ansible Configuration Settings documentation]].

*** A note about comments in ~ansible.cfg~

The configuration file is one variant of an ~.ini~ format. Both the hash sign
(~#~) and semicolon (~;~) are allowed as comment markers when the comment starts
the line. However, if the comment is inline with regular values, only the
semicolon is allowed to introduce the comment.

** Create docker target environment
*** Ubuntu environment

#+BEGIN_SRC bash :noeval
cd dockerenv/ubuntu
ssh-keygen -b 4096 -t rsa -f ./id_rsa -N ""
docker build -t ubuntuansibletarget:latest .

# Start env. I use --init because it seems to respect ctrl-c when I want to exit
docker run --rm -p 2022:22 --init ubuntuansibletarget:latest

# Test connection
ssh -o "IdentitiesOnly=yes" -o "StrictHostKeyChecking=no" -o "UserKnownHostsFile=/dev/null" -i id_rsa -p 2022 ansibleuser@localhost
#+END_SRC

*** Fedora environment

#+BEGIN_SRC bash :noeval
cd dockerenv/fedora
ssh-keygen -b 4096 -t rsa -f ./id_rsa -N ""
docker build -t fedoraansibletarget:latest .

# Start env. I use --init because it seems to respect ctrl-c when I want to exit
docker run --rm -p 3022:22 --init fedoraansibletarget:latest

# Test connection
ssh -o "IdentitiesOnly=yes" -o "StrictHostKeyChecking=no" -o "UserKnownHostsFile=/dev/null" -i id_rsa -p 3022 ansibleuser@localhost
#+END_SRC

*** Create multiple containers with the ~docker compose~ command

After the containers above has been built you can create multiple of them by
running:

#+BEGIN_SRC bash :noeval
cd dockerenv
docker compose up ; docker compose down
# or
cd dockerenv
./startenv.sh
#+END_SRC

This will run the containers in the foreground and will remove the containers
automatically when stopped.

Try connecting to each machine:

#+BEGIN_SRC bash :noeval
ssh -o "IdentitiesOnly=yes" -o "StrictHostKeyChecking=no" -o "UserKnownHostsFile=/dev/null" -i ubuntu/id_rsa -p 2022 ansibleuser@localhost whoami
ssh -o "IdentitiesOnly=yes" -o "StrictHostKeyChecking=no" -o "UserKnownHostsFile=/dev/null" -i ubuntu/id_rsa -p 2122 ansibleuser@localhost whoami
ssh -o "IdentitiesOnly=yes" -o "StrictHostKeyChecking=no" -o "UserKnownHostsFile=/dev/null" -i fedora/id_rsa -p 3022 ansibleuser@localhost whoami
ssh -o "IdentitiesOnly=yes" -o "StrictHostKeyChecking=no" -o "UserKnownHostsFile=/dev/null" -i fedora/id_rsa -p 3122 ansibleuser@localhost whoami
#+END_SRC

* Building an inventory
** Intro

The ~inventory.yaml~ basic format looks something like this:

#+BEGIN_SRC yaml
myhosts: # Group name
  hosts:
    my_host_01:
      ansible_host: 192.0.2.50 # Ip for the my_host_01 alias
    my_host_02:
      ansible_host: 192.0.2.51
    my_host_03:
      ansible_host: 192.0.2.52
#+END_SRC

*** Variables

Variables set values for managed nodes, such as the IP address, FQDN, operating
system, and SSH user, so you do not need to pass them when running Ansible
commands.

Variables can apply to specific hosts.

#+BEGIN_SRC yaml
webservers:
  hosts:
    webserver01:
      ansible_host: 192.0.2.140
      http_port: 80
    webserver02:
      ansible_host: 192.0.2.150
      http_port: 443
#+END_SRC

Variables can also apply to all hosts in a group:

#+BEGIN_SRC yaml
webservers:
  hosts:
    webserver01:
      ansible_host: 192.0.2.140
      http_port: 80
    webserver02:
      ansible_host: 192.0.2.150
      http_port: 443
  vars:
    ansible_user: my_server_user
#+END_SRC

*** Metagroups

Create a metagroup that organizes multiple groups in your inventory with the following syntax:

#+BEGIN_SRC yaml
metagroupname:
  children:
#+END_SRC

The following inventory illustrates a basic structure for a data center. This
example inventory contains a ~network~ metagroup that includes all network
devices and a ~datacenter~ metagroup that includes the ~network~ group and all
webservers.

#+BEGIN_SRC yaml
leafs:
  hosts:
    leaf01:
      ansible_host: 192.0.2.100
    leaf02:
      ansible_host: 192.0.2.110

spines:
  hosts:
    spine01:
      ansible_host: 192.0.2.120
    spine02:
      ansible_host: 192.0.2.130

network:
  children:
    leafs:
    spines:

webservers:
  hosts:
    webserver01:
      ansible_host: 192.0.2.140
    webserver02:
      ansible_host: 192.0.2.150

datacenter:
  children:
    network:
    webservers:
#+END_SRC

*** Example

Start checking the inventory file that has been configured for the container
defined earlier:

#+BEGIN_SRC bash :noeval
ansible-inventory -i inventory/inventory.yaml --list
# Because we have a ansible.cfg file which points to the inventory file we can
# just run
ansible-inventory --list
#+END_SRC

In our inventory I ahve defined some variables for each host as we don't want to
use the defaults.

Try pinging each of them:

#+BEGIN_SRC bash :noeval
ansible all -m ping -i inventory/inventory.yaml
# Because we have a ansible.cfg file which points to the inventory file we can
# just run
ansible all -m ping
#+END_SRC

The inventory can be in both ~.yaml~ and ~.ini~ format. I prefer ~.yaml~ and
will only use ~.yaml~ in my examples.

** How to build your inventory

Ansible automates tasks on managed nodes or “hosts” in your infrastructure,
using a list or group of lists known as inventory. You can pass host names at
the command line, but most Ansible users create inventory files. Your inventory
defines the managed nodes you automate, with groups so you can run automation
tasks on multiple hosts at the same time. Once your inventory is defined, you
use patterns to select the hosts or groups you want Ansible to run against.

The default location for this file is ~/etc/ansible/hosts~. You can specify a
different inventory file at the command line using the ~-i <path>~ option or in
a configuration file using the ~inventory~ key.

As your inventory expands, you may need more than a single file to organize your
hosts and groups. Some alternatives are:

- You can create a directory with multiple inventory files
- You can pull inventory dynamically. For example, you can use a dynamic
  inventory plugin to list resources in one or more cloud providers
- You can use multiple sources for inventory, including both dynamic inventory
  and static files

*** Adding ranges of hosts

If you have a lot of hosts with a similar pattern, you can add them as a range
rather than listing each hostname separately:

#+BEGIN_SRC yaml
# ...
  webservers:
    hosts:
      www[01:50].example.com:
# ...
  webservers:
    hosts:
      www[01:50:2].example.com: # To only have all odd numbers
#+END_SRC

For numeric patterns, leading zeros can be included or removed, as desired.
Ranges are inclusive. You can also define alphabetic ranges:

#+BEGIN_SRC yaml
# ...
  databases:
    hosts:
      db-[a:f].example.com:
#+END_SRC

*** Passing multiple inventory sources

To target two inventory sources from the command line:

#+BEGIN_SRC bash :noeval
ansible-playbook get_logs.yml -i staging -i production
#+END_SRC

*** Organizing inventory in a directory

You can consolidate multiple inventory sources in a single directory. The
simplest version of this is a directory with multiple files instead of a single
inventory file.

You can also combine multiple inventory source types in an inventory directory.
This can be useful for combining static and dynamic hosts and managing them as
one inventory. The following inventory directory combines an inventory plugin
source, a dynamic inventory script, and a file with static hosts:

#+BEGIN_SRC
inventory/
  openstack.yml          # configure inventory plugin to get hosts from OpenStack cloud
  dynamic-inventory.py   # add additional hosts with dynamic inventory script
  on-prem                # add static hosts and groups
  parent-groups          # add static hosts and groups
#+END_SRC

You can target this inventory directory as follows:

#+BEGIN_SRC bash :noeval
ansible-playbook example.yml -i inventory
#+END_SRC

*** Adding variables to inventory

You can store variable values that relate to a specific host or group in
inventory. To start with, you may add variables directly to the hosts and groups
in your main inventory file.

**** Assigning a variable to one machine: host variables

You can easily assign a variable to a single host and then use it later in
playbooks. You can do this directly in your inventory file.

#+BEGIN_SRC yaml
atlanta:
  hosts:
    host1:
      http_port: 80
      maxRequestsPerChild: 808
    host2:
      http_port: 303
      maxRequestsPerChild: 909
#+END_SRC

Connection variables also work well as host variables:

#+BEGIN_SRC yaml
my_group:
  hosts:
    other1.example.com:
      ansible_connection: ssh
      ansible_user: myuser
    other2.example.com:
      ansible_connection: ssh
      ansible_user: myotheruser
#+END_SRC

**** Inventory aliases

You can also define aliases in your inventory using host variables:

#+BEGIN_SRC yaml
# ...
  hosts:
    jumper:
      ansible_port: 5555
      ansible_host: 192.0.2.50
#+END_SRC

In this example, running Ansible against the host alias ~jumper~ will connect to
~192.0.2.50~ on port ~5555~. In previous examples we have defined the host/ip
instead of an alias. In our [[file:inventory/inventory.yaml][inventory.yaml]] we use aliases since all machines are
located on the same machine (~localhost~).

**** Assigning a variable to many machines: group variables

If all hosts in a group share a variable value, you can apply that variable to
an entire group at once.

#+BEGIN_SRC yaml
atlanta:
  hosts:
    host1:
    host2:
  vars:
    ntp_server: ntp.atlanta.example.com
    proxy: proxy.atlanta.example.com
#+END_SRC

Group variables are a convenient way to apply variables to multiple hosts at
once. Before executing, however, Ansible always flattens variables, including
inventory variables, to the host level. If a host is a member of multiple
groups, Ansible reads variable values from all of those groups. If you assign
different values to the same variable in different groups, Ansible chooses which
value to use based on internal rules for merging (see below).

**** Inheriting variable values: group variables for groups of groups

You can apply variables to parent groups (nested groups or groups of groups) as
well as to child groups.

#+BEGIN_SRC yaml
usa:
  children:
    southeast: # Group level 1
      children:
        atlanta: # Group level 2
          hosts:
            host1:
            host2:
        raleigh: # Group level 2
          hosts:
            host2:
            host3:
      vars:
        some_server: foo.southeast.example.com
        halon_system_timeout: 30
        self_destruct_countdown: 60
        escape_pods: 2
    northeast: # Group level 1
    northwest: # Group level 1
    southwest: # Group level 1
#+END_SRC

A child group’s variables will have higher precedence (override) than a parent
group’s variables.

**** Organizing host and group variables

Although you can store variables in the main inventory file, storing separate
host and group variables files may help you organize your variable values more
easily. You can also use lists and hash data in host and group variables files,
which you cannot do in your main inventory file.

Valid file extensions include ~.yml~, ~.yaml~, ~.json~, or no file extension.

Ansible loads host and group variable files by searching paths relative to the
inventory file or the playbook file. If your inventory file at
~/etc/ansible/hosts~ contains a host named ~foosball~ that belongs to two
groups, ~raleigh~ and ~webservers~, that host will use variables in YAML files
at the following locations:

#+BEGIN_SRC
/etc/ansible/group_vars/raleigh # can optionally end in '.yml', '.yaml', or '.json'
/etc/ansible/group_vars/webservers
/etc/ansible/host_vars/foosball
#+END_SRC

For example, if you group hosts in your inventory by datacenter, and each
datacenter uses its own NTP server and database server, you can create a file
called ~/etc/ansible/group_vars/raleigh~ to store the variables for the raleigh
group:

#+BEGIN_SRC yaml
---
ntp_server: acme.example.org
database_server: storage.example.org
#+END_SRC

You can also create /directories/ named after your groups or hosts. Ansible will
read all the files in these directories in lexicographical order. An example
with the ~raleigh~ group:

#+BEGIN_SRC
/etc/ansible/group_vars/raleigh/db_settings
/etc/ansible/group_vars/raleigh/cluster_settings
#+END_SRC

All hosts in the ~raleigh~ group will have the variables defined in these files
available to them. This can be very useful to keep your variables organized when
a single file gets too big, or when you want to use Ansible Vault on some group
variables.

For ~ansible-playbook~ you can also add ~group_vars/~ and ~host_vars/~
directories to your playbook directory. Other Ansible commands (for example,
~ansible~, ~ansible-console~, and so on) will only look for ~group_vars/~ and
~host_vars/~ in the inventory directory. If you want other commands to load
group and host variables from a playbook directory, you must provide the
~--playbook-dir~ option on the command line. If you load inventory files from
both the playbook directory and the inventory directory, variables in the
playbook directory will override variables set in the inventory directory.

**** How variables are merged

By default, variables are merged/flattened to the specific host before a play is
run. This keeps Ansible focused on the Host and Task, so groups do not survive
outside of inventory and host matching. The order/precedence is (from lowest to
highest):

- all group (because it is the "parent" of all other groups)
- parent group
- child group
- host

By default, Ansible merges groups at the same parent/child level in ASCII order,
and variables from the last group loaded overwrite variables from the previous
groups. For example, an ~a_group~ will be merged with ~b_group~ and ~b_group~
vars that match will overwrite the ones in ~a_group~.

**** Managing inventory variable load order

When using multiple inventory sources, keep in mind that any variable conflicts
are resolved according to the merge rules described above and
[[https://docs.ansible.com/ansible/latest/playbook_guide/playbooks_variables.html#ansible-variable-precedence][Variable precedence: Where should I put a variable?]].

When you pass multiple inventory sources at the command line, Ansible merges
variables in the order you pass those parameters. If ~[all:vars]~ in staging
inventory defines ~myvar = 1~ and production inventory defines ~myvar = 2~,
then:

- Pass ~-i staging -i production~ to run the playbook with ~myvar = 2~
- Pass ~-i production -i staging~ to run the playbook with ~myvar = 1~

When you put multiple inventory sources in a directory, Ansible merges them in
ASCII order according to the file names. You can control the load order by
adding prefixes to the files:

#+BEGIN_SRC
inventory/
  01-openstack.yml          # configure inventory plugin to get hosts from Openstack cloud
  02-dynamic-inventory.py   # add additional hosts with dynamic inventory script
  03-static-inventory       # add static hosts
  group_vars/
    all.yml                 # assign variables to all hosts
#+END_SRC

If ~01-openstack.yml~ defines ~myvar = 1~ for the group ~all~,
~02-dynamic-inventory.py~ defines ~myvar = 2~, and ~03-static-inventory~ defines
~myvar = 3~, the playbook will be run with ~myvar = 3~.

**** Connecting to hosts: behavioral inventory parameters

As mentioned earlier, there are variables that controls how Ansible interacts
with remote hosts:

For a full list see https://docs.ansible.com/ansible/latest/inventory_guide/intro_inventory.html#connecting-to-hosts-behavioral-inventory-parameters

** Patterns: targeting hosts and groups

When you execute Ansible through an ad hoc command or by running a playbook, you
must choose which managed nodes or groups you want to execute against. Patterns
let you run commands and playbooks against specific hosts and/or groups in your
inventory. An Ansible pattern can refer to a single host, an IP address, an
inventory group, a set of groups, or all hosts in your inventory. Patterns are
highly flexible - you can exclude or require subsets of hosts, use wildcards or
regular expressions, and more. Ansible executes on all inventory hosts included
in the pattern.

*** Using patterns

You use a pattern almost any time you execute an ad hoc command or a playbook.
The pattern is the only element of an ad hoc command that has no flag. It is
usually the second element:

#+BEGIN_SRC bash :noeval
ansible <pattern> -m <module_name> -a "<module options>"
#+END_SRC

In a playbook, the pattern is the content of the ~hosts:~ line for each play:

#+BEGIN_SRC yaml
- name: <play_name>
  hosts: <pattern>
#+END_SRC

*** Common patterns

| Description            | Pattern(s)                       | Targets                                             |
|------------------------+----------------------------------+-----------------------------------------------------|
| All hosts              | ~all~ (or ~*~)                   |                                                     |
| One host               | ~host1~                          |                                                     |
| Multiple hosts         | ~host1:host2~ (or ~host1,host2~) |                                                     |
| One group              | ~webservers~                     |                                                     |
| Multiple groups        | ~webservers:dbservers~           | all hosts in webservers plus all hosts in dbservers |
| Excluding groups       | ~webservers:!atlanta~            | all hosts in webservers except those in atlanta     |
| Intersection of groups | ~webservers:&staging~            | any hosts in webservers that are also in staging    |

You can use either a comma (~,~) or a colon (~:~) to separate a list of hosts.
The comma is preferred when dealing with ranges and IPv6 addresses.

You can use wildcard patterns with FQDNs or IP addresses, as long as the hosts
are named in your inventory by FQDN or IP address:

#+BEGIN_SRC
192.0.*
*.example.com
*.com
#+END_SRC

If you have defined a host by alias you must refer to it with the alias name
(wildcard patterns are also allowed).

You can only refer to hosts or groups listed in your inventory. This includes if
you refer to IP addresses and FQDNs.

*** Pattern processing order

The processing happens in the following order:

1. ~:~ and ~,~
2. ~&~ (intersection)
3. ~!~ (exclusion)

There are more pattern rules described at:
https://docs.ansible.com/ansible/latest/inventory_guide/intro_patterns.html

*** Limit a run to a subset of hosts

You can change the behavior of the patterns defined in playbook using
command-line options. You can also limit the hosts you target on a particular
run with the ~--limit~ or ~-l~ flag.

E.g.

#+BEGIN_SRC bash :noeval
ansible-playbook site.yml --limit datacenter2
#+END_SRC

This command will limit the playbook to the ~datacenter2~ pattern. It will be
the intersection of what is defined in the ~hosts:~ field in the playbook with
what is provided by the ~--limit~ (or ~-l~) option.

Finally, you can use ~--limit~ to read the list of hosts from a file by
prefixing the file name with ~@~:

#+BEGIN_SRC bash :noeval
ansible-playbook site.yml --limit @retry_hosts.txt
#+END_SRC

If [[https://docs.ansible.com/ansible/latest/reference_appendices/config.html#retry-files-enabled][RETRY_FILES_ENABLED]] is set to ~True~, a ~.retry~ file will be created after
the ~ansible-playbook~ run containing a list of failed hosts from all plays.
This file is overwritten each time ~ansible-playbook~ finishes running.

#+BEGIN_SRC bash :noeval
ansible-playbook site.yml --limit @site.retry
#+END_SRC

* Using Ansible command line tools

An Ansible ad hoc command uses the ~/usr/bin/ansible~ command-line tool to
automate a single task on one or more managed nodes. ad hoc commands are quick
and easy, but they are not reusable.

** Introduction to ad hoc commands

An ad hoc command looks like this:

#+BEGIN_SRC bash :noeval
ansible [pattern] -m [module] -a "[module options]"
#+END_SRC

The ~-a~ option accepts options either through the ~key=value~ syntax or a JSON
string starting with ~{~ and ending with ~}~ for more complex option structure.

*** Use cases for ad hoc tasks

ad hoc tasks can be used to reboot servers, copy files, manage packages and
users, and much more. You can use any Ansible module in an ad hoc task. ad hoc
tasks, like playbooks, use a declarative model, calculating and executing the
actions required to reach a specified final state. They achieve a form of
idempotence by checking the current state before they begin and doing nothing
unless the current state is different from the specified final state.

**** Running a command on the servers

The default module for the ~ansible~ command-line utility is the
[[https://docs.ansible.com/ansible/latest/collections/ansible/builtin/command_module.html#command-module][ansible.builtin.command module]]. The commands below will all be run using the
prepared [[file:inventory/inventory.yaml][inventory.yaml]] file. We we use the ~all~ group but you can replace it
with e.g. ~ubuntus~ or ~fedoras~.

To print the user of each target you can run:

#+BEGIN_SRC bash :noeval
ansible all -a "whoami"
#+END_SRC

You can also use variables:

#+BEGIN_SRC bash :noeval
ansible all -a 'echo $PATH' # Notice the quoting to not expand outside ansible
#+END_SRC

In some cases you may need to escalate your privileges. This can be done with
the ~--become~ flag:

#+BEGIN_SRC bash :noeval
ansible all -a "whoami" --become [--ask-become-pass]
#+END_SRC

If you add ~--ask-become-pass~ or ~-K~, Ansible prompts you for the password to
use for privilege escalation (e.g. ~sudo~).

By default, Ansible uses only five simultaneous processes. If you have more
hosts than the value set for the fork count, it can increase the time it takes
for Ansible to communicate with the hosts. To increase the number of
simultaneous processes you can use the ~-f~ option. E.g.:

#+BEGIN_SRC bash :noeval
ansible all -a "whoami" -f 10
#+END_SRC

To print the content of ~/etc/os-release~ of each target you can run:

#+BEGIN_SRC bash :noeval
ansible all -a "cat /etc/os-release"
#+END_SRC

This prints a lot of information the ~command~ module doesn't support extended
shell syntaxes like piping and redirects (although shell variables will always
work). If your command requires shell-specific syntax, use the
~ansible.builtin.shell~ module instead.

#+BEGIN_SRC bash :noeval
ansible all -m ansible.builtin.shell -a "cat /etc/os-release | grep PRETTY_NAME"
#+END_SRC

**** Managing files

An ad hoc task can harness the power of Ansible and SCP to transfer many files
to multiple machines in parallel. To transfer a file directly to all servers:

#+BEGIN_SRC bash :noeval
ansible all -m ansible.builtin.shell -a "ls -la host_file" # Verify it doesn't exist
ansible all -m ansible.builtin.copy -a "src=/etc/hosts dest=~/host_file"
ansible all -m ansible.builtin.shell -a "ls -la host_file" # Verify it exists
#+END_SRC

Another module that handles files is the [[https://docs.ansible.com/ansible/latest/collections/ansible/builtin/template_module.html#template-module][ansible.builtin.template module]].

The [[https://docs.ansible.com/ansible/latest/collections/ansible/builtin/file_module.html#file-module][ansible.builtin.file module]] allows changing ownership and permissions on
files. These same options can be passed directly to the ~copy~ module as well:

#+BEGIN_SRC bash :noeval
ansible all -m ansible.builtin.file -a "dest=/home/ansibleuser/host_file mode=600 owner=root group=root" --become
ansible all -m ansible.builtin.shell -a "ls -la host_file" # Verify ownership and permission
#+END_SRC

We can also create directories with the ~file~ module (similar to ~mkdir -p~):

#+BEGIN_SRC bash :noeval
ansible all -m ansible.builtin.file -a "dest=/home/ansibleuser/dir/subdir mode=755 owner=ansibleuser group=ansibleuser state=directory"
ansible all -m ansible.builtin.shell -a "ls -lad dir/subdir" # Verify the dir exists
#+END_SRC

You can also remove directories:

#+BEGIN_SRC bash :noeval
ansible all -m ansible.builtin.file -a "dest=/home/ansibleuser/dir state=absent"
ansible all -m ansible.builtin.shell -a "ls -lad dir" # Verify the dir is removed
#+END_SRC

**** Managing packages

You might also use an ad hoc task to install, update, or remove packages on
managed nodes using a package management module. Package management modules
support common functions to install, remove, and generally manage packages. Some
specific functions for a package manager might not be present in the Ansible
module since they are not part of general package management.

There is a ~yum~ module that won't work for our ubuntu containers and also an
~apt~ module that won't work for our fedora containers. But there is a more
generic ~package~ module we can use:

#+BEGIN_SRC bash :noeval
ansible all -m ansible.builtin.package -a "name=vim state=present" --become
#+END_SRC

You can also define a certain version:

#+BEGIN_SRC bash :noeval
ansible all -m ansible.builtin.package -a "name=vim-2:9.1 state=present" --become
#+END_SRC

To ensure a package is at the latest version:

#+BEGIN_SRC bash :noeval
ansible all -m ansible.builtin.package -a "name=vim state=latest" --become
#+END_SRC

To install or ensure that something is not installed:

#+BEGIN_SRC bash :noeval
ansible all -m ansible.builtin.package -a "name=vim state=absent" --become
#+END_SRC

**** Managing users and groups

With the [[https://docs.ansible.com/ansible/latest/collections/ansible/builtin/user_module.html#user-module][ansible.builtin.user module]] you can create, manage, and remove user
accounts on your managed nodes with ad hoc tasks:

#+BEGIN_SRC bash :noeval
# Create a user with username 'new_user' and password 'secret'
ansible all -m ansible.builtin.user -a "name=new_user password=$(echo secret | mkpasswd --method=sha-512 -s)" --become
# Verify on ubuntu1 that a user is created (username is secret):
ssh -o "StrictHostKeyChecking=no" -o "UserKnownHostsFile=/dev/null" -p 2122 new_user@localhost whoami
# Verify on fedora1 that a user is created (username is secret):
ssh -o "StrictHostKeyChecking=no" -o "UserKnownHostsFile=/dev/null" -p 3122 new_user@localhost whoami

# Remove the user
ansible all -m ansible.builtin.user -a "name=new_user state=absent" --become
#+END_SRC

**** Managing services

Ensure (or start) a service is started on all servers:

#+BEGIN_SRC bash :noeval
ansible fedoras -m ansible.builtin.package -a "name=httpd state=present" --become
ansible fedoras -m ansible.builtin.service -a "name=httpd state=started" --become

ansible ubuntus -m ansible.builtin.package -a "name=apache2 state=present" --become
ansible ubuntus -m ansible.builtin.service -a "name=apache2 state=started" --become
#+END_SRC

Verify that it's working by visiting:

- http://localhost:2080
- http://localhost:2180
- http://localhost:3080
- http://localhost:3180

You can restart a service:

#+BEGIN_SRC bash :noeval
ansible fedoras -m ansible.builtin.service -a "name=httpd state=restarted" --become
#+END_SRC

And ensure that a service is stopped (or stop it):

#+BEGIN_SRC bash :noeval
ansible fedoras -m ansible.builtin.service -a "name=httpd state=stopped" --become
#+END_SRC

**** Gathering facts

Facts represent discovered variables about a system. You can use facts to
implement conditional execution of tasks but also just to get ad hoc information
about your systems. To see all facts use the [[https://docs.ansible.com/ansible/latest/collections/ansible/builtin/setup_module.html#setup-module][ansible.builtin.setup module]]:

#+BEGIN_SRC bash :noeval
ansible all -m ansible.builtin.setup
#+END_SRC

**** Check mode (dry run)

In check mode, Ansible does not make any changes to remote systems. Ansible
prints the commands only. It does not run the commands. You activate it with the
~-C~ or ~--check~ option.

#+BEGIN_SRC bash :noeval
ansible all -m copy -a "content=foo dest=/root/bar.txt" -C
#+END_SRC

* Playbooks

Playbooks are automation blueprints, in ~.yaml~ format, that Ansible uses to
deploy and configure managed nodes.

- Playbook :: A list of plays that define the order in which Ansible performs
  operations, from top to bottom, to achieve an overall goal.
- Play :: An ordered list of tasks that maps to managed nodes in an inventory.
- Task :: A reference to a single module that defines the operations that
  Ansible performs.
- Module :: A unit of code or binary that Ansible runs on managed nodes. Ansible
  modules are grouped in collections with a Fully Qualified Collection Name
  (FQCN) for each module.

Try running the following playbook:

[[file:examples/001_hello_world.yaml][001_hello_world.yaml]]

#+BEGIN_SRC yaml
- name: My first play
  hosts: ubuntus # Run on all machines in the ubuntus group
  tasks:
   - name: Ping my hosts
     ansible.builtin.ping:

   - name: Print message
     ansible.builtin.debug:
      msg: Hello world
#+END_SRC

Run it with:

#+BEGIN_SRC bash :noeval
ansible-playbook examples/001_hello_world.yaml
#+END_SRC

In the output you will see your tasks being run as well as an ~Gathering Facts~
task that is run implicitly. By default, Ansible gathers information about your
inventory that it can use in the playbook.

Th play recap summarizes the results of all tasks in the playbook per host. In
this example, there are three tasks so ~ok=3~ indicates that each task ran
successfully.

** Ansible playbooks

Ansible Playbooks offer a repeatable, reusable, simple configuration management
and multi-machine deployment system, one that is well suited to deploying
complex applications. If you need to execute a task with Ansible more than once,
write a playbook and put it under source control. Then you can use the playbook
to push out new configuration or confirm the configuration of remote systems.

Playbooks can:

- declare configurations
- orchestrate steps of any manual ordered process, on multiple sets of machines,
  in a defined order
- launch tasks synchronously or asynchronously

*** Playbook syntax

A playbook is composed of one or more /plays/ in an ordered list. Each play
executes part of the overall goal of the playbook, running one or more tasks.
Each task calls an Ansible module.

*** Playbook execution

A playbook runs in order from top to bottom. Within each play, tasks also run in
order from top to bottom. Playbooks with multiple plays can orchestrate
multi-machine deployments, running one play on your webservers, then another
play on your database servers, then a third play on your network infrastructure,
and so on. At a minimum, each play defines two things:

- the managed nodes to target, using a pattern
- at least one task to execute

In this example, the first play targets the web servers; the second play targets
the database servers.

#+BEGIN_SRC yaml
---
- name: Update web servers
  hosts: webservers
  remote_user: root

  tasks:
  - name: Ensure apache is at the latest version
    ansible.builtin.yum:
      name: httpd
      state: latest

  - name: Write the apache config file
    ansible.builtin.template:
      src: /srv/httpd.j2
      dest: /etc/httpd.conf

- name: Update db servers
  hosts: databases
  remote_user: root

  tasks:
  - name: Ensure postgresql is at the latest version
    ansible.builtin.yum:
      name: postgresql
      state: latest

  - name: Ensure that postgresql is started
    ansible.builtin.service:
      name: postgresql
      state: started
#+END_SRC

Your playbook can include more than just a hosts line and tasks. See more about
[[https://docs.ansible.com/ansible/latest/reference_appendices/playbooks_keywords.html#playbook-keywords][Playbook Keywords]].

*** Task execution

By default, Ansible executes each task in order, one at a time, against all
machines matched by the host pattern. Each task executes a module with specific
arguments. When a task has executed on all target machines, Ansible moves on to
the next task. If a task fails on a host, Ansible takes that host out of the
rotation for the rest of the playbook.

*** Desired state and 'idempotency'

Most Ansible modules check whether the desired final state has already been
achieved, and exit without performing any actions if that state has been
achieved, so that repeating the task does not change the final state. Modules
that behave this way are often called ‘idempotent.’ Whether you run a playbook
once, or multiple times, the outcome should be the same. However, not all
playbooks and not all modules behave this way. If you are unsure, test your
playbooks in a sandbox environment before running them multiple times in
production.

*** Running playbooks

Use the ~ansible-playbook~ command:

#+BEGIN_SRC bash :noeval
ansible-playbook playbook.yml
#+END_SRC

Use the ~--verbose~ flag when running your playbook to see detailed output from
successful modules as well as unsuccessful ones.

**** Running playbooks in check mode

Ansible’s check mode allows you to execute a playbook without applying any
alterations to your systems. You can use check mode to test playbooks before
implementing them in a production environment.

To run a playbook in check mode, you can pass the ~-C~ or ~--check~ flag to the
ansible-playbook command:

#+BEGIN_SRC bash :noeval
ansible-playbook --check playbook.yaml
#+END_SRC

Executing this command will run the playbook normally, but instead of
implementing any modifications, Ansible will simply provide a report on the
changes it would have made. This report encompasses details such as file
modifications, command execution, and module calls.

*** Verifying playbooks

You may want to verify your playbooks to catch syntax errors and other problems
before you run them. The ~ansible-playbook~ command offers several options for
verification, including ~--check~, ~--diff~, ~--list-hosts~, ~--list-tasks~, and
~--syntax-check~.

You can use ~ansible-lint~ for detailed, Ansible-specific feedback on your
playbooks before you execute them.

** Working with playbooks

If Ansible modules are the tools in your workshop, playbooks are your
instruction manuals, and your inventory of hosts is your raw material.

*** Templating with Jinja2

Ansible uses Jinja2 templating to enable dynamic expressions and access to
variables and facts. You can use templating with the [[https://docs.ansible.com/ansible/latest/collections/ansible/builtin/template_module.html#template-module][template module]]. For
example, you can create a template for a configuration file, then deploy that
configuration file to multiple environments and supply the correct data (IP
address, hostname, version) for each environment. You can also use templating
in playbooks directly, by templating task names and more. You can use all the
[[https://jinja.palletsprojects.com/en/3.1.x/templates/#builtin-filters][standard filters and tests included in Jinja2]]. Ansible includes additional
specialized filters for selecting and transforming data, tests for evaluating
template expressions, and Lookup plugins for retrieving data from external
sources such as files, APIs, and databases for use in templating.

All templating happens on the Ansible control node before the task is sent and
executed on the target machine.

*** Example

In [[file:examples/002_template_example][002_template_example]] a small example has been prepared which utilizes the
~template~ plugin.

Try it out with:

#+BEGIN_SRC bash :noeval
ansible-playbook examples/002_template_example/main.yaml
#+END_SRC

* Old
** Ad-hoc commands

#+BEGIN_SRC bash :noeval
ansible -i inventory example -m ping -u centos
ansible -i inventory example -m ping -u ansibleuser --key-file ../../dockerenv/id_rsa

# If we add the key in the inventory file we can omit the key
ansible -i inventory example -m ping -u ansibleuser

# We can even add the user to the inventory file
ansible -i inventory example -m ping

# With an ansible.cfg file we can point to our inventory file and then
# we can omit the -i option as well
ansible ubuntu-server -m ping

# -m is for module
ansible ubuntu-server -m ping

# default for -m is "command" and -a feeds the module arguments
ansible ubuntu-server -a "ls -la"
ansible ubuntu-server -a "date"

ansible multi -a "hostname"

# Control parallellism with -f (default set to 5)
ansible multi -a "hostname" -f 1

# Return everything that ansible can find about a server. Something called "gather facts"
ansible multi -m setup

# Become a different user with -b/--become (default "sudo")
ansible multi -b -a "whoami"

# Install a package
ansible multi -b -m yum -a "name=ntp state=present"

# Check that the service is runnnig / enable the service
ansible multi -b -m service -a "name=ntpd state=started enabled=yes"

# The --limit command can focus on a single server instead of the whole group
#TODO

# Background tasks -B -P
ansible multi -b -B 3600 -P 0 -a "yum -y update"
# Look at ansible_job_id and results_file field
ansible multi -b -m async_status -a <ansible_job_id>

# This won't work as the command module doesn't handle pipes and redirections etc.
ansible multi -b -a "tail /var/log/messages | grep ansible-command | wc -l"

# Use shell module instead (but should be avoided)
ansible multi -b -m shell -a "tail /var/log/messages | grep ansible-command | wc -l"
#+END_SRC

Ansible is idempotent. If we run it more than one time it will still yield the
same result. The ~command~ module will always run anyway and report a ~CHANGED~
status as ansible don't know what has been done. When using other ansible
modules, ansible can know if something was updated or not.

#+BEGIN_SRC yaml
---
- name: Set up NTP on all servers.
  hosts: all
  become: yes # Run as sudo
  tasks:
    - name: Ensure NTP is installed.
      yum: name=ntp state=present
    - name: Ensure NTP is running.
      services: name= ntpd state=started enabled=yes
#+END_SRC

** Module documentation

#+BEGIN_SRC bash :noeval
ansible-doc <module_name>
#e.g.
ansible-doc service
#+END_SRC

Modules to investigate:

- cron
- git

** Playbooks

Convention to call the main playbook ~main.yml~

*** Example 1

#+BEGIN_SRC yaml
---
- name: Install Apache.
  hosts: all

  tasks:
    - name: Install Apache.
      command: yum install --quiet -y httpd httpd-devel
    - name: Copy configuration files.
      command: >
        cp src_file /path/to/target
      command: >
        cp src_file2 /path/to/target2
    - name: Start Apache and configure it to run at boot.
      command: service httpd start
    - command: chkconfig httpd on
#+END_SRC

#+BEGIN_SRC yaml
---
- name: Install Apache.
  hosts: all
  become: true # Can also be put in each task if we don't need to be root during
               # all steps. You can also provide the -b option to the
               # ansible-playbook command

  tasks:
    - name: Install Apache.
      yum:
        name:
          - httpd
          - httpd-devel
        state: present

    - name: Copy configuration files.
      copy:
        src: "{{ item.src }}" # jinja templates
        #src: "{{ item['src'] }}" # Also acceptable
        dst: "{{ item.dest }}"
        owner: root
        group: root
        mode: 0644
      with_items:
        - src: httpd.conf
          dest: /etc/httpd/conf/httpd.conf
        - src: httpd-vhosts.conf
          dest: /etc/httpd/conf/httpd-vhosts.conf

    - name: Make sure Apache is started now and at boot.
      service:
        name: httpd
        state: started
        enabled: true
#+END_SRC

This playbook is idempotent but if any of the copied file is changed later on
the web server won't restart automatically!

#+BEGIN_SRC bash :noeval
ansible-playbook -i inventory main.yml

ansbile-playbook -i inventory multi --limit=192.168.60.5
ansbile-playbook -i inventory multi --limit=!:db

ansible-inventory --list -i inventory
#+END_SRC

*** Example 2

#+BEGIN_SRC yaml
---
- hosts: solr
  become: true

  vars_files:
    - vars.yaml

  pre_tasks:
    - name: Update apt cache if needed
      apt: update_cache=true cache_valid_time=3600

  handler:
    # A task can trigger this if it has been updated by using "notify: restart solr"
    # It's not used in the example below though
    - name: restart solr
      services: name=solr state=restarted

  tasks:
    - name: Install Java
      apt: name=openjdk-8.jdk state=present

    - name: Download solr.
      get_url:
        url: "http://fake.url/path/{{ solr_version }}/download/solr-{{ solr_version }}.tgz"
        dest: "{{ download_dir }}/solr-{{ solr_version }}.tgz" # It's a good idea to state the whole path
                                                               # so ansible can check it it already exists
        checksum: "{{ solr_checksum }}"

    - name: Expand solr.
      unarchive:
        src: "{{ download_dir }}/solr-{{ solr_version }}.tgz"
        dest: "{{ download_dir }}"
        remote_src: true # Be default it takes the file on my local machine and copies it to the remove.
                         # This tells ansible that the file is on the remote already
        # Controls idempotece by specifying which files will be created by this action
        creates: "{{ download_dir }}/solr-{{ solr_version }}/README.txt"

    - name: Run Solr insallation script.
      command: >
        {{ download_dir }}/solr-{{ solr_version }}/bin/install_solr.sh
        {{ download_dir }}/solr-{{ solr_version }}.tgz
        -i /opt
        -d /var/solr
        -u solr
        -s solr
        -p 8983
        creates={{ solr_dir }}/bin/solr

    - name: Ensure solr is started and enabled at boot.
      service: name=solr state=started enabled=yes
#+END_SRC

#+BEGIN_SRC yaml
---
download_dir: /tmp
solr_dir: /opt/solr
solr_version: 8.5.0
solr_checksum: sha512:abc123
#+END_SRC

Check if it's valid:

#+BEGIN_SRC bash :noeval
ansible-playbook -i inventory main.yml --syntax-check
#+END_SRC

*** Example 3

#+BEGIN_SRC yaml
---
- name: Install Apache.
  hosts: all
  become: true

  vars:
    proxy_vars:
      http_proxy: http://example-proxy:80/
      https_proxy: https://example-proxy:80/

  environment:
    # Set's environment for all tasks
    var0: value0
    var1: value1

  handler:
    # A handler works like a normal task and can also use notify to trigger other handlers
    - name: restart apache
      service:
        name: httpd
        state: restarted
      #notify: restart memcached

  tasks:
    - name: Download a file.
      get_url:
        url: http://ipv4.download.thinkbroadband.com/20MB.zip
        dest: /tmp
      environment:
        http_proxy: http://example-proxy:80/
        https_proxy: https://example-proxy:80/
      # or
      #environment: proxy_vars


    - name: Add an environment variable to the remote user's shell.
      lineinefile:
        dest: "~/.bash_profile"
        regexp: '^ENV_VAR='
        line: 'ENV_VAR=value'
      become: false

    - name: Get the value of an environment variable.
      shell: 'source ~/.bash_profile && echo $ENV_VAR'
      register: foo

    - debug: msg="The variable is {{ foo.stdout }}"

    - name: Install Apache.
      yum:
        name: httpd
        state: present

    - name: Copy test config file.
      copy:
        src: files/test.conf
        dst: /etc/httpd/conf.d/test.conf
      # Run the "restart apache" handler if this task has been run. The handler will be run
      # after all tasks are done
      notify:
        # List of handlers
        - restart apache

    # With this meta task we will run all handler to be run directly instead of in the end
    - name: Make sure handlers are flushed immediately.
      meta: flush_handlers

    - name: Make sure Apache is started now and at boot.
      service:
        name: httpd
        state: started
        enabled: true
#+END_SRC

#+BEGIN_SRC xml
<LocationMatch "^/+$">
  Options -Indexes
  ErrorDocument 403 /.noindex.html
</LocationMatch>

<Directory /var/www/html>
  AllowOverride None
  Require all granted
</Directory>
#+END_SRC

If a task fails before a handler has been run it will not execute. So if you
notify in one step but a later task fails, the handler will not be run in the
end of the playbook. Try it out with the ~fail~ module:

#+BEGIN_SRC yaml
tasks:
  ...
  - fail:
  ...
#+END_SRC

You can overcome this behaviour by running ~ansible-playbook~ with
~--force-handlers~.

*** Example 4

#+BEGIN_SRC yaml
---
- name: Install Apache.
  hosts: all
  #gather_facts: false # Will not make ansible_os_family available
  become: true

  #vars:
  #  apache_package: httpd
  #  apache_service: httpd
  #  apache_config_dir: /etc/apache2/sites-enabled

  handler:
    # A handler works like a normal task and can also use notify to trigger other handlers
    - name: restart apache
      service:
        name: "{{ apache_service }}"
        state: restarted
      #notify: restart memcached

  pre_tasks:
    - debug: var=ansible_os_family

    - name: Load variables files.
      include_vars: "{{ item }}"
      with_first_found:
        - "vars/apache_{{ ansible_os_family }}.yml"
        - "vars/apache_default.yml"

  tasks:
    - name: Install Apache.
      package:
        name: "{{ apache_package }}"
        state: present
      register: foo

    - debug: var=foo
    - debug: var=foo.rc
    - debug: var=foo['rc']

    - name: Copy test config file.
      copy:
        src: files/test.conf
        dst: "{{ apache_config_dir }}/test.conf"
      # Run the "restart apache" handler if this task has been run. The handler will be run
      # after all tasks are done
      notify:
        # List of handlers
        - restart apache

    # With this meta task we will run all handler to be run directly instead of in the end
    - name: Make sure handlers are flushed immediately.
      meta: flush_handlers

    - name: Make sure Apache is started now and at boot.
      service:
        name: "{{ apache_service }}"
        state: started
        enabled: true
#+END_SRC

#+BEGIN_SRC yaml
# vars/apache_default.yml
apache_package: apache2
apache_service: apache2
apache_config_dir: /etc/apache2/sites-enabled
#+END_SRC

#+BEGIN_SRC yaml
# vars/apache_RedHat.yml
apache_package: httpd
apache_service: httpd
apache_config_dir: /etc/httpd/conf.d
#+END_SRC

The ~ansible_os_family~ is set during the ~gather_facts~ step. You can see
everything ansible knows about the system by using the ~setup~ module:

#+BEGIN_SRC bash :noeval
ansible -i inventory centos -m setup
#+END_SRC

*** Other keywords to investigate

- ~when~: Control if the task should be run
- ~changed_when~: Interpret yourself if the task resulted in a change
- ~failed_when~: Interpret yourself if the task resulted in a fail
- ~ignore_error~:
- ~tags~: Tag a number of task and control which tasks should be run with ~--tags~
- blocks: Allows you to do try except workflows

** Ansible vault

#+BEGIN_SRC yaml
---
- hosts: localhost
  connection: local
  gather_facts: no

  vars_files:
    - vars/api_key.yml

  tasks:
    - name: Echo the API key which was injected into the env.
      shell: echo $API_KEY
      environment:
        API_KEY: "{{ myapp_api_key }}"
      register: echo_result

    - names: Show the result.
      debug: var=echo_result.stdout
#+END_SRC

Encrypt a var file

#+BEGIN_SRC bash :noeval
ansible-vault encrypt vars/api_key.yml
# Provide password
#+END_SRC

Use it:

#+BEGIN_SRC bash :noeval
ansible-playbook main.yml --ask-vault-pass
ansible-playbook main.yml --vault-password-file path/to/file
#+END_SRC

Decrypt file

#+BEGIN_SRC bash :noeval
ansible-vault decrypt vars/api_key.yml
#+END_SRC

Edit file without decrypting it to separate file

#+BEGIN_SRC bash :noeval
ansible-vault edit vars/api_key.yml
#+END_SRC

Change password key:

#+BEGIN_SRC bash :noeval
ansible-vault rekey vars/api_key.yml
#+END_SRC

** Playbook organization

Tasks can be included in a playbook.

#+BEGIN_SRC yaml
---
- name: Install Apache.
  hosts: all
  become: true

  handler:
    # Basically this import will replace this line with the content of apache.yml
    # so I guess that ordering is still important of imports
    - import_tasks: handlers/apache.yml

  pre_tasks:
    - name: Load variables files.
      include_vars: "{{ item }}"
      with_first_found:
        - "vars/apache_{{ ansible_os_family }}.yml"
        - "vars/apache_default.yml"

  tasks:
    - import_tasks: tasks/apache.yml
      #vars:
      #  apache_package: apache3
    # There's also something called include_tasks
    #- include_tasks: tasks/log.yml

#- import_playbook: app.yml
#+END_SRC

#+BEGIN_SRC yaml
# handlers/apache.yml
---
- name: restart apache
  service:
    name: "{{ apache_service }}"
    state: restarted
#+END_SRC

#+BEGIN_SRC yaml
# tasks/apache.yml
---
- name: Install Apache.
  package:
    name: "{{ apache_package }}"
    state: present

- name: Copy test config file.
  copy:
    src: files/test.conf
    dst: "{{ apache_config_dir }}/test.conf"
  notify:
    - restart apache

- name: Make sure Apache is started now and at boot.
  service:
    name: "{{ apache_service }}"
    state: started
    enabled: true
#+END_SRC

You can also import a playbook using ~import_playbook~

** Roles

Roles let's you package up stuff which can be used for a single or multiple
playbooks.

** Config
*** ~ansible.cfg~

#+BEGIN_SRC
[ssh_connection]
pipelining = True
#+END_SRC

*** Inventory format

#+BEGIN_SRC ini
# Application servers
[app]
192.168.60.4
192.168.60.5

# Database servers
[db]
192.168.60.6

# Group has all the servers
[multi:children]
app
db

[multi:vars]
ansible_ssh_user=ansibleuser
ansible_host=localhost
#ansible_ssh_common_args="-o StrictHostKeyChecking=no"
#+END_SRC
