* Table of Contents :TOC_3:QUOTE:
#+BEGIN_QUOTE
- [[#links][Links]]
- [[#getting-started][Getting started]]
  - [[#install][Install]]
    - [[#install-on-the-managed-node][Install on the managed node]]
  - [[#configure-ansible][Configure ansible]]
    - [[#a-note-about-comments-in-ansiblecfg][A note about comments in ~ansible.cfg~]]
  - [[#create-docker-target-environment][Create docker target environment]]
    - [[#ubuntu-environment][Ubuntu environment]]
    - [[#fedora-environment][Fedora environment]]
    - [[#create-multiple-containers-with-the-docker-compose-command][Create multiple containers with the ~docker compose~ command]]
- [[#building-an-inventory][Building an inventory]]
  - [[#intro][Intro]]
    - [[#variables][Variables]]
    - [[#metagroups][Metagroups]]
    - [[#example][Example]]
  - [[#how-to-build-your-inventory][How to build your inventory]]
    - [[#adding-ranges-of-hosts][Adding ranges of hosts]]
    - [[#passing-multiple-inventory-sources][Passing multiple inventory sources]]
    - [[#organizing-inventory-in-a-directory][Organizing inventory in a directory]]
    - [[#adding-variables-to-inventory][Adding variables to inventory]]
  - [[#patterns-targeting-hosts-and-groups][Patterns: targeting hosts and groups]]
    - [[#using-patterns][Using patterns]]
    - [[#common-patterns][Common patterns]]
    - [[#pattern-processing-order][Pattern processing order]]
    - [[#limit-a-run-to-a-subset-of-hosts][Limit a run to a subset of hosts]]
- [[#using-ansible-command-line-tools][Using Ansible command line tools]]
  - [[#introduction-to-ad-hoc-commands][Introduction to ad hoc commands]]
    - [[#use-cases-for-ad-hoc-tasks][Use cases for ad hoc tasks]]
- [[#playbooks][Playbooks]]
  - [[#ansible-playbooks][Ansible playbooks]]
    - [[#playbook-syntax][Playbook syntax]]
    - [[#playbook-execution][Playbook execution]]
    - [[#task-execution][Task execution]]
    - [[#desired-state-and-idempotency][Desired state and 'idempotency']]
    - [[#running-playbooks][Running playbooks]]
    - [[#verifying-playbooks][Verifying playbooks]]
  - [[#working-with-playbooks][Working with playbooks]]
    - [[#templating-with-jinja2][Templating with Jinja2]]
    - [[#using-filters-to-manipulate-data][Using filters to manipulate data]]
    - [[#tests][Tests]]
    - [[#lookups][Lookups]]
    - [[#python3-in-templates][Python3 in templates]]
    - [[#the-now-function-get-the-current-time][The ~now~ function: get the current time]]
    - [[#loops][Loops]]
    - [[#controlling-where-tasks-run-delegation-and-local-actions][Controlling where tasks run: delegation and local actions]]
- [[#snippets][Snippets]]
  - [[#try-out-variables][Try out variables]]
  - [[#include--exclude-certain-groups-from-running-a-job][Include / Exclude certain groups from running a job]]
- [[#useful-scripts][Useful scripts]]
- [[#old][Old]]
  - [[#ad-hoc-commands][Ad-hoc commands]]
  - [[#module-documentation][Module documentation]]
  - [[#playbooks-1][Playbooks]]
    - [[#example-1][Example 1]]
    - [[#example-2][Example 2]]
    - [[#example-3][Example 3]]
    - [[#example-4][Example 4]]
    - [[#other-keywords-to-investigate][Other keywords to investigate]]
  - [[#ansible-vault][Ansible vault]]
  - [[#playbook-organization][Playbook organization]]
  - [[#roles][Roles]]
  - [[#config][Config]]
    - [[#ansiblecfg][~ansible.cfg~]]
    - [[#inventory-format][Inventory format]]
#+END_QUOTE

* Links

- https://www.jeffgeerling.com/blog/2020/ansible-101-jeff-geerling-youtube-streaming-series (ansible 2.9)?
- https://docs.ansible.com/ansible/latest/getting_started/basic_concepts.html (glossary)
- https://docs.ansible.com/ansible/latest/reference_appendices/playbooks_keywords.html#playbook-keywords
- https://docs.ansible.com/ansible/latest/reference_appendices/general_precedence.html#general-precedence-rules
- https://stackoverflow.com/questions/54572995/how-to-run-a-playbook-task-based-on-os-type-in-ansible

* Getting started
** Install

#+BEGIN_SRC bash :noeval
# For fedora
sudo dnf install ansible

# For osx
brew install ansible

# Verify install
ansible --version
#+END_SRC

*** Install on the managed node

Ansible does not have to be installed but you need python and a user account
that can connect through SSH.

** Configure ansible

You don't have to follow these steps as there is already a [[file:ansible.cfg][ansible.cfg]] created.

You can generate an Ansible configuration file, ~ansible.cfg~, that lists all
default settings as follows:

#+BEGIN_SRC bash :noeval
ansible-config init --disabled > ansible.cfg
#+END_SRC

Include available plugins to create a more complete Ansible configuration as
follows:

#+BEGIN_SRC bash :noeval
ansible-config init --disabled -t all > ansible.cfg
#+END_SRC

The configuration files are searched for in the following order:

- ~ANSIBLE_CONFIG~ (environment variable if set)
- ~ansible.cfg~ (in the current directory)
- ~~/.ansible.cfg~ (in the home directory)
- ~/etc/ansible/ansible.cfg~

Not all configuration options are present in the command line, just the ones
deemed most useful or common. Settings in the command line will override those
passed through the configuration file and the environment.

For more information see the [[https://docs.ansible.com/ansible/latest/reference_appendices/config.html#ansible-configuration-settings][Ansible Configuration Settings documentation]].

*** A note about comments in ~ansible.cfg~

The configuration file is one variant of an ~.ini~ format. Both the hash sign
(~#~) and semicolon (~;~) are allowed as comment markers when the comment starts
the line. However, if the comment is inline with regular values, only the
semicolon is allowed to introduce the comment.

** Create docker target environment
*** Ubuntu environment

#+BEGIN_SRC bash :noeval
cd dockerenv/ubuntu
ssh-keygen -b 4096 -t rsa -f ./id_rsa -N ""
docker build -t ubuntuansibletarget:latest .

# Start env
docker run --name ubuntutarget --rm -p 2022:22 --privileged ubuntuansibletarget:latest

# Test connection
ssh -o "IdentitiesOnly=yes" -o "StrictHostKeyChecking=no" -o "UserKnownHostsFile=/dev/null" -i id_rsa -p 2022 ansibleuser@localhost

# Stop container. It takes a few seconds to stop the container
docker stop ubuntutarget
#+END_SRC

*** Fedora environment

#+BEGIN_SRC bash :noeval
cd dockerenv/fedora
ssh-keygen -b 4096 -t rsa -f ./id_rsa -N ""
docker build -t fedoraansibletarget:latest .

# Start env
docker run --name fedoratarget --rm -p 3022:22 --privileged fedoraansibletarget:latest

# Test connection
ssh -o "IdentitiesOnly=yes" -o "StrictHostKeyChecking=no" -o "UserKnownHostsFile=/dev/null" -i id_rsa -p 3022 ansibleuser@localhost

# Stop container. It takes a few seconds to stop the container
docker stop fedoratarget
#+END_SRC

*** Create multiple containers with the ~docker compose~ command

After the containers above has been built you can create multiple of them by
running:

#+BEGIN_SRC bash :noeval
cd dockerenv
docker compose up ; docker compose down
# or
cd dockerenv
./startenv.sh
#+END_SRC

This will run the containers in the foreground and will remove the containers
automatically when stopped.

Try connecting to each machine:

#+BEGIN_SRC bash :noeval
ssh -o "IdentitiesOnly=yes" -o "StrictHostKeyChecking=no" -o "UserKnownHostsFile=/dev/null" -i ubuntu/id_rsa -p 2022 ansibleuser@localhost whoami
ssh -o "IdentitiesOnly=yes" -o "StrictHostKeyChecking=no" -o "UserKnownHostsFile=/dev/null" -i ubuntu/id_rsa -p 2122 ansibleuser@localhost whoami
ssh -o "IdentitiesOnly=yes" -o "StrictHostKeyChecking=no" -o "UserKnownHostsFile=/dev/null" -i fedora/id_rsa -p 3022 ansibleuser@localhost whoami
ssh -o "IdentitiesOnly=yes" -o "StrictHostKeyChecking=no" -o "UserKnownHostsFile=/dev/null" -i fedora/id_rsa -p 3122 ansibleuser@localhost whoami
#+END_SRC

* Building an inventory
** Intro

The ~inventory.yaml~ basic format looks something like this:

#+BEGIN_SRC yaml
myhosts: # Group name
  hosts:
    my_host_01:
      ansible_host: 192.0.2.50 # Ip for the my_host_01 alias
    my_host_02:
      ansible_host: 192.0.2.51
    my_host_03:
      ansible_host: 192.0.2.52
#+END_SRC

*** Variables

Variables set values for managed nodes, such as the IP address, FQDN, operating
system, and SSH user, so you do not need to pass them when running Ansible
commands.

Variables can apply to specific hosts.

#+BEGIN_SRC yaml
webservers:
  hosts:
    webserver01:
      ansible_host: 192.0.2.140
      http_port: 80
    webserver02:
      ansible_host: 192.0.2.150
      http_port: 443
#+END_SRC

Variables can also apply to all hosts in a group:

#+BEGIN_SRC yaml
webservers:
  hosts:
    webserver01:
      ansible_host: 192.0.2.140
      http_port: 80
    webserver02:
      ansible_host: 192.0.2.150
      http_port: 443
  vars:
    ansible_user: my_server_user
#+END_SRC

*** Metagroups

Create a metagroup that organizes multiple groups in your inventory with the following syntax:

#+BEGIN_SRC yaml
metagroupname:
  children:
#+END_SRC

The following inventory illustrates a basic structure for a data center. This
example inventory contains a ~network~ metagroup that includes all network
devices and a ~datacenter~ metagroup that includes the ~network~ group and all
webservers.

#+BEGIN_SRC yaml
leafs:
  hosts:
    leaf01:
      ansible_host: 192.0.2.100
    leaf02:
      ansible_host: 192.0.2.110

spines:
  hosts:
    spine01:
      ansible_host: 192.0.2.120
    spine02:
      ansible_host: 192.0.2.130

network:
  children:
    leafs:
    spines:

webservers:
  hosts:
    webserver01:
      ansible_host: 192.0.2.140
    webserver02:
      ansible_host: 192.0.2.150

datacenter:
  children:
    network:
    webservers:
#+END_SRC

*** Example

Start checking the inventory file that has been configured for the container
defined earlier:

#+BEGIN_SRC bash :noeval
ansible-inventory -i inventory/inventory.yaml --list
# Because we have a ansible.cfg file which points to the inventory file we can
# just run
ansible-inventory --list
#+END_SRC

In our inventory I have defined some variables for each host as we don't want to
use the defaults.

Try pinging each of them:

#+BEGIN_SRC bash :noeval
ansible all -m ping -i inventory/inventory.yaml
# Because we have a ansible.cfg file which points to the inventory file we can
# just run
ansible all -m ping
#+END_SRC

The inventory can be in both ~.yaml~ and ~.ini~ format. I prefer ~.yaml~ and
will only use ~.yaml~ in my examples.

** How to build your inventory

Ansible automates tasks on managed nodes or "hosts" in your infrastructure,
using a list or group of lists known as inventory. You can pass host names at
the command line, but most Ansible users create inventory files. Your inventory
defines the managed nodes you automate, with groups so you can run automation
tasks on multiple hosts at the same time. Once your inventory is defined, you
use patterns to select the hosts or groups you want Ansible to run against.

The default location for this file is ~/etc/ansible/hosts~. You can specify a
different inventory file at the command line using the ~-i <path>~ option or in
a configuration file using the ~inventory~ key.

As your inventory expands, you may need more than a single file to organize your
hosts and groups. Some alternatives are:

- You can create a directory with multiple inventory files
- You can pull inventory dynamically. For example, you can use a dynamic
  inventory plugin to list resources in one or more cloud providers
- You can use multiple sources for inventory, including both dynamic inventory
  and static files

*** Adding ranges of hosts

If you have a lot of hosts with a similar pattern, you can add them as a range
rather than listing each hostname separately:

#+BEGIN_SRC yaml
# ...
  webservers:
    hosts:
      www[01:50].example.com:
# ...
  webservers:
    hosts:
      www[01:50:2].example.com: # To only have all odd numbers
#+END_SRC

For numeric patterns, leading zeros can be included or removed, as desired.
Ranges are inclusive. You can also define alphabetic ranges:

#+BEGIN_SRC yaml
# ...
  databases:
    hosts:
      db-[a:f].example.com:
#+END_SRC

*** Passing multiple inventory sources

To target two inventory sources from the command line:

#+BEGIN_SRC bash :noeval
ansible-playbook get_logs.yml -i staging -i production
#+END_SRC

*** Organizing inventory in a directory

You can consolidate multiple inventory sources in a single directory. The
simplest version of this is a directory with multiple files instead of a single
inventory file.

You can also combine multiple inventory source types in an inventory directory.
This can be useful for combining static and dynamic hosts and managing them as
one inventory. The following inventory directory combines an inventory plugin
source, a dynamic inventory script, and a file with static hosts:

#+BEGIN_SRC
inventory/
  openstack.yml          # configure inventory plugin to get hosts from OpenStack cloud
  dynamic-inventory.py   # add additional hosts with dynamic inventory script
  on-prem                # add static hosts and groups
  parent-groups          # add static hosts and groups
#+END_SRC

You can target this inventory directory as follows:

#+BEGIN_SRC bash :noeval
ansible-playbook example.yml -i inventory
#+END_SRC

*** Adding variables to inventory

You can store variable values that relate to a specific host or group in
inventory. To start with, you may add variables directly to the hosts and groups
in your main inventory file.

**** Assigning a variable to one machine: host variables

You can easily assign a variable to a single host and then use it later in
playbooks. You can do this directly in your inventory file.

#+BEGIN_SRC yaml
atlanta:
  hosts:
    host1:
      http_port: 80
      maxRequestsPerChild: 808
    host2:
      http_port: 303
      maxRequestsPerChild: 909
#+END_SRC

Connection variables also work well as host variables:

#+BEGIN_SRC yaml
my_group:
  hosts:
    other1.example.com:
      ansible_connection: ssh
      ansible_user: myuser
    other2.example.com:
      ansible_connection: ssh
      ansible_user: myotheruser
#+END_SRC

**** Inventory aliases

You can also define aliases in your inventory using host variables:

#+BEGIN_SRC yaml
# ...
  hosts:
    jumper:
      ansible_port: 5555
      ansible_host: 192.0.2.50
#+END_SRC

In this example, running Ansible against the host alias ~jumper~ will connect to
~192.0.2.50~ on port ~5555~. In previous examples we have defined the host/ip
instead of an alias. In our [[file:inventory/inventory.yaml][inventory.yaml]] we use aliases since all machines are
located on the same machine (~localhost~).

**** Assigning a variable to many machines: group variables

If all hosts in a group share a variable value, you can apply that variable to
an entire group at once.

#+BEGIN_SRC yaml
atlanta:
  hosts:
    host1:
    host2:
  vars:
    ntp_server: ntp.atlanta.example.com
    proxy: proxy.atlanta.example.com
#+END_SRC

Group variables are a convenient way to apply variables to multiple hosts at
once. Before executing, however, Ansible always flattens variables, including
inventory variables, to the host level. If a host is a member of multiple
groups, Ansible reads variable values from all of those groups. If you assign
different values to the same variable in different groups, Ansible chooses which
value to use based on internal rules for merging (see below).

**** Inheriting variable values: group variables for groups of groups

You can apply variables to parent groups (nested groups or groups of groups) as
well as to child groups.

#+BEGIN_SRC yaml
usa:
  children:
    southeast: # Group level 1
      children:
        atlanta: # Group level 2
          hosts:
            host1:
            host2:
        raleigh: # Group level 2
          hosts:
            host2:
            host3:
      vars:
        some_server: foo.southeast.example.com
        halon_system_timeout: 30
        self_destruct_countdown: 60
        escape_pods: 2
    northeast: # Group level 1
    northwest: # Group level 1
    southwest: # Group level 1
#+END_SRC

A child group’s variables will have higher precedence (override) than a parent
group’s variables.

**** Organizing host and group variables

Although you can store variables in the main inventory file, storing separate
host and group variables files may help you organize your variable values more
easily. You can also use lists and hash data in host and group variables files,
which you cannot do in your main inventory file.

Valid file extensions include ~.yml~, ~.yaml~, ~.json~, or no file extension.

Ansible loads host and group variable files by searching paths relative to the
inventory file or the playbook file. If your inventory file at
~/etc/ansible/hosts~ contains a host named ~foosball~ that belongs to two
groups, ~raleigh~ and ~webservers~, that host will use variables in YAML files
at the following locations:

#+BEGIN_SRC
/etc/ansible/group_vars/raleigh # can optionally end in '.yml', '.yaml', or '.json'
/etc/ansible/group_vars/webservers
/etc/ansible/host_vars/foosball
#+END_SRC

For example, if you group hosts in your inventory by datacenter, and each
datacenter uses its own NTP server and database server, you can create a file
called ~/etc/ansible/group_vars/raleigh~ to store the variables for the raleigh
group:

#+BEGIN_SRC yaml
---
ntp_server: acme.example.org
database_server: storage.example.org
#+END_SRC

You can also create /directories/ named after your groups or hosts. Ansible will
read all the files in these directories in lexicographical order. An example
with the ~raleigh~ group:

#+BEGIN_SRC
/etc/ansible/group_vars/raleigh/db_settings
/etc/ansible/group_vars/raleigh/cluster_settings
#+END_SRC

All hosts in the ~raleigh~ group will have the variables defined in these files
available to them. This can be very useful to keep your variables organized when
a single file gets too big, or when you want to use Ansible Vault on some group
variables.

For ~ansible-playbook~ you can also add ~group_vars/~ and ~host_vars/~
directories to your playbook directory. Other Ansible commands (for example,
~ansible~, ~ansible-console~, and so on) will only look for ~group_vars/~ and
~host_vars/~ in the inventory directory. If you want other commands to load
group and host variables from a playbook directory, you must provide the
~--playbook-dir~ option on the command line. If you load inventory files from
both the playbook directory and the inventory directory, variables in the
playbook directory will override variables set in the inventory directory.

**** How variables are merged

By default, variables are merged/flattened to the specific host before a play is
run. This keeps Ansible focused on the Host and Task, so groups do not survive
outside of inventory and host matching. The order/precedence is (from lowest to
highest):

- all group (because it is the "parent" of all other groups)
- parent group
- child group
- host

By default, Ansible merges groups at the same parent/child level in ASCII order,
and variables from the last group loaded overwrite variables from the previous
groups. For example, an ~a_group~ will be merged with ~b_group~ and ~b_group~
vars that match will overwrite the ones in ~a_group~.

**** Managing inventory variable load order

When using multiple inventory sources, keep in mind that any variable conflicts
are resolved according to the merge rules described above and
[[https://docs.ansible.com/ansible/latest/playbook_guide/playbooks_variables.html#ansible-variable-precedence][Variable precedence: Where should I put a variable?]].

When you pass multiple inventory sources at the command line, Ansible merges
variables in the order you pass those parameters. If ~[all:vars]~ in staging
inventory defines ~myvar = 1~ and production inventory defines ~myvar = 2~,
then:

- Pass ~-i staging -i production~ to run the playbook with ~myvar = 2~
- Pass ~-i production -i staging~ to run the playbook with ~myvar = 1~

When you put multiple inventory sources in a directory, Ansible merges them in
ASCII order according to the file names. You can control the load order by
adding prefixes to the files:

#+BEGIN_SRC
inventory/
  01-openstack.yml          # configure inventory plugin to get hosts from Openstack cloud
  02-dynamic-inventory.py   # add additional hosts with dynamic inventory script
  03-static-inventory       # add static hosts
  group_vars/
    all.yml                 # assign variables to all hosts
#+END_SRC

If ~01-openstack.yml~ defines ~myvar = 1~ for the group ~all~,
~02-dynamic-inventory.py~ defines ~myvar = 2~, and ~03-static-inventory~ defines
~myvar = 3~, the playbook will be run with ~myvar = 3~.

**** Connecting to hosts: behavioral inventory parameters

As mentioned earlier, there are variables that controls how Ansible interacts
with remote hosts:

For a full list see https://docs.ansible.com/ansible/latest/inventory_guide/intro_inventory.html#connecting-to-hosts-behavioral-inventory-parameters

** Patterns: targeting hosts and groups

When you execute Ansible through an ad hoc command or by running a playbook, you
must choose which managed nodes or groups you want to execute against. Patterns
let you run commands and playbooks against specific hosts and/or groups in your
inventory. An Ansible pattern can refer to a single host, an IP address, an
inventory group, a set of groups, or all hosts in your inventory. Patterns are
highly flexible - you can exclude or require subsets of hosts, use wildcards or
regular expressions, and more. Ansible executes on all inventory hosts included
in the pattern.

*** Using patterns

You use a pattern almost any time you execute an ad hoc command or a playbook.
The pattern is the only element of an ad hoc command that has no flag. It is
usually the second element:

#+BEGIN_SRC bash :noeval
ansible <pattern> -m <module_name> -a "<module options>"
#+END_SRC

In a playbook, the pattern is the content of the ~hosts:~ line for each play:

#+BEGIN_SRC yaml
- name: <play_name>
  hosts: <pattern>
#+END_SRC

*** Common patterns

| Description            | Pattern(s)                       | Targets                                             |
|------------------------+----------------------------------+-----------------------------------------------------|
| All hosts              | ~all~ (or ~*~)                   |                                                     |
| One host               | ~host1~                          |                                                     |
| Multiple hosts         | ~host1:host2~ (or ~host1,host2~) |                                                     |
| One group              | ~webservers~                     |                                                     |
| Multiple groups        | ~webservers:dbservers~           | all hosts in webservers plus all hosts in dbservers |
| Excluding groups       | ~webservers:!atlanta~            | all hosts in webservers except those in atlanta     |
| Intersection of groups | ~webservers:&staging~            | any hosts in webservers that are also in staging    |

You can use either a comma (~,~) or a colon (~:~) to separate a list of hosts.
The comma is preferred when dealing with ranges and IPv6 addresses.

You can use wildcard patterns with FQDNs or IP addresses, as long as the hosts
are named in your inventory by FQDN or IP address:

#+BEGIN_SRC
192.0.*
*.example.com
*.com
#+END_SRC

If you have defined a host by alias you must refer to it with the alias name
(wildcard patterns are also allowed).

You can only refer to hosts or groups listed in your inventory. This includes if
you refer to IP addresses and FQDNs.

*** Pattern processing order

The processing happens in the following order:

1. ~:~ and ~,~
2. ~&~ (intersection)
3. ~!~ (exclusion)

There are more pattern rules described at:
https://docs.ansible.com/ansible/latest/inventory_guide/intro_patterns.html

*** Limit a run to a subset of hosts

You can change the behavior of the patterns defined in playbook using
command-line options. You can also limit the hosts you target on a particular
run with the ~--limit~ or ~-l~ flag.

E.g.

#+BEGIN_SRC bash :noeval
ansible-playbook site.yml --limit datacenter2
#+END_SRC

This command will limit the playbook to the ~datacenter2~ pattern. It will be
the intersection of what is defined in the ~hosts:~ field in the playbook with
what is provided by the ~--limit~ (or ~-l~) option.

Finally, you can use ~--limit~ to read the list of hosts from a file by
prefixing the file name with ~@~:

#+BEGIN_SRC bash :noeval
ansible-playbook site.yml --limit @retry_hosts.txt
#+END_SRC

If [[https://docs.ansible.com/ansible/latest/reference_appendices/config.html#retry-files-enabled][RETRY_FILES_ENABLED]] is set to ~True~, a ~.retry~ file will be created after
the ~ansible-playbook~ run containing a list of failed hosts from all plays.
This file is overwritten each time ~ansible-playbook~ finishes running.

Then you can retry a playbook for only the failing hosts:

#+BEGIN_SRC bash :noeval
ansible-playbook site.yml --limit @site.retry
#+END_SRC

* Using Ansible command line tools

An Ansible ad hoc command uses the ~/usr/bin/ansible~ command-line tool to
automate a single task on one or more managed nodes. ad hoc commands are quick
and easy, but they are not reusable.

** Introduction to ad hoc commands

An ad hoc command looks like this:

#+BEGIN_SRC bash :noeval
ansible [pattern] -m [module] -a "[module options]"
#+END_SRC

The ~-a~ option accepts options either through the ~key=value~ syntax or a JSON
string starting with ~{~ and ending with ~}~ for more complex option structure.

*** Use cases for ad hoc tasks

ad hoc tasks can be used to reboot servers, copy files, manage packages and
users, and much more. You can use any Ansible module in an ad hoc task. ad hoc
tasks, like playbooks, use a declarative model, calculating and executing the
actions required to reach a specified final state. They achieve a form of
idempotence by checking the current state before they begin and doing nothing
unless the current state is different from the specified final state.

**** Running a command on the servers

The default module for the ~ansible~ command-line utility is the
[[https://docs.ansible.com/ansible/latest/collections/ansible/builtin/command_module.html#command-module][ansible.builtin.command module]]. The commands below will all be run using the
prepared [[file:inventory/inventory.yaml][inventory.yaml]] file. We we use the ~all~ group but you can replace it
with e.g. ~ubuntus~ or ~fedoras~.

To print the user of each target you can run:

#+BEGIN_SRC bash :noeval
ansible all -a "whoami"
#+END_SRC

You can also use variables:

#+BEGIN_SRC bash :noeval
ansible all -a 'echo $PATH' # Notice the quoting to not expand outside ansible
#+END_SRC

In some cases you may need to escalate your privileges. This can be done with
the ~--become~ flag:

#+BEGIN_SRC bash :noeval
ansible all -a "whoami" --become [--ask-become-pass]
#+END_SRC

If you add ~--ask-become-pass~ or ~-K~, Ansible prompts you for the password to
use for privilege escalation (e.g. ~sudo~).

By default, Ansible uses only five simultaneous processes. If you have more
hosts than the value set for the fork count, it can increase the time it takes
for Ansible to communicate with the hosts. To increase the number of
simultaneous processes you can use the ~-f~ option. E.g.:

#+BEGIN_SRC bash :noeval
ansible all -a "whoami" -f 10
#+END_SRC

To print the content of ~/etc/os-release~ of each target you can run:

#+BEGIN_SRC bash :noeval
ansible all -a "cat /etc/os-release"
#+END_SRC

This prints a lot of information the ~command~ module doesn't support extended
shell syntaxes like piping and redirects (although shell variables will always
work). If your command requires shell-specific syntax, use the
~ansible.builtin.shell~ module instead.

#+BEGIN_SRC bash :noeval
ansible all -m ansible.builtin.shell -a "cat /etc/os-release | grep PRETTY_NAME"
#+END_SRC

**** Managing files

An ad hoc task can harness the power of Ansible and SCP to transfer many files
to multiple machines in parallel. To transfer a file directly to all servers:

#+BEGIN_SRC bash :noeval
ansible all -m ansible.builtin.shell -a "ls -la host_file" # Verify it doesn't exist
ansible all -m ansible.builtin.copy -a "src=/etc/hosts dest=~/host_file"
ansible all -m ansible.builtin.shell -a "ls -la host_file" # Verify it exists
#+END_SRC

Another module that handles files is the [[https://docs.ansible.com/ansible/latest/collections/ansible/builtin/template_module.html#template-module][ansible.builtin.template module]].

The [[https://docs.ansible.com/ansible/latest/collections/ansible/builtin/file_module.html#file-module][ansible.builtin.file module]] allows changing ownership and permissions on
files. These same options can be passed directly to the ~copy~ module as well:

#+BEGIN_SRC bash :noeval
ansible all -m ansible.builtin.file -a "dest=/home/ansibleuser/host_file mode=600 owner=root group=root" --become
ansible all -m ansible.builtin.shell -a "ls -la host_file" # Verify ownership and permission
#+END_SRC

We can also create directories with the ~file~ module (similar to ~mkdir -p~):

#+BEGIN_SRC bash :noeval
ansible all -m ansible.builtin.file -a "dest=/home/ansibleuser/dir/subdir mode=755 owner=ansibleuser group=ansibleuser state=directory"
ansible all -m ansible.builtin.shell -a "ls -lad dir/subdir" # Verify the dir exists
#+END_SRC

You can also remove directories:

#+BEGIN_SRC bash :noeval
ansible all -m ansible.builtin.file -a "dest=/home/ansibleuser/dir state=absent"
ansible all -m ansible.builtin.shell -a "ls -lad dir" # Verify the dir is removed
#+END_SRC

**** Managing packages

You might also use an ad hoc task to install, update, or remove packages on
managed nodes using a package management module. Package management modules
support common functions to install, remove, and generally manage packages. Some
specific functions for a package manager might not be present in the Ansible
module since they are not part of general package management.

There is a ~yum~ module that won't work for our ubuntu containers and also an
~apt~ module that won't work for our fedora containers. But there is a more
generic ~package~ module we can use:

#+BEGIN_SRC bash :noeval
ansible all -m ansible.builtin.package -a "name=vim state=present" --become
#+END_SRC

You can also define a certain version:

#+BEGIN_SRC bash :noeval
ansible all -m ansible.builtin.package -a "name=vim-2:9.1 state=present" --become
#+END_SRC

To ensure a package is at the latest version:

#+BEGIN_SRC bash :noeval
ansible all -m ansible.builtin.package -a "name=vim state=latest" --become
#+END_SRC

To uninstall or ensure that something is not installed:

#+BEGIN_SRC bash :noeval
ansible all -m ansible.builtin.package -a "name=vim state=absent" --become
#+END_SRC

**** Managing users and groups

With the [[https://docs.ansible.com/ansible/latest/collections/ansible/builtin/user_module.html#user-module][ansible.builtin.user module]] you can create, manage, and remove user
accounts on your managed nodes with ad hoc tasks:

#+BEGIN_SRC bash :noeval
# Create a user with username 'new_user' and password 'secret'
ansible all -m ansible.builtin.user -a "name=new_user password=$(echo secret | mkpasswd --method=sha-512 -s)" --become
# Verify on ubuntu1 that a user is created (username is secret):
ssh -o "StrictHostKeyChecking=no" -o "UserKnownHostsFile=/dev/null" -p 2122 new_user@localhost whoami
# Verify on fedora1 that a user is created (username is secret):
ssh -o "StrictHostKeyChecking=no" -o "UserKnownHostsFile=/dev/null" -p 3122 new_user@localhost whoami

# Remove the user
ansible all -m ansible.builtin.user -a "name=new_user state=absent" --become
#+END_SRC

**** Managing services

Ensure (or start) a service is started on all servers:

#+BEGIN_SRC bash :noeval
ansible fedoras -m ansible.builtin.package -a "name=httpd state=present" --become
ansible fedoras -m ansible.builtin.service -a "name=httpd state=started" --become

ansible ubuntus -m ansible.builtin.package -a "name=apache2 state=present" --become
ansible ubuntus -m ansible.builtin.service -a "name=apache2 state=started" --become
#+END_SRC

Verify that it's working by visiting:

- http://localhost:2080
- http://localhost:2180
- http://localhost:3080
- http://localhost:3180

You can restart a service:

#+BEGIN_SRC bash :noeval
ansible fedoras -m ansible.builtin.service -a "name=httpd state=restarted" --become
#+END_SRC

And ensure that a service is stopped (or stop it):

#+BEGIN_SRC bash :noeval
ansible fedoras -m ansible.builtin.service -a "name=httpd state=stopped" --become
#+END_SRC

**** Gathering facts

Facts represent discovered variables about a system. You can use facts to
implement conditional execution of tasks but also just to get ad hoc information
about your systems. To see all facts use the [[https://docs.ansible.com/ansible/latest/collections/ansible/builtin/setup_module.html#setup-module][ansible.builtin.setup module]]:

#+BEGIN_SRC bash :noeval
ansible all -m ansible.builtin.setup
#+END_SRC

**** Check mode (dry run)

In check mode, Ansible does not make any changes to remote systems. Ansible
prints the commands only. It does not run the commands. You activate it with the
~-C~ or ~--check~ option.

#+BEGIN_SRC bash :noeval
ansible all -m copy -a "content=foo dest=/root/bar.txt" -C
#+END_SRC

* Playbooks

Playbooks are automation blueprints, in ~.yaml~ format, that Ansible uses to
deploy and configure managed nodes.

- Playbook :: A list of plays that define the order in which Ansible performs
  operations, from top to bottom, to achieve an overall goal.
- Play :: An ordered list of tasks that maps to managed nodes in an inventory.
- Task :: A reference to a single module that defines the operations that
  Ansible performs.
- Module :: A unit of code or binary that Ansible runs on managed nodes. Ansible
  modules are grouped in collections with a Fully Qualified Collection Name
  (FQCN) for each module.

Try running the following playbook:

[[file:examples/001_hello_world.yaml][001_hello_world.yaml]]

#+BEGIN_SRC yaml
- name: My first play
  hosts: ubuntus # Run on all machines in the ubuntus group
  tasks:
   - name: Ping my hosts
     ansible.builtin.ping:

   - name: Print message
     ansible.builtin.debug:
      msg: Hello world
#+END_SRC

Run it with:

#+BEGIN_SRC bash :noeval
ansible-playbook examples/001_hello_world.yaml
#+END_SRC

In the output you will see your tasks being run as well as an ~Gathering Facts~
task that is run implicitly. By default, Ansible gathers information about your
inventory that it can use in the playbook.

The play recap summarizes the results of all tasks in the playbook per host. In
this example, there are three tasks so ~ok=3~ indicates that each task ran
successfully.

** Ansible playbooks

Ansible Playbooks offer a repeatable, reusable, simple configuration management
and multi-machine deployment system, one that is well suited to deploying
complex applications. If you need to execute a task with Ansible more than once,
write a playbook and put it under source control. Then you can use the playbook
to push out new configuration or confirm the configuration of remote systems.

Playbooks can:

- declare configurations
- orchestrate steps of any manual ordered process, on multiple sets of machines,
  in a defined order
- launch tasks synchronously or asynchronously

*** Playbook syntax

A playbook is composed of one or more /plays/ in an ordered list. Each play
executes part of the overall goal of the playbook, running one or more tasks.
Each task calls an Ansible module.

*** Playbook execution

A playbook runs in order from top to bottom. Within each play, tasks also run in
order from top to bottom. Playbooks with multiple plays can orchestrate
multi-machine deployments, running one play on your webservers, then another
play on your database servers, then a third play on your network infrastructure,
and so on. At a minimum, each play defines two things:

- the managed nodes to target, using a pattern
- at least one task to execute

In this example, the first play targets the web servers; the second play targets
the database servers.

#+BEGIN_SRC yaml
---
- name: Update web servers
  hosts: webservers
  remote_user: root

  tasks:
  - name: Ensure apache is at the latest version
    ansible.builtin.yum:
      name: httpd
      state: latest

  - name: Write the apache config file
    ansible.builtin.template:
      src: /srv/httpd.j2
      dest: /etc/httpd.conf

- name: Update db servers
  hosts: databases
  remote_user: root

  tasks:
  - name: Ensure postgresql is at the latest version
    ansible.builtin.yum:
      name: postgresql
      state: latest

  - name: Ensure that postgresql is started
    ansible.builtin.service:
      name: postgresql
      state: started
#+END_SRC

Your playbook can include more than just a hosts line and tasks. See more about
[[https://docs.ansible.com/ansible/latest/reference_appendices/playbooks_keywords.html#playbook-keywords][Playbook Keywords]].

*** Task execution

By default, Ansible executes each task in order, one at a time, against all
machines matched by the host pattern. Each task executes a module with specific
arguments. When a task has executed on all target machines, Ansible moves on to
the next task. If a task fails on a host, Ansible takes that host out of the
rotation for the rest of the playbook.

*** Desired state and 'idempotency'

Most Ansible modules check whether the desired final state has already been
achieved, and exit without performing any actions if that state has been
achieved, so that repeating the task does not change the final state. Modules
that behave this way are often called ‘idempotent.’ Whether you run a playbook
once, or multiple times, the outcome should be the same. However, not all
playbooks and not all modules behave this way. If you are unsure, test your
playbooks in a sandbox environment before running them multiple times in
production.

*** Running playbooks

Use the ~ansible-playbook~ command:

#+BEGIN_SRC bash :noeval
ansible-playbook playbook.yml
#+END_SRC

Use the ~--verbose~ flag when running your playbook to see detailed output from
successful modules as well as unsuccessful ones.

**** Running playbooks in check mode

Ansible’s check mode allows you to execute a playbook without applying any
alterations to your systems. You can use check mode to test playbooks before
implementing them in a production environment.

To run a playbook in check mode, you can pass the ~-C~ or ~--check~ flag to the
ansible-playbook command:

#+BEGIN_SRC bash :noeval
ansible-playbook --check playbook.yaml
#+END_SRC

Executing this command will run the playbook normally, but instead of
implementing any modifications, Ansible will simply provide a report on the
changes it would have made. This report encompasses details such as file
modifications, command execution, and module calls.

*** Verifying playbooks

You may want to verify your playbooks to catch syntax errors and other problems
before you run them. The ~ansible-playbook~ command offers several options for
verification, including ~--check~, ~--diff~, ~--list-hosts~, ~--list-tasks~, and
~--syntax-check~.

You can use ~ansible-lint~ for detailed, Ansible-specific feedback on your
playbooks before you execute them.

** Working with playbooks

If Ansible modules are the tools in your workshop, playbooks are your
instruction manuals, and your inventory of hosts is your raw material.

*** Templating with Jinja2

Ansible uses Jinja2 templating to enable dynamic expressions and access to
variables and facts. You can use templating with the [[https://docs.ansible.com/ansible/latest/collections/ansible/builtin/template_module.html#template-module][template module]]. For
example, you can create a template for a configuration file, then deploy that
configuration file to multiple environments and supply the correct data (IP
address, hostname, version) for each environment. You can also use templating
in playbooks directly, by templating task names and more. You can use all the
[[https://jinja.palletsprojects.com/en/3.1.x/templates/#builtin-filters][standard filters and tests included in Jinja2]]. Ansible includes additional
specialized filters for selecting and transforming data, tests for evaluating
template expressions, and [[*Lookups][Lookup plugins]] for retrieving data from external
sources such as files, APIs, and databases for use in templating.

All templating happens on the Ansible control node before the task is sent and
executed on the target machine.

**** Example

In [[file:examples/002_template_example][002_template_example]] a small example has been prepared which utilizes the
~template~ plugin.

Try it out with:

#+BEGIN_SRC bash :noeval
ansible-playbook examples/002_template_example/main.yaml
#+END_SRC

*** Using filters to manipulate data
**** Handling undefined variables
***** Providing default values

#+BEGIN_SRC
{{ some_variable | default(5) }}
#+END_SRC

If the variable ~some_variable~ is not defined, Ansible uses the default value
~5~. Also works for ~{{ foo.bar.baz | default('DEFAULT') }}~ if either ~foo~,
~foo.bar~ or ~foo.bar.baz~ would be undefined.

If you want to use the default value when variables evaluate to false or an
empty string you have to set the second parameter to ~true~:

#+BEGIN_SRC
{{ lookup('env', 'MY_USER') | default('admin', true) }}
#+END_SRC

***** Making variables optional

By default, Ansible requires values for all variables in a templated expression.
However, you can make specific module variables optional. For example, you might
want to use a system default for some items and control the value for others. To
make a module variable optional, set the default value to the special variable
~omit~:

#+BEGIN_SRC
mode: "{{ item.mode | default(omit) }}"
#+END_SRC

In this example Ansible would not send a value for the ~mode~ field.

***** Defining mandatory values

If you configure Ansible to ignore undefined variables (e.g. by setting the
environment variable ~DEFAULT_UNDEFINED_VAR_BEHAVIOR~ to ~true~), you may want
to define some values as mandatory.

#+BEGIN_SRC
{{ variable | mandatory }}
#+END_SRC

A convenient way of requiring a variable to be overridden is to give it an
undefined value using the ~undef()~ function:

#+BEGIN_SRC
galaxy_url: "https://galaxy.ansible.com"
galaxy_api_key: "{{ undef(hint='You must specify your Galaxy API key') }}"
#+END_SRC

**** Ternary operator

You can create a test, then define one value to use when the test returns ~true~
and another when the test returns ~false~:

#+BEGIN_SRC
{{ (status == 'needs_restart') | ternary('restart', 'continue') }}
#+END_SRC

In addition, you can define one value to use on ~true~, one value on ~false~ and
a third value on ~null~:

#+BEGIN_SRC
{{ enabled | ternary('no shutdown', 'shutdown', omit) }}
#+END_SRC

**** Managing data types
***** Transforming dictionaries into lists

Use the ~ansible.builtin.dict2items~ filter to transform a dictionary into a
list of items suitable for looping:

#+BEGIN_SRC
{{ dict | dict2items }}
#+END_SRC

Dictionary data before:

#+BEGIN_SRC yaml
tags:
  Application: payment
  Environment: dev
#+END_SRC

List data after:

#+BEGIN_SRC yaml
- key: Application
  value: payment
- key: Environment
  value: dev
#+END_SRC

If you want to configure the names of the keys, the ~ansible.builtin.dict2items~
filter accepts 2 keyword arguments. Pass the ~key_name~ and ~value_name~
arguments to configure the names of the keys in the list output:

#+BEGIN_SRC
{{ files | dict2items(key_name='file', value_name='path') }}
#+END_SRC

***** Transforming lists into dictionaries

Use the ~ansible.builtin.items2dict~ filter to transform a list into a
dictionary, mapping the content into ~key: value~ pairs:

#+BEGIN_SRC
{{ tags | items2dict }}
#+END_SRC

List data before:

#+BEGIN_SRC yaml
tags:
  - key: Application
    value: payment
  - key: Environment
    value: dev
#+END_SRC

Dictionary data after:

#+BEGIN_SRC yaml
Application: payment
Environment: dev
#+END_SRC

If the input list doesn't use the ~key~ and ~value~ fields, you must pass the
~key_name~ and ~value_name~ arguments to configure the transformation. For
example:

#+BEGIN_SRC
{{ fruits | items2dict(key_name='fruit', value_name='color') }}
#+END_SRC

***** Forcing the data type

You can cast values as certain types. For example, if you expect the input
~"True"~ from a ~vars_prompt~ and you want Ansible to recognize it as a boolean
value instead of a string:

#+BEGIN_SRC yaml
- ansible.builtin.debug:
     msg: test
  when: some_string_value | bool
#+END_SRC

If you want to perform a mathematical comparison on a fact and you want Ansible
to recognize it as an integer instead of a string:

#+BEGIN_SRC yaml
- shell: echo "only on Red Hat 6, derivatives, and later"
  when: ansible_facts['os_family'] == "RedHat" and ansible_facts['lsb']['major_release'] | int >= 6
#+END_SRC

**** Other examples

There are a lot more examples at:
https://docs.ansible.com/ansible/latest/playbook_guide/playbooks_filters.html

*** Tests

[[https://jinja.palletsprojects.com/en/latest/templates/#tests][Tests]] in Jinja are a way of evaluating template expressions and returning True
or False. Jinja ships with many of these. See [[https://jinja.palletsprojects.com/en/latest/templates/#builtin-tests][builtin tests]] in the official
Jinja template documentation.

The main difference between tests and filters are that Jinja tests are used for
comparisons, whereas filters are used for data manipulation.

**** Test syntax

The syntax for using a jinja test is as follows

#+BEGIN_SRC
variable is test_name
#+END_SRC

**** Testing strings

To match strings against a substring or a regular expression, use the ~match~,
~search~ or ~regex~ tests:

#+BEGIN_SRC yaml
vars:
  url: "https://example.com/users/foo/resources/bar"

tasks:
    - debug:
        msg: "matched pattern 1"
      # match succeeds if it finds the pattern at the beginning of the string
      when: url is match("https://example.com/users/.*/resources")

    - debug:
        msg: "matched pattern 2"
      # search succeeds if it finds the pattern anywhere within string
      when: url is search("users/.*/resources/.*")

    - debug:
        msg: "matched pattern 3"
      when: url is search("users")

    - debug:
        msg: "matched pattern 4"
      # By default, regex works like search, but regex can be configured to
      # perform other tests as well, by passing the match_type keyword argument
      when: url is regex("example\.com/\w+/foo")
#+END_SRC

More information can be found in the relevant [[https://docs.python.org/3/library/re.html#regular-expression-objects][Python documentation about regex]].

**** Testing truthiness

#+BEGIN_SRC yaml
- debug:
    msg: "Truthy"
  when: value is truthy
  vars:
    value: "some string"

- debug:
    msg: "Falsy"
  when: value is falsy
  vars:
    value: ""
#+END_SRC

**** Comparing versions

https://docs.ansible.com/ansible/latest/playbook_guide/playbooks_tests.html#comparing-versions

**** Set theory tests

To see if a list includes or is included by another list, you can use ~subset~
and ~superset~:

#+BEGIN_SRC yaml
vars:
    a: [1,2,3,4,5]
    b: [2,3]
tasks:
    - debug:
        msg: "A includes B"
      when: a is superset(b)

    - debug:
        msg: "B is included in A"
      when: b is subset(a)
#+END_SRC

**** Testing paths

The following tests can provide information about a path on the control node:

#+BEGIN_SRC yaml
- debug:
    msg: "path is a directory"
  when: mypath is directory

- debug:
    msg: "path is a file"
  when: mypath is file

- debug:
    msg: "path is a symlink"
  when: mypath is link

- debug:
    msg: "path already exists"
  when: mypath is exists

- debug:
    msg: "path is {{ (mypath is abs)|ternary('absolute','relative')}}"

- debug:
    msg: "path is the same file as path2"
  when: mypath is same_file(path2)

- debug:
    msg: "path is a mount"
  when: mypath is mount

- debug:
    msg: "path is a directory"
  when: mypath is directory
  vars:
     mypath: /my/path

- debug:
    msg: "path is a file"
  when: "'/my/path' is file"
#+END_SRC

**** Testing task results

The following tasks are illustrative of the tests meant to check the status of
tasks:

#+BEGIN_SRC yaml
tasks:
  - shell: /usr/bin/foo
    ignore_errors: True
    register: result

  - debug:
      msg: "it failed"
    when: result is failed

  # in most cases you'll want a handler, but if you want to do something right now, this is nice
  - debug:
      msg: "it changed"
    when: result is changed

  - debug:
      msg: "it succeeded in Ansible >= 2.1"
    when: result is succeeded

  - debug:
      msg: "it succeeded"
    when: result is success

  - debug:
      msg: "it was skipped"
    when: result is skipped
#+END_SRC

*** Lookups

Lookup plugins retrieve data from outside sources such as files, databases,
key/value stores, APIs, and other services. Ansible makes the data returned by a
lookup plugin available using the standard templating system.

A lookup can be used indirectly in ~with_<lookup>~ constructs for looping. They
can also be used more explicitly as part of Jinja2 expressions fed into the
~lookup~ keyword.

**** Using lookups in variables

You can populate variables using lookups. Ansible evaluates the value each time
it is executed in a task (or template).

#+BEGIN_SRC yaml
vars:
  motd_value: "{{ lookup('file', '/etc/motd') }}"
tasks:
  - debug:
      msg: "motd value is {{ motd_value }}"
#+END_SRC

This uses the [[https://docs.ansible.com/ansible/latest/collections/ansible/builtin/file_lookup.html#ansible-collections-ansible-builtin-file-lookup][file lookup]]. There are more [[https://docs.ansible.com/ansible/latest/collections/ansible/builtin/index.html#lookup-plugins][builtin lookups]]. You can also list all
installed lookups with ~ansible-doc -l -t lookup~.

*** Python3 in templates

Ansible uses Jinja2 to take advantage of Python data types and standard
functions in templates and variables. You can use these data types and standard
functions to perform a rich set of operations on your data.

**** Dictionary views

#+BEGIN_SRC yaml
vars:
  hosts:
    testhost1: 127.0.0.2
    testhost2: 127.0.0.3
tasks:
  - debug:
      msg: '{{ item }}'
    # Works with both Python 2 and Python 3
    loop: "{{ hosts.keys() | list }}"
#+END_SRC

**** ~dict.iteritems()~

#+BEGIN_SRC yaml
vars:
  hosts:
    testhost1: 127.0.0.2
    testhost2: 127.0.0.3
tasks:
  - debug:
      msg: '{{ item }}'
    # Works with both Python 2 and Python 3
    loop: "{{ hosts.items() | list }}"
#+END_SRC

*** The ~now~ function: get the current time

The ~now()~ Jinja2 function retrieves a Python datetime object or a string
representation for the current time. It supports two arguments:

- ~utc~ :: Specify ~True~ to get the current time in UTC. Defaults to ~False~.
- ~fmt~ :: Accepts a [[https://docs.python.org/3/library/datetime.html#strftime-strptime-behavior][strftime]] string that returns a formatted date time string.

E.g.

#+BEGIN_SRC
dtg: "Current time (UTC): {{ now(utc=true,fmt='%Y-%m-%d %H:%M:%S') }}"
#+END_SRC

*** Loops

Ansible offers the ~loop~, ~with_<lookup>~, and ~until~ keywords to execute a
task multiple times. Examples of commonly-used loops include changing ownership
on several files and/or directories with the file module, creating multiple
users with the user module, and repeating a polling step until a certain result
is reached.

**** Using loops
***** Iterating over a simple list

Repeated tasks can be written as standard loops over a simple list of strings.
You can define the list directly in the task.

#+BEGIN_SRC yaml
- name: Add several users
  ansible.builtin.user:
    name: "{{ item }}"
    state: present
    groups: "wheel"
  loop:
     - testuser1
     - testuser2
#+END_SRC

You can define the list in a variables file, or in the ~vars~ section of your
play, then refer to the name of the list in the task.

#+BEGIN_SRC
loop: "{{ somelist }}"
#+END_SRC

Either of these examples would be the equivalent of:

#+BEGIN_SRC yaml
- name: Add user testuser1
  ansible.builtin.user:
    name: "testuser1"
    state: present
    groups: "wheel"

- name: Add user testuser2
  ansible.builtin.user:
    name: "testuser2"
    state: present
    groups: "wheel"
#+END_SRC

***** Iterating over a list of hashes

If you have a list of hashes, you can reference subkeys in a loop. For example:

#+BEGIN_SRC yaml
- name: Add several users
  ansible.builtin.user:
    name: "{{ item.name }}"
    state: present
    groups: "{{ item.groups }}"
  loop:
    - { name: 'testuser1', groups: 'wheel' }
    - { name: 'testuser2', groups: 'root' }
#+END_SRC

When combining conditionals with a loop, the ~when:~ statement is processed
separately for each item.

***** Iterating over a dictionary

To loop over a dict, use the ~dict2items~ filter:

#+BEGIN_SRC yaml
- name: Using dict2items
  ansible.builtin.debug:
    msg: "{{ item.key }} - {{ item.value }}"
  loop: "{{ tag_data | dict2items }}"
  vars:
    tag_data:
      Environment: dev
      Application: payment
#+END_SRC

***** Registering variables with a loop

You can register the output of a loop as a variable. For example:

#+BEGIN_SRC yaml
- name: Register loop output as a variable
  ansible.builtin.shell: "echo {{ item }}"
  loop:
    - "one"
    - "two"
  register: echo
#+END_SRC

When you use ~register~ with a loop, the data structure placed in the variable
will contain a ~results~ attribute that is a list of all responses from the
module. This differs from the data structure returned when using ~register~
without a loop. The ~changed~ / ~failed~ / ~skipped~ attribute that’s beside the
results will represent the overall state. ~changed~ / ~failed~ will be ~true~ if
at least one of the iterations triggered a ~change~ / ~failed~, while skipped
will be ~true~ only if all iterations were skipped.

#+BEGIN_SRC json
{
    "changed": true,
    "msg": "All items completed",
    "results": [
        {
            "changed": true,
            "cmd": "echo \"one\" ",
            "delta": "0:00:00.003110",
            "end": "2013-12-19 12:00:05.187153",
            "invocation": {
                "module_args": "echo \"one\"",
                "module_name": "shell"
            },
            "item": "one",
            "rc": 0,
            "start": "2013-12-19 12:00:05.184043",
            "stderr": "",
            "stdout": "one"
        },
        {
            "changed": true,
            "cmd": "echo \"two\" ",
            "delta": "0:00:00.002920",
            "end": "2013-12-19 12:00:05.245502",
            "invocation": {
                "module_args": "echo \"two\"",
                "module_name": "shell"
            },
            "item": "two",
            "rc": 0,
            "start": "2013-12-19 12:00:05.242582",
            "stderr": "",
            "stdout": "two"
        }
    ]
}
#+END_SRC

Subsequent loops over the registered variable to inspect the results may look
like:

#+BEGIN_SRC yaml
- name: Fail if return code is not 0
  ansible.builtin.fail:
    msg: "The command ({{ item.cmd }}) did not have a 0 return code"
  when: item.rc != 0
  loop: "{{ echo.results }}"
#+END_SRC

During iteration, the result of the current item will be placed in the variable.

#+BEGIN_SRC yaml
- name: Place the result of the current item in the variable
  ansible.builtin.shell: echo "{{ item }}"
  loop:
    - one
    - two
  register: echo
  changed_when: echo.stdout != "one"
#+END_SRC

***** Retrying a task until a condition is met

You can use the ~until~ keyword to retry a task until a certain condition is
met:

#+BEGIN_SRC yaml
- name: Retry a task until a certain condition is met
  ansible.builtin.shell: /usr/bin/foo
  register: result
  until: result.stdout.find("all systems go") != -1
  retries: 5
  delay: 10
#+END_SRC

This task runs up to 5 times with a delay of 10 seconds between each attempt. If
the result of any attempt has “all systems go” in its stdout, the task succeeds.
The default value for ~retries~ is 3 and ~delay~ is 5.

To see the results of individual retries, run the play with ~-vv~.

You can combine the ~until~ keyword with ~loop~ or ~with_<lookup>~. The result
of the task for each element of the loop is registered in the variable and can
be used in the ~until~ condition:

#+BEGIN_SRC yaml
- name: Retry combined with a loop
  uri:
    url: "https://{{ item }}.ansible.com"
    method: GET
  register: uri_output
  with_items:
  - "galaxy"
  - "docs"
  - "forum"
  - "www"
  retries: 2
  delay: 1
  until: "uri_output.status == 200"
#+END_SRC

***** Looping over inventory

Normally the play itself is a loop over your inventory, but sometimes you need a
task to do the same over a different set of hosts. To loop over your inventory,
or just a subset of it, you can use a regular ~loop~ with the
~ansible_play_batch~ or ~groups~ variables.

#+BEGIN_SRC yaml
- name: Show all the hosts in the inventory
  ansible.builtin.debug:
    msg: "{{ item }}"
  loop: "{{ groups['all'] }}"

- name: Show all the hosts in the current play
  ansible.builtin.debug:
    msg: "{{ item }}"
  loop: "{{ ansible_play_batch }}"
#+END_SRC

There is also a specific lookup plugin ~inventory_hostnames~ that can be used
like this:

#+BEGIN_SRC yaml
- name: Show all the hosts in the inventory
  ansible.builtin.debug:
    msg: "{{ item }}"
  loop: "{{ query('inventory_hostnames', 'all') }}"

- name: Show all the hosts matching the pattern, ie all but the group www
  ansible.builtin.debug:
    msg: "{{ item }}"
  loop: "{{ query('inventory_hostnames', 'all:!www') }}"
#+END_SRC

**** Ensuring list input for ~loop~: using ~query~ rather than ~lookup~

The ~loop~ keyword requires a list as input, but the ~lookup~ keyword returns a
string of comma-separated values by default. You can also use the ~query~
function that always returns a list.

You can force ~lookup~ to return a list to ~loop~ by using ~wantlist=True~, or
you can use query instead.

The following two examples do the same thing.

#+BEGIN_SRC yaml
loop: "{{ query('inventory_hostnames', 'all') }}"

loop: "{{ lookup('inventory_hostnames', 'all', wantlist=True) }}"
#+END_SRC

**** Adding controls to loops

The ~loop_control~ keyword lets you manage your loops in useful ways.

***** Limiting loop output with ~label~

When looping over complex data structures, the console output of your task can
be enormous. To limit the displayed output, use the ~label~ directive with
~loop_control~.

#+BEGIN_SRC yaml
- name: Create servers
  digital_ocean:
    name: "{{ item.name }}"
    state: present
  loop:
    - name: server1
      disks: 3gb
      ram: 15Gb
      network:
        nic01: 100Gb
        nic02: 10Gb
        ...
  loop_control:
    label: "{{ item.name }}"
#+END_SRC

The output of this task will display just the ~name~ field for each ~item~
instead of the entire contents of the multi-line ~{{ item }}~ variable.

This is for making console output more readable, not protecting sensitive data.
If there is sensitive data in ~loop~, set ~no_log: true~ on the task to prevent
disclosure.

***** Pausing within a loop

To control the time (in seconds) between the execution of each item in a task
loop, use the ~pause~ directive with ~loop_control~.

***** Extended loop variables

You can get extended loop information using the extended option to loop control.

#+BEGIN_SRC yaml
loop_control:
  extended: true
#+END_SRC

| Variable                 | Description                                                                             |
|--------------------------+-----------------------------------------------------------------------------------------|
| ~ansible_loop.allitems~  | The list of all items in the loop                                                       |
| ~ansible_loop.index0~    | The current iteration of the loop. (0 indexed)                                          |
| ~ansible_loop.revindex0~ | The number of iterations from the end of the loop (0 indexed)                           |
| ~ansible_loop.first~     | ~True~ if first iteration                                                               |
| ~ansible_loop.last~      | ~True~ if last iteration                                                                |
| ~ansible_loop.length~    | The number of items in the loop                                                         |
| ~ansible_loop.previtem~  | The item from the previous iteration of the loop. Undefined during the first iteration. |
| ~ansible_loop.nextitem~  | The item from the following iteration of the loop. Undefined during the last iteration. |

***** Renaming the loop variable

Instead of the default ~{{ item }}~ variable you can provide a custom name with:

#+BEGIN_SRC yaml
loop_control:
  loop_var: "file"
#+END_SRC

Now you will use ~{{ file }}~ instead.

**** Nested Loops
***** Stacking loops via include_tasks

You can nest two looping tasks using ~include_tasks~. However, by default,
Ansible sets the loop variable ~item~ for each loop. This means the inner,
nested loop will overwrite the value of ~item~ from the outer loop. To avoid
this, you can specify the name of the variable for each loop using ~loop_var~
with ~loop_control~.

#+BEGIN_SRC yaml
# main.yml
- include_tasks: inner.yml
  loop:
    - 1
    - 2
    - 3
  loop_control:
    loop_var: outer_item

# inner.yml
- name: Print outer and inner items
  ansible.builtin.debug:
    msg: "outer item={{ outer_item }} inner item={{ item }}"
  loop:
    - a
    - b
    - c
#+END_SRC

*** Controlling where tasks run: delegation and local actions
**** Delegating tasks

If you want to perform a task on one host with the reference to other hosts, use
the ~delegate_to~ keyword on a task. This is ideal for managing nodes in a
load-balanced pool or for controlling outage windows.

#+BEGIN_SRC yaml
---
- hosts: webservers
  serial: 5

  tasks:
    - name: Take out of load balancer pool
      ansible.builtin.command: /usr/bin/take_out_of_pool {{ inventory_hostname }}
      delegate_to: 127.0.0.1

    - name: Actual steps would go here
      ansible.builtin.yum:
        name: acme-web-stack
        state: latest

    - name: Add back to load balancer pool
      ansible.builtin.command: /usr/bin/add_back_to_pool {{ inventory_hostname }}
      delegate_to: 127.0.0.1
#+END_SRC

The first and third tasks in this play run on ~127.0.0.1~, which is the machine
running Ansible.

The ~ansible_host~ variable and other connection variables, if present, reflects
information about the host a task is delegated to, not the inventory_hostname.

The host to which a task is delegated does not inherit variables from the host
that is delegating the task.

**** Templating in delegation context

Under delegation, the execution interpreter (normally Python), ~connection~,
~become~, and ~shell~ plugin options will now be templated using values from the
delegated to host. All variables except ~inventory_hostname~ will now be
consumed from this host and not the original task host. If you need variables
from the original task host for those options, you must use
~hostvars[inventory_hostname]['varname']~, even ~inventory_hostname_short~
refers to the delegated host.

* Snippets
** Try out variables

#+BEGIN_SRC yaml
---
- name: Check variables
  hosts: all

  tasks:
    - name: Set example values
      ansible.builtin.set_fact:
        an_ip_address: "192.168.0.43"
        a_prefix: 24

    - debug:
        msg: |
          Hostname: {{ hostname }}
          Gateway:  {{ gateway }}
      vars:
        hostname: "{{ an_ip_address }}/{{ a_prefix }}"
        gateway: "{{ hostname | ansible.utils.ipaddr('1') | ansible.utils.ipaddr('address') }}"
#+END_SRC

Run it with

#+BEGIN_SRC bash :noeval
ansible-playbook playbook.yaml
# or
ansible-playbook playbook.yaml -l host
#+END_SRC

** Include / Exclude certain groups from running a job

#+BEGIN_SRC yaml
---
- name: Hello Fedora
  hosts: all

  tasks:
    - debug:
        msg: "Hello world"

    - debug:
        msg: "Hello {{ ansible_distribution }}"
      when: inventory_hostname in groups["fedoras"]
      # or
      #when: inventory_hostname not in groups["ubuntus"]
#+END_SRC

* Useful scripts

Gather and present facts from a machine (the trailing comma after the ip is
intentional). The command below will gather facts from a machine with ip address
~aaa.bbb.ccc.ddd~ and will authenticate with username and password where the
username is ~username~ and password will be provided interactively.

#+BEGIN_SRC bash :noeval
ansible all -i aaa.bbb.ccc.ddd, -m setup --extra-vars "ansible_user=username" --ask-pass
#+END_SRC

* Old
** Ad-hoc commands

#+BEGIN_SRC bash :noeval
ansible -i inventory example -m ping -u centos
ansible -i inventory example -m ping -u ansibleuser --key-file ../../dockerenv/id_rsa

# If we add the key in the inventory file we can omit the key
ansible -i inventory example -m ping -u ansibleuser

# We can even add the user to the inventory file
ansible -i inventory example -m ping

# With an ansible.cfg file we can point to our inventory file and then
# we can omit the -i option as well
ansible ubuntu-server -m ping

# -m is for module
ansible ubuntu-server -m ping

# default for -m is "command" and -a feeds the module arguments
ansible ubuntu-server -a "ls -la"
ansible ubuntu-server -a "date"

ansible multi -a "hostname"

# Control parallellism with -f (default set to 5)
ansible multi -a "hostname" -f 1

# Return everything that ansible can find about a server. Something called "gather facts"
ansible multi -m setup

# Become a different user with -b/--become (default "sudo")
ansible multi -b -a "whoami"

# Install a package
ansible multi -b -m yum -a "name=ntp state=present"

# Check that the service is runnnig / enable the service
ansible multi -b -m service -a "name=ntpd state=started enabled=yes"

# The --limit command can focus on a single server instead of the whole group
#TODO

# Background tasks -B -P
ansible multi -b -B 3600 -P 0 -a "yum -y update"
# Look at ansible_job_id and results_file field
ansible multi -b -m async_status -a <ansible_job_id>

# This won't work as the command module doesn't handle pipes and redirections etc.
ansible multi -b -a "tail /var/log/messages | grep ansible-command | wc -l"

# Use shell module instead (but should be avoided)
ansible multi -b -m shell -a "tail /var/log/messages | grep ansible-command | wc -l"
#+END_SRC

Ansible is idempotent. If we run it more than one time it will still yield the
same result. The ~command~ module will always run anyway and report a ~CHANGED~
status as ansible don't know what has been done. When using other ansible
modules, ansible can know if something was updated or not.

#+BEGIN_SRC yaml
---
- name: Set up NTP on all servers.
  hosts: all
  become: yes # Run as sudo
  tasks:
    - name: Ensure NTP is installed.
      yum: name=ntp state=present
    - name: Ensure NTP is running.
      services: name= ntpd state=started enabled=yes
#+END_SRC

** Module documentation

#+BEGIN_SRC bash :noeval
ansible-doc <module_name>
#e.g.
ansible-doc service
#+END_SRC

Modules to investigate:

- cron
- git

** Playbooks

Convention to call the main playbook ~main.yml~

*** Example 1

#+BEGIN_SRC yaml
---
- name: Install Apache.
  hosts: all

  tasks:
    - name: Install Apache.
      command: yum install --quiet -y httpd httpd-devel
    - name: Copy configuration files.
      command: >
        cp src_file /path/to/target
      command: >
        cp src_file2 /path/to/target2
    - name: Start Apache and configure it to run at boot.
      command: service httpd start
    - command: chkconfig httpd on
#+END_SRC

#+BEGIN_SRC yaml
---
- name: Install Apache.
  hosts: all
  become: true # Can also be put in each task if we don't need to be root during
               # all steps. You can also provide the -b option to the
               # ansible-playbook command

  tasks:
    - name: Install Apache.
      yum:
        name:
          - httpd
          - httpd-devel
        state: present

    - name: Copy configuration files.
      copy:
        src: "{{ item.src }}" # jinja templates
        #src: "{{ item['src'] }}" # Also acceptable
        dst: "{{ item.dest }}"
        owner: root
        group: root
        mode: 0644
      with_items:
        - src: httpd.conf
          dest: /etc/httpd/conf/httpd.conf
        - src: httpd-vhosts.conf
          dest: /etc/httpd/conf/httpd-vhosts.conf

    - name: Make sure Apache is started now and at boot.
      service:
        name: httpd
        state: started
        enabled: true
#+END_SRC

This playbook is idempotent but if any of the copied file is changed later on
the web server won't restart automatically!

#+BEGIN_SRC bash :noeval
ansible-playbook -i inventory main.yml

ansbile-playbook -i inventory multi --limit=192.168.60.5
ansbile-playbook -i inventory multi --limit=!:db

ansible-inventory --list -i inventory
#+END_SRC

*** Example 2

#+BEGIN_SRC yaml
---
- hosts: solr
  become: true

  vars_files:
    - vars.yaml

  pre_tasks:
    - name: Update apt cache if needed
      apt: update_cache=true cache_valid_time=3600

  handler:
    # A task can trigger this if it has been updated by using "notify: restart solr"
    # It's not used in the example below though
    - name: restart solr
      services: name=solr state=restarted

  tasks:
    - name: Install Java
      apt: name=openjdk-8.jdk state=present

    - name: Download solr.
      get_url:
        url: "http://fake.url/path/{{ solr_version }}/download/solr-{{ solr_version }}.tgz"
        dest: "{{ download_dir }}/solr-{{ solr_version }}.tgz" # It's a good idea to state the whole path
                                                               # so ansible can check it it already exists
        checksum: "{{ solr_checksum }}"

    - name: Expand solr.
      unarchive:
        src: "{{ download_dir }}/solr-{{ solr_version }}.tgz"
        dest: "{{ download_dir }}"
        remote_src: true # Be default it takes the file on my local machine and copies it to the remove.
                         # This tells ansible that the file is on the remote already
        # Controls idempotece by specifying which files will be created by this action
        creates: "{{ download_dir }}/solr-{{ solr_version }}/README.txt"

    - name: Run Solr insallation script.
      command: >
        {{ download_dir }}/solr-{{ solr_version }}/bin/install_solr.sh
        {{ download_dir }}/solr-{{ solr_version }}.tgz
        -i /opt
        -d /var/solr
        -u solr
        -s solr
        -p 8983
        creates={{ solr_dir }}/bin/solr

    - name: Ensure solr is started and enabled at boot.
      service: name=solr state=started enabled=yes
#+END_SRC

#+BEGIN_SRC yaml
---
download_dir: /tmp
solr_dir: /opt/solr
solr_version: 8.5.0
solr_checksum: sha512:abc123
#+END_SRC

Check if it's valid:

#+BEGIN_SRC bash :noeval
ansible-playbook -i inventory main.yml --syntax-check
#+END_SRC

*** Example 3

#+BEGIN_SRC yaml
---
- name: Install Apache.
  hosts: all
  become: true

  vars:
    proxy_vars:
      http_proxy: http://example-proxy:80/
      https_proxy: https://example-proxy:80/

  environment:
    # Set's environment for all tasks
    var0: value0
    var1: value1

  handler:
    # A handler works like a normal task and can also use notify to trigger other handlers
    - name: restart apache
      service:
        name: httpd
        state: restarted
      #notify: restart memcached

  tasks:
    - name: Download a file.
      get_url:
        url: http://ipv4.download.thinkbroadband.com/20MB.zip
        dest: /tmp
      environment:
        http_proxy: http://example-proxy:80/
        https_proxy: https://example-proxy:80/
      # or
      #environment: proxy_vars


    - name: Add an environment variable to the remote user's shell.
      lineinefile:
        dest: "~/.bash_profile"
        regexp: '^ENV_VAR='
        line: 'ENV_VAR=value'
      become: false

    - name: Get the value of an environment variable.
      shell: 'source ~/.bash_profile && echo $ENV_VAR'
      register: foo

    - debug: msg="The variable is {{ foo.stdout }}"

    - name: Install Apache.
      yum:
        name: httpd
        state: present

    - name: Copy test config file.
      copy:
        src: files/test.conf
        dst: /etc/httpd/conf.d/test.conf
      # Run the "restart apache" handler if this task has been run. The handler will be run
      # after all tasks are done
      notify:
        # List of handlers
        - restart apache

    # With this meta task we will run all handler to be run directly instead of in the end
    - name: Make sure handlers are flushed immediately.
      meta: flush_handlers

    - name: Make sure Apache is started now and at boot.
      service:
        name: httpd
        state: started
        enabled: true
#+END_SRC

#+BEGIN_SRC xml
<LocationMatch "^/+$">
  Options -Indexes
  ErrorDocument 403 /.noindex.html
</LocationMatch>

<Directory /var/www/html>
  AllowOverride None
  Require all granted
</Directory>
#+END_SRC

If a task fails before a handler has been run it will not execute. So if you
notify in one step but a later task fails, the handler will not be run in the
end of the playbook. Try it out with the ~fail~ module:

#+BEGIN_SRC yaml
tasks:
  ...
  - fail:
  ...
#+END_SRC

You can overcome this behaviour by running ~ansible-playbook~ with
~--force-handlers~.

*** Example 4

#+BEGIN_SRC yaml
---
- name: Install Apache.
  hosts: all
  #gather_facts: false # Will not make ansible_os_family available
  become: true

  #vars:
  #  apache_package: httpd
  #  apache_service: httpd
  #  apache_config_dir: /etc/apache2/sites-enabled

  handler:
    # A handler works like a normal task and can also use notify to trigger other handlers
    - name: restart apache
      service:
        name: "{{ apache_service }}"
        state: restarted
      #notify: restart memcached

  pre_tasks:
    - debug: var=ansible_os_family

    - name: Load variables files.
      include_vars: "{{ item }}"
      with_first_found:
        - "vars/apache_{{ ansible_os_family }}.yml"
        - "vars/apache_default.yml"

  tasks:
    - name: Install Apache.
      package:
        name: "{{ apache_package }}"
        state: present
      register: foo

    - debug: var=foo
    - debug: var=foo.rc
    - debug: var=foo['rc']

    - name: Copy test config file.
      copy:
        src: files/test.conf
        dst: "{{ apache_config_dir }}/test.conf"
      # Run the "restart apache" handler if this task has been run. The handler will be run
      # after all tasks are done
      notify:
        # List of handlers
        - restart apache

    # With this meta task we will run all handler to be run directly instead of in the end
    - name: Make sure handlers are flushed immediately.
      meta: flush_handlers

    - name: Make sure Apache is started now and at boot.
      service:
        name: "{{ apache_service }}"
        state: started
        enabled: true
#+END_SRC

#+BEGIN_SRC yaml
# vars/apache_default.yml
apache_package: apache2
apache_service: apache2
apache_config_dir: /etc/apache2/sites-enabled
#+END_SRC

#+BEGIN_SRC yaml
# vars/apache_RedHat.yml
apache_package: httpd
apache_service: httpd
apache_config_dir: /etc/httpd/conf.d
#+END_SRC

The ~ansible_os_family~ is set during the ~gather_facts~ step. You can see
everything ansible knows about the system by using the ~setup~ module:

#+BEGIN_SRC bash :noeval
ansible -i inventory centos -m setup
#+END_SRC

*** Other keywords to investigate

- ~when~: Control if the task should be run
- ~changed_when~: Interpret yourself if the task resulted in a change
- ~failed_when~: Interpret yourself if the task resulted in a fail
- ~ignore_error~:
- ~tags~: Tag a number of task and control which tasks should be run with ~--tags~
- blocks: Allows you to do try except workflows

** Ansible vault

#+BEGIN_SRC yaml
---
- hosts: localhost
  connection: local
  gather_facts: no

  vars_files:
    - vars/api_key.yml

  tasks:
    - name: Echo the API key which was injected into the env.
      shell: echo $API_KEY
      environment:
        API_KEY: "{{ myapp_api_key }}"
      register: echo_result

    - names: Show the result.
      debug: var=echo_result.stdout
#+END_SRC

Encrypt a var file

#+BEGIN_SRC bash :noeval
ansible-vault encrypt vars/api_key.yml
# Provide password
#+END_SRC

Use it:

#+BEGIN_SRC bash :noeval
ansible-playbook main.yml --ask-vault-pass
ansible-playbook main.yml --vault-password-file path/to/file
#+END_SRC

Decrypt file

#+BEGIN_SRC bash :noeval
ansible-vault decrypt vars/api_key.yml
#+END_SRC

Edit file without decrypting it to separate file

#+BEGIN_SRC bash :noeval
ansible-vault edit vars/api_key.yml
#+END_SRC

Change password key:

#+BEGIN_SRC bash :noeval
ansible-vault rekey vars/api_key.yml
#+END_SRC

** Playbook organization

Tasks can be included in a playbook.

#+BEGIN_SRC yaml
---
- name: Install Apache.
  hosts: all
  become: true

  handler:
    # Basically this import will replace this line with the content of apache.yml
    # so I guess that ordering is still important of imports
    - import_tasks: handlers/apache.yml

  pre_tasks:
    - name: Load variables files.
      include_vars: "{{ item }}"
      with_first_found:
        - "vars/apache_{{ ansible_os_family }}.yml"
        - "vars/apache_default.yml"

  tasks:
    - import_tasks: tasks/apache.yml
      #vars:
      #  apache_package: apache3
    # There's also something called include_tasks
    #- include_tasks: tasks/log.yml

#- import_playbook: app.yml
#+END_SRC

#+BEGIN_SRC yaml
# handlers/apache.yml
---
- name: restart apache
  service:
    name: "{{ apache_service }}"
    state: restarted
#+END_SRC

#+BEGIN_SRC yaml
# tasks/apache.yml
---
- name: Install Apache.
  package:
    name: "{{ apache_package }}"
    state: present

- name: Copy test config file.
  copy:
    src: files/test.conf
    dst: "{{ apache_config_dir }}/test.conf"
  notify:
    - restart apache

- name: Make sure Apache is started now and at boot.
  service:
    name: "{{ apache_service }}"
    state: started
    enabled: true
#+END_SRC

You can also import a playbook using ~import_playbook~

** Roles

Roles let's you package up stuff which can be used for a single or multiple
playbooks.

** Config
*** ~ansible.cfg~

#+BEGIN_SRC
[ssh_connection]
pipelining = True
#+END_SRC

*** Inventory format

#+BEGIN_SRC ini
# Application servers
[app]
192.168.60.4
192.168.60.5

# Database servers
[db]
192.168.60.6

# Group has all the servers
[multi:children]
app
db

[multi:vars]
ansible_ssh_user=ansibleuser
ansible_host=localhost
#ansible_ssh_common_args="-o StrictHostKeyChecking=no"
#+END_SRC
